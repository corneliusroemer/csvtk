{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"csvtk - a cross-platform, efficient and practical CSV/TSV toolkit Documents: http://bioinf.shenwei.me/csvtk ( Usage and Tutorial ). \u4e2d\u6587\u4ecb\u7ecd Source code: https://github.com/shenwei356/csvtk Latest version: Introduction Similar to FASTA/Q format in field of Bioinformatics, CSV/TSV formats are basic and ubiquitous file formats in both Bioinformatics and data science. People usually use spreadsheet software like MS Excel to process table data. However this is all by clicking and typing, which is not automated and is time-consuming to repeat , especially when you want to apply similar operations with different datasets or purposes. You can also accomplish some CSV/TSV manipulations using shell commands, but more code is needed to handle the header line. Shell commands do not support selecting columns with column names either. csvtk is convenient for rapid data investigation and also easy to integrate into analysis pipelines . It could save you lots of time in (not) writing Python/R scripts. Table of Contents Features Subcommands Installation Command-line completion Compared to csvkit Examples Acknowledgements Contact License Starchart Features Cross-platform (Linux/Windows/Mac OS X/OpenBSD/FreeBSD) Light weight and out-of-the-box, no dependencies, no compilation, no configuration Fast , multiple-CPUs supported (some commands) Practical functions provided by N subcommands Support STDIN and gziped input/output file, easy being used in pipe Most of the subcommands support unselecting fields and fuzzy fields , e.g. -f \"-id,-name\" for all fields except \"id\" and \"name\", -F -f \"a.*\" for all fields with prefix \"a.\". Support some common plots (see usage ) Seamlessly support for data with meta line (e.g., sep=, ) of separator declaration used by MS Excel Subcommands 49 subcommands in total. Information headers : prints headers dim : dimensions of CSV file nrow : print number of records ncol : print number of columns summary : summary statistics of selected numeric or text fields (groupby group fields) watch : online monitoring and histogram of selected field corr : calculate Pearson correlation between numeric columns Format conversion pretty : converts CSV to readable aligned table csv2tab : converts CSV to tabular format tab2csv : converts tabular format to CSV space2tab : converts space delimited format to CSV transpose : transposes CSV data csv2md : converts CSV to markdown format csv2rst : convert CSV to reStructuredText format csv2json : converts CSV to JSON format csv2xlsx : convert CSV/TSV files to XLSX file xlsx2csv : converts XLSX to CSV format Set operations head : prints first N records concat : concatenates CSV/TSV files by rows sample : sampling by proportion cut : select and arrange fields grep : greps data by selected fields with patterns/regular expressions uniq : unique data without sorting freq : frequencies of selected fields inter : intersection of multiple files filter : filters rows by values of selected fields with arithmetic expression filter2 : filters rows by awk-like arithmetic/string expressions join : join files by selected fields (inner, left and outer join) split splits CSV/TSV into multiple files according to column values splitxlsx : splits XLSX sheet into multiple sheets according to column values comb : compute combinations of items at every row Edit add-header : add column names del-header : delete column names rename : renames column names with new names rename2 : renames column names by regular expression replace : replaces data of selected fields by regular expression round : round float to n decimal places mutate : creates new columns from selected fields by regular expression mutate2 : creates new column from selected fields by awk-like arithmetic/string expressions sep : separate column into multiple columns gather : gathers columns into key-value pairs unfold : unfold multiple values in cells of a field fold : fold multiple values of a field into cells of groups fmtdate : format date of selected fields Ordering sort : sorts by selected fields Ploting plot see usage plot hist histogram plot box boxplot plot line line plot and scatter plot Misc cat stream file and report progress version print version information and check for update genautocomplete generate shell autocompletion script (bash|zsh|fish|powershell) Installation Download Page csvtk is implemented in Go programming language, executable binary files for most popular operating systems are freely available in release page. Method 1: Download binaries (latest stable/dev version) Just download compressed executable file of your operating system, and decompress it with tar -zxvf *.tar.gz command or other tools. And then: For Linux-like systems If you have root privilege simply copy it to /usr/local/bin : sudo cp csvtk /usr/local/bin/ Or copy to anywhere in the environment variable PATH : mkdir -p $HOME/bin/; cp csvtk $HOME/bin/ For windows , just copy csvtk.exe to C:\\WINDOWS\\system32 . Method 2: Install via conda (latest stable version) conda install -c bioconda csvtk Method 3: Install via homebrew brew install csvtk Method 4: For Go developer (latest stable/dev version) go get -u github.com/shenwei356/csvtk/csvtk Method 5: For ArchLinux AUR users (may be not the latest) yaourt -S csvtk Command-line completion Bash: # generate completion shell csvtk genautocomplete --shell bash # configure if never did. # install bash-completion if the \"complete\" command is not found. echo \"for bcfile in ~/.bash_completion.d/* ; do source \\$bcfile; done\" >> ~/.bash_completion echo \"source ~/.bash_completion\" >> ~/.bashrc Zsh: # generate completion shell csvtk genautocomplete --shell zsh --file ~/.zfunc/_csvtk # configure if never did echo 'fpath=( ~/.zfunc \"${fpath[@]}\" )' >> ~/.zshrc echo \"autoload -U compinit; compinit\" >> ~/.zshrc fish: csvtk genautocomplete --shell fish --file ~/.config/fish/completions/csvtk.fish Compared to csvkit csvkit , attention: this table wasn't updated for 2 years. Features csvtk csvkit Note Read Gzip Yes Yes read gzip files Fields ranges Yes Yes e.g. -f 1-4,6 Unselect fileds Yes -- e.g. -1 for excluding first column Fuzzy fields Yes -- e.g. ab* for columns with name prefix \"ab\" Reorder fields Yes Yes it means -f 1,2 is different from -f 2,1 Rename columns Yes -- rename with new name(s) or from existed names Sort by multiple keys Yes Yes bash sort like operations Sort by number Yes -- e.g. -k 1:n Multiple sort Yes -- e.g. -k 2:r -k 1:nr Pretty output Yes Yes convert CSV to readable aligned table Unique data Yes -- unique data of selected fields frequency Yes -- frequencies of selected fields Sampling Yes -- sampling by proportion Mutate fields Yes -- create new columns from selected fields Repalce Yes -- replace data of selected fields Similar tools: csvkit - A suite of utilities for converting to and working with CSV, the king of tabular file formats. http://csvkit.rtfd.org/ xsv - A fast CSV toolkit written in Rust. miller - Miller is like sed, awk, cut, join, and sort for name-indexed data such as CSV and tabular JSON http://johnkerl.org/miller tsv-utils - Command line utilities for tab-separated value files written in the D programming language. Examples More examples and tutorial . Attention The CSV parser requires all the lines have same number of fields/columns. Even lines with spaces will cause error. Use '-I/--ignore-illegal-row' to skip these lines if neccessary. By default, csvtk thinks your files have header row, if not, switch flag -H on. Column names better be unique. By default, lines starting with # will be ignored, if the header row starts with # , please assign flag -C another rare symbol, e.g. '$' . By default, csvtk handles CSV files, use flag -t for tab-delimited files. If \" exists in tab-delimited files, use flag -l . Do not mix use field (column) numbers and names. Examples Pretty result $ csvtk pretty names.csv id first_name last_name username 11 Rob Pike rob 2 Ken Thompson ken 4 Robert Griesemer gri 1 Robert Thompson abc NA Robert Abel 123 Summary of selected numeric fields, supporting \"group-by\" $ cat testdata/digitals2.csv \\ | csvtk summary --ignore-non-digits --fields f4:sum,f5:sum --groups f1,f2 \\ | csvtk pretty f1 f2 f4:sum f5:sum bar xyz 7.00 106.00 bar xyz2 4.00 4.00 foo bar 6.00 3.00 foo bar2 4.50 5.00 Select fields/columns ( cut ) By index: csvtk cut -f 1,2 By names: csvtk cut -f first_name,username Unselect : csvtk cut -f -1,-2 or csvtk cut -f -first_name Fuzzy fields : csvtk cut -F -f \"*_name,username\" Field ranges: csvtk cut -f 2-4 for column 2,3,4 or csvtk cut -f -3--1 for discarding column 1,2,3 All fields: csvtk cut -F -f \"*\" Search by selected fields ( grep ) (matched parts will be highlighted as red) By exactly matching: csvtk grep -f first_name -p Robert -p Rob By regular expression: csvtk grep -f first_name -r -p Rob By pattern list: csvtk grep -f first_name -P name_list.txt Remore rows containing missing data (NA): csvtk grep -F -f \"*\" -r -p \"^$\" -v Rename column names ( rename and rename2 ) Setting new names: csvtk rename -f A,B -n a,b or csvtk rename -f 1-3 -n a,b,c Replacing with original names by regular express: cat ../testdata/c.csv | ./csvtk rename2 -F -f \"*\" -p \"(.*)\" -r 'prefix_$1' for adding prefix to all column names. Edit data with regular expression ( replace ) Remove Chinese charactors: csvtk replace -F -f \"*_name\" -p \"\\p{Han}+\" -r \"\" Create new column from selected fields by regular expression ( mutate ) In default, copy a column: csvtk mutate -f id Extract prefix of data as group name (get \"A\" from \"A.1\" as group name): csvtk mutate -f sample -n group -p \"^(.+?)\\.\" Sort by multiple keys ( sort ) By single column : csvtk sort -k 1 or csvtk sort -k last_name By multiple columns: csvtk sort -k 1,2 or csvtk sort -k 1 -k 2 or csvtk sort -k last_name,age Sort by number: csvtk sort -k 1:n or csvtk sort -k 1:nr for reverse number Complex sort: csvtk sort -k region -k age:n -k id:nr In natural order: csvtk sort -k chr:N Join multiple files by keys ( join ) All files have same key column: csvtk join -f id file1.csv file2.csv Files have different key columns: csvtk join -f \"username;username;name\" names.csv phone.csv adress.csv -k Filter by numbers ( filter ) Single field: csvtk filter -f \"id>0\" Multiple fields : csvtk filter -f \"1-3>0\" Using --any to print record if any of the field satisfy the condition: csvtk filter -f \"1-3>0\" --any fuzzy fields : csvtk filter -F -f \"A*!=0\" Filter rows by awk-like arithmetic/string expressions ( filter2 ) Using field index: csvtk filter2 -f '$3>0' Using column names: csvtk filter2 -f '$id > 0' Both arithmetic and string expressions: csvtk filter2 -f '$id > 3 || $username==\"ken\"' More complicated: csvtk filter2 -H -t -f '$1 > 2 && $2 % 2 == 0' Ploting plot histogram with data of the second column: csvtk -t plot hist testdata/grouped_data.tsv.gz -f 2 | display plot boxplot with data of the \"GC Content\" (third) column, group information is the \"Group\" column. csvtk -t plot box testdata/grouped_data.tsv.gz -g \"Group\" \\ -f \"GC Content\" --width 3 | display plot horiz boxplot with data of the \"Length\" (second) column, group information is the \"Group\" column. csvtk -t plot box testdata/grouped_data.tsv.gz -g \"Group\" -f \"Length\" \\ --height 3 --width 5 --horiz --title \"Horiz box plot\" | display plot line plot with X-Y data csvtk -t plot line testdata/xy.tsv -x X -y Y -g Group | display plot scatter plot with X-Y data csvtk -t plot line testdata/xy.tsv -x X -y Y -g Group --scatter | display Acknowledgements We are grateful to Zhiluo Deng and Li Peng for suggesting features and reporting bugs. Thanks Albert Vilella for features suggestion, which makes csvtk feature-rich\u3002 Contact Create an issue to report bugs, propose new functions or ask for help. Or leave a comment . License MIT License Starchart","title":"Home"},{"location":"#csvtk-a-cross-platform-efficient-and-practical-csvtsv-toolkit","text":"Documents: http://bioinf.shenwei.me/csvtk ( Usage and Tutorial ). \u4e2d\u6587\u4ecb\u7ecd Source code: https://github.com/shenwei356/csvtk Latest version:","title":"csvtk - a cross-platform, efficient and practical CSV/TSV toolkit"},{"location":"#introduction","text":"Similar to FASTA/Q format in field of Bioinformatics, CSV/TSV formats are basic and ubiquitous file formats in both Bioinformatics and data science. People usually use spreadsheet software like MS Excel to process table data. However this is all by clicking and typing, which is not automated and is time-consuming to repeat , especially when you want to apply similar operations with different datasets or purposes. You can also accomplish some CSV/TSV manipulations using shell commands, but more code is needed to handle the header line. Shell commands do not support selecting columns with column names either. csvtk is convenient for rapid data investigation and also easy to integrate into analysis pipelines . It could save you lots of time in (not) writing Python/R scripts.","title":"Introduction"},{"location":"#table-of-contents","text":"Features Subcommands Installation Command-line completion Compared to csvkit Examples Acknowledgements Contact License Starchart","title":"Table of Contents"},{"location":"#features","text":"Cross-platform (Linux/Windows/Mac OS X/OpenBSD/FreeBSD) Light weight and out-of-the-box, no dependencies, no compilation, no configuration Fast , multiple-CPUs supported (some commands) Practical functions provided by N subcommands Support STDIN and gziped input/output file, easy being used in pipe Most of the subcommands support unselecting fields and fuzzy fields , e.g. -f \"-id,-name\" for all fields except \"id\" and \"name\", -F -f \"a.*\" for all fields with prefix \"a.\". Support some common plots (see usage ) Seamlessly support for data with meta line (e.g., sep=, ) of separator declaration used by MS Excel","title":"Features"},{"location":"#subcommands","text":"49 subcommands in total. Information headers : prints headers dim : dimensions of CSV file nrow : print number of records ncol : print number of columns summary : summary statistics of selected numeric or text fields (groupby group fields) watch : online monitoring and histogram of selected field corr : calculate Pearson correlation between numeric columns Format conversion pretty : converts CSV to readable aligned table csv2tab : converts CSV to tabular format tab2csv : converts tabular format to CSV space2tab : converts space delimited format to CSV transpose : transposes CSV data csv2md : converts CSV to markdown format csv2rst : convert CSV to reStructuredText format csv2json : converts CSV to JSON format csv2xlsx : convert CSV/TSV files to XLSX file xlsx2csv : converts XLSX to CSV format Set operations head : prints first N records concat : concatenates CSV/TSV files by rows sample : sampling by proportion cut : select and arrange fields grep : greps data by selected fields with patterns/regular expressions uniq : unique data without sorting freq : frequencies of selected fields inter : intersection of multiple files filter : filters rows by values of selected fields with arithmetic expression filter2 : filters rows by awk-like arithmetic/string expressions join : join files by selected fields (inner, left and outer join) split splits CSV/TSV into multiple files according to column values splitxlsx : splits XLSX sheet into multiple sheets according to column values comb : compute combinations of items at every row Edit add-header : add column names del-header : delete column names rename : renames column names with new names rename2 : renames column names by regular expression replace : replaces data of selected fields by regular expression round : round float to n decimal places mutate : creates new columns from selected fields by regular expression mutate2 : creates new column from selected fields by awk-like arithmetic/string expressions sep : separate column into multiple columns gather : gathers columns into key-value pairs unfold : unfold multiple values in cells of a field fold : fold multiple values of a field into cells of groups fmtdate : format date of selected fields Ordering sort : sorts by selected fields Ploting plot see usage plot hist histogram plot box boxplot plot line line plot and scatter plot Misc cat stream file and report progress version print version information and check for update genautocomplete generate shell autocompletion script (bash|zsh|fish|powershell)","title":"Subcommands"},{"location":"#installation","text":"Download Page csvtk is implemented in Go programming language, executable binary files for most popular operating systems are freely available in release page.","title":"Installation"},{"location":"#method-1-download-binaries-latest-stabledev-version","text":"Just download compressed executable file of your operating system, and decompress it with tar -zxvf *.tar.gz command or other tools. And then: For Linux-like systems If you have root privilege simply copy it to /usr/local/bin : sudo cp csvtk /usr/local/bin/ Or copy to anywhere in the environment variable PATH : mkdir -p $HOME/bin/; cp csvtk $HOME/bin/ For windows , just copy csvtk.exe to C:\\WINDOWS\\system32 .","title":"Method 1: Download binaries (latest stable/dev version)"},{"location":"#method-2-install-via-conda-latest-stable-version","text":"conda install -c bioconda csvtk","title":"Method 2: Install via conda (latest stable version)"},{"location":"#method-3-install-via-homebrew","text":"brew install csvtk","title":"Method 3: Install via homebrew"},{"location":"#method-4-for-go-developer-latest-stabledev-version","text":"go get -u github.com/shenwei356/csvtk/csvtk","title":"Method 4: For Go developer (latest stable/dev version)"},{"location":"#method-5-for-archlinux-aur-users-may-be-not-the-latest","text":"yaourt -S csvtk","title":"Method 5: For ArchLinux AUR users (may be not the latest)"},{"location":"#command-line-completion","text":"Bash: # generate completion shell csvtk genautocomplete --shell bash # configure if never did. # install bash-completion if the \"complete\" command is not found. echo \"for bcfile in ~/.bash_completion.d/* ; do source \\$bcfile; done\" >> ~/.bash_completion echo \"source ~/.bash_completion\" >> ~/.bashrc Zsh: # generate completion shell csvtk genautocomplete --shell zsh --file ~/.zfunc/_csvtk # configure if never did echo 'fpath=( ~/.zfunc \"${fpath[@]}\" )' >> ~/.zshrc echo \"autoload -U compinit; compinit\" >> ~/.zshrc fish: csvtk genautocomplete --shell fish --file ~/.config/fish/completions/csvtk.fish","title":"Command-line completion"},{"location":"#compared-to-csvkit","text":"csvkit , attention: this table wasn't updated for 2 years. Features csvtk csvkit Note Read Gzip Yes Yes read gzip files Fields ranges Yes Yes e.g. -f 1-4,6 Unselect fileds Yes -- e.g. -1 for excluding first column Fuzzy fields Yes -- e.g. ab* for columns with name prefix \"ab\" Reorder fields Yes Yes it means -f 1,2 is different from -f 2,1 Rename columns Yes -- rename with new name(s) or from existed names Sort by multiple keys Yes Yes bash sort like operations Sort by number Yes -- e.g. -k 1:n Multiple sort Yes -- e.g. -k 2:r -k 1:nr Pretty output Yes Yes convert CSV to readable aligned table Unique data Yes -- unique data of selected fields frequency Yes -- frequencies of selected fields Sampling Yes -- sampling by proportion Mutate fields Yes -- create new columns from selected fields Repalce Yes -- replace data of selected fields Similar tools: csvkit - A suite of utilities for converting to and working with CSV, the king of tabular file formats. http://csvkit.rtfd.org/ xsv - A fast CSV toolkit written in Rust. miller - Miller is like sed, awk, cut, join, and sort for name-indexed data such as CSV and tabular JSON http://johnkerl.org/miller tsv-utils - Command line utilities for tab-separated value files written in the D programming language.","title":"Compared to csvkit"},{"location":"#examples","text":"More examples and tutorial . Attention The CSV parser requires all the lines have same number of fields/columns. Even lines with spaces will cause error. Use '-I/--ignore-illegal-row' to skip these lines if neccessary. By default, csvtk thinks your files have header row, if not, switch flag -H on. Column names better be unique. By default, lines starting with # will be ignored, if the header row starts with # , please assign flag -C another rare symbol, e.g. '$' . By default, csvtk handles CSV files, use flag -t for tab-delimited files. If \" exists in tab-delimited files, use flag -l . Do not mix use field (column) numbers and names. Examples Pretty result $ csvtk pretty names.csv id first_name last_name username 11 Rob Pike rob 2 Ken Thompson ken 4 Robert Griesemer gri 1 Robert Thompson abc NA Robert Abel 123 Summary of selected numeric fields, supporting \"group-by\" $ cat testdata/digitals2.csv \\ | csvtk summary --ignore-non-digits --fields f4:sum,f5:sum --groups f1,f2 \\ | csvtk pretty f1 f2 f4:sum f5:sum bar xyz 7.00 106.00 bar xyz2 4.00 4.00 foo bar 6.00 3.00 foo bar2 4.50 5.00 Select fields/columns ( cut ) By index: csvtk cut -f 1,2 By names: csvtk cut -f first_name,username Unselect : csvtk cut -f -1,-2 or csvtk cut -f -first_name Fuzzy fields : csvtk cut -F -f \"*_name,username\" Field ranges: csvtk cut -f 2-4 for column 2,3,4 or csvtk cut -f -3--1 for discarding column 1,2,3 All fields: csvtk cut -F -f \"*\" Search by selected fields ( grep ) (matched parts will be highlighted as red) By exactly matching: csvtk grep -f first_name -p Robert -p Rob By regular expression: csvtk grep -f first_name -r -p Rob By pattern list: csvtk grep -f first_name -P name_list.txt Remore rows containing missing data (NA): csvtk grep -F -f \"*\" -r -p \"^$\" -v Rename column names ( rename and rename2 ) Setting new names: csvtk rename -f A,B -n a,b or csvtk rename -f 1-3 -n a,b,c Replacing with original names by regular express: cat ../testdata/c.csv | ./csvtk rename2 -F -f \"*\" -p \"(.*)\" -r 'prefix_$1' for adding prefix to all column names. Edit data with regular expression ( replace ) Remove Chinese charactors: csvtk replace -F -f \"*_name\" -p \"\\p{Han}+\" -r \"\" Create new column from selected fields by regular expression ( mutate ) In default, copy a column: csvtk mutate -f id Extract prefix of data as group name (get \"A\" from \"A.1\" as group name): csvtk mutate -f sample -n group -p \"^(.+?)\\.\" Sort by multiple keys ( sort ) By single column : csvtk sort -k 1 or csvtk sort -k last_name By multiple columns: csvtk sort -k 1,2 or csvtk sort -k 1 -k 2 or csvtk sort -k last_name,age Sort by number: csvtk sort -k 1:n or csvtk sort -k 1:nr for reverse number Complex sort: csvtk sort -k region -k age:n -k id:nr In natural order: csvtk sort -k chr:N Join multiple files by keys ( join ) All files have same key column: csvtk join -f id file1.csv file2.csv Files have different key columns: csvtk join -f \"username;username;name\" names.csv phone.csv adress.csv -k Filter by numbers ( filter ) Single field: csvtk filter -f \"id>0\" Multiple fields : csvtk filter -f \"1-3>0\" Using --any to print record if any of the field satisfy the condition: csvtk filter -f \"1-3>0\" --any fuzzy fields : csvtk filter -F -f \"A*!=0\" Filter rows by awk-like arithmetic/string expressions ( filter2 ) Using field index: csvtk filter2 -f '$3>0' Using column names: csvtk filter2 -f '$id > 0' Both arithmetic and string expressions: csvtk filter2 -f '$id > 3 || $username==\"ken\"' More complicated: csvtk filter2 -H -t -f '$1 > 2 && $2 % 2 == 0' Ploting plot histogram with data of the second column: csvtk -t plot hist testdata/grouped_data.tsv.gz -f 2 | display plot boxplot with data of the \"GC Content\" (third) column, group information is the \"Group\" column. csvtk -t plot box testdata/grouped_data.tsv.gz -g \"Group\" \\ -f \"GC Content\" --width 3 | display plot horiz boxplot with data of the \"Length\" (second) column, group information is the \"Group\" column. csvtk -t plot box testdata/grouped_data.tsv.gz -g \"Group\" -f \"Length\" \\ --height 3 --width 5 --horiz --title \"Horiz box plot\" | display plot line plot with X-Y data csvtk -t plot line testdata/xy.tsv -x X -y Y -g Group | display plot scatter plot with X-Y data csvtk -t plot line testdata/xy.tsv -x X -y Y -g Group --scatter | display","title":"Examples"},{"location":"#acknowledgements","text":"We are grateful to Zhiluo Deng and Li Peng for suggesting features and reporting bugs. Thanks Albert Vilella for features suggestion, which makes csvtk feature-rich\u3002","title":"Acknowledgements"},{"location":"#contact","text":"Create an issue to report bugs, propose new functions or ask for help. Or leave a comment .","title":"Contact"},{"location":"#license","text":"MIT License","title":"License"},{"location":"#starchart","text":"","title":"Starchart"},{"location":"bioinf/","text":"","title":"Bioinf"},{"location":"chinese/","text":"\u5982\u540c\u751f\u7269\u4fe1\u606f\u9886\u57df\u4e2d\u7684FASTA/Q\u683c\u5f0f\u4e00\u6837\uff0cCSV/TSV\u4f5c\u4e3a\u8ba1\u7b97\u673a\u3001\u6570\u636e\u79d1\u5b66\u548c\u751f\u7269\u4fe1\u606f\u7684\u57fa\u672c\u683c\u5f0f\uff0c\u5e94\u7528\u975e\u5e38\u5e7f\u6cdb\u3002\u5e38\u7528\u7684\u5904\u7406\u8f6f\u4ef6\u5305\u62ec\uff1a \u4ee5\u5fae\u8f6fExcel\u4e3a\u4ee3\u8868\u7684\u7535\u5b50\u8868\u683c\u8f6f\u4ef6 Notepad++/SublimeText\u7b49\u6587\u672c\u7f16\u8f91\u5668 sed/awk/cut\u7b49Shell\u547d\u4ee4 \u5404\u79cd\u7f16\u7a0b\u8bed\u8a00\u7684\u6570\u636e\u5904\u7406\u5e93\u3002 \u7136\u800c\uff0c\u7535\u5b50\u8868\u683c\u8f6f\u4ef6\u548c\u6587\u672c\u7f16\u8f91\u5668\u56fa\u7136\u5f3a\u5927\uff0c\u4f46\u4f9d\u8d56\u9f20\u6807\u64cd\u4f5c\uff0c\u4e0d\u9002\u5408\u6279\u91cf\u5904\u7406\uff1b sed/awk/cut\u7b49Shell\u547d\u4ee4\u4e3b\u8981\u7528\u4e8e\u901a\u7528\u7684\u8868\u683c\u6570\u636e\uff0c\u4e0d\u9002\u5408\u542b\u6709\u6807\u9898\u884c\u7684CSV\u683c\u5f0f \uff1b \u4e3a\u4e86\u4e00\u4e2a\u5c0f\u64cd\u4f5c\u5199Python/R\u811a\u672c\u4e5f\u6709\u70b9\u5c0f\u9898\u5927\u4f5c\uff0c\u4e14\u96be\u4ee5\u590d\u7528 \u3002 \u5f00\u53d1csvtk\u524d\u73b0\u6709\u7684\u5de5\u5177\u4e3b\u8981\u662fPython\u5199\u7684csvkit\uff0cRust\u5199\u7684xsv\uff0cC\u8bed\u8a00\u5199\u7684miller\uff0c\u90fd\u5404\u6709\u4f18\u52a3\u3002\u5f53\u65f6\u6211\u521a\u5f00\u53d1\u5b8cseqkit\uff0c\u6295\u6587\u7ae0\u8fc7\u7a0b\u4e2d\u65f6\u95f4\u5145\u8db3\uff0c\u4fbf\u60f3\u8d81\u70ed\u518d\u9020\u4e00\u4e2a\u8f6e\u5b50\u3002 \u6240\u4ee5\u6211\u51b3\u5b9a\u5199\u4e00\u4e2a\u547d\u4ee4\u884c\u5de5\u5177\u6765\u6ee1\u8db3CSV/TSV\u683c\u5f0f\u7684\u5e38\u89c1\u64cd\u4f5c\uff0c\u8fd9\u5c31\u662fcsvtk\u4e86\u3002 \u4ecb\u7ecd \u57fa\u672c\u4fe1\u606f \u5de5\u5177\u7c7b\u578b: \u547d\u4ee4\u884c\u5de5\u5177\uff0c\u5b50\u547d\u4ee4\u7ed3\u6784 \u652f\u6301\u683c\u5f0f: CSV/TSV, plain/gzip-compressed \u7f16\u7a0b\u8bed\u8a00: Go \u652f\u6301\u5e73\u53f0: Linux, OS X\uff0c Windows \u7b49 \u53d1\u5e03\u65b9\u5f0f: \u5355\u4e00\u53ef\u6267\u884c\u4e8c\u8fdb\u5236\u6587\u4ef6\uff0c\u4e0b\u8f7d\u5373\u7528 \u53d1\u5e03\u5e73\u53f0: Github, Bioconda \u9879\u76ee\u4e3b\u9875: http://bioinf.shenwei.me/csvtk/ \u5f00\u6e90\u5730\u5740: https://github.com/shenwei356/csvtk \u7279\u6027 \u8de8\u5e73\u53f0 \u8f7b\u91cf\uff0c\u65e0\u4efb\u4f55\u4f9d\u8d56\uff0c\u65e0\u9700\u7f16\u8bd1\u3001\u914d\u7f6e\uff0c\u4e0b\u8f7d\u5373\u7528 \u5feb\u901f \u652f\u6301stdin\u548cgzip\u538b\u7f29\u7684\u8f93\u5165\u548c\u8f93\u51fa\u6587\u4ef6\uff0c\u4fbf\u4e8e\u6d41\u5904\u7406 27\u4e2a\u5b50\u547d\u4ee4\u63d0\u4f9b\u591a\u79cd\u5b9e\u7528\u7684\u529f\u80fd\uff0c\u4e14\u80fd\u901a\u8fc7\u547d\u4ee4\u884c\u7ba1\u9053\u7ec4\u5408 \u652f\u6301Bash\u81ea\u52a8\u8865\u5168 \u652f\u6301\u7b80\u5355\u7684\u7ed8\u56fe \u529f\u80fd \u5728\u5f00\u53d1csvtk\u4e4b\u524d\u7684\u4e24\u4e09\u5e74\u95f4\uff0c\u6211\u5df2\u7ecf\u5199\u4e86\u51e0\u4e2a\u53ef\u4ee5\u590d\u7528\u7684Python/Perl\u811a\u672c\uff08https://github.com/shenwei356/datakit\uff09 \uff0c\u5305\u62eccsv2tab\u3001csvtk_grep\u3001csv_join\u3001csv_melt\uff0cintersection\uff0cunique\u3002\u6240\u4ee5\u6211\u7684\u8ba1\u5212\u662f\u9996\u5148\u96c6\u6210\u8fd9\u4e9b\u5df2\u6709\u7684\u529f\u80fd\uff0c\u968f\u540e\u6839\u636e\u9700\u6c42\u8fdb\u884c\u6269\u5c55\u3002 \u5230\u76ee\u524d\u4e3a\u6b62\uff0ccsvtk\u5df2\u670927\u4e2a\u5b50\u547d\u4ee4\uff0c\u5206\u4e3a\u4ee5\u4e0b\u51e0\u5927\u7c7b\uff1a \u4fe1\u606f headers \u76f4\u89c2\u6253\u5370\u6807\u9898\u884c\uff08 \u64cd\u4f5c\u5217\u6570\u8f83\u591a\u7684CSV\u524d\u4f7f\u7528\u6700\u4f73 \uff09 stats \u57fa\u672c\u7edf\u8ba1 stats2 \u5bf9\u9009\u5b9a\u7684\u6570\u503c\u5217\u8fdb\u884c\u57fa\u672c\u7edf\u8ba1 \u683c\u5f0f\u8f6c\u5316 pretty \u8f6c\u4e3a\u7f8e\u89c2\u3001\u53ef\u8bfb\u6027\u5f3a\u7684\u683c\u5f0f\uff08 \u6700\u5e38\u7528\u547d\u4ee4\u4e4b\u4e00 \uff09 csv2tab \u8f6cCSV\u4e3a\u5236\u8868\u7b26\u5206\u5272\u683c\u5f0f\uff08TSV\uff09 tab2csv \u8f6cTSV\u4e3aCSV space2tab \u8f6c\u7a7a\u683c\u5206\u5272\u683c\u5f0f\u4e3aTSV transpose \u8f6c\u7f6eCSV/TSV csv2md \u8f6cCSV/TSV\u4e3amakrdown\u683c\u5f0f\uff08 \u5199\u6587\u6863\u5e38\u7528 \uff09 \u96c6\u5408\u64cd\u4f5c head \u6253\u5370\u524dN\u6761\u8bb0\u5f55 sample \u6309\u6bd4\u4f8b\u968f\u673a\u91c7\u6837 cut \u9009\u62e9\u7279\u5b9a\u5217\uff0c\u652f\u6301 \u6309\u5217\u6216\u5217\u540d\u8fdb\u884c\u57fa\u672c\u9009\u62e9\u3001\u8303\u56f4\u9009\u62e9\u3001\u6a21\u7cca\u9009\u62e9\u3001\u8d1f\u5411\u9009\u62e9 \uff08 \u6700\u5e38\u7528\u547d\u4ee4\u4e4b\u4e00\uff0c\u975e\u5e38\u5f3a\u5927 \uff09 uniq \u65e0\u987b\u6392\u5e8f\uff0c\u8fd4\u56de\u6309\u6307\u5b9a\uff08\u591a\uff09\u5217\u4f5c\u4e3akey\u7684\u552f\u4e00\u8bb0\u5f55\uff08\u597d\u7ed5\u3002\u3002\uff09 freq \u6309\u6307\u5b9a\uff08\u591a\uff09\u5217\u8fdb\u884c\u8ba1\u6570\uff08 \u5e38\u7528 \uff09 inter \u591a\u4e2a\u6587\u4ef6\u95f4\u7684\u4ea4\u96c6 grep \u6307\u5b9a\uff08\u591a\uff09\u5217\u4e3aKey\u8fdb\u884c\u641c\u7d22\uff08 \u6700\u5e38\u7528\u547d\u4ee4\u4e4b\u4e00\uff0c\u53ef\u6309\u6307\u5b9a\u5217\u641c\u7d22 \uff09 filter \u6309\u6307\u5b9a\uff08\u591a\uff09\u5217\u7684\u6570\u503c\u8fdb\u884c\u8fc7\u6ee4 filter2 \u7528\u7c7b\u4f3cawk\u7684\u6570\u503c/\u8868\u8fbe\u5f0f\uff0c\u6309\u6307\u5b9a\uff08\u591a\uff09\u5217\u7684\u6570\u503c\u8fdb\u884c\u8fc7\u6ee4 join \u5408\u5e76\u591a\u4e2a\u6587\u4ef6\uff08 \u5e38\u7528 \uff09 \u7f16\u8f91 rename \u76f4\u63a5\u91cd\u547d\u540d\u6307\u5b9a\uff08\u591a\uff09\u5217\u540d\uff08 \u7b80\u5355\u800c\u5b9e\u7528 \uff09 rename2 \u4ee5\u6b63\u5219\u8868\u8fbe\u5f0f\u91cd\u547d\u540d\u6307\u5b9a\uff08\u591a\uff09\u5217\u540d\uff08 \u7b80\u5355\u800c\u5b9e\u7528 \uff09 replace \u4ee5\u6b63\u5219\u8868\u8fbe\u5f0f\u5bf9\u6307\u5b9a\uff08\u591a\uff09\u5217\u8fdb\u884c\u66ff\u6362\u7f16\u8f91\uff08 \u6700\u5e38\u7528\u547d\u4ee4\u4e4b\u4e00\uff0c\u53ef\u6309\u6307\u5b9a\u5217\u7f16\u8f91 \uff09 mutate \u4ee5\u6b63\u5219\u8868\u8fbe\u5f0f\u57fa\u4e8e\u5df2\u6709\u5217\u521b\u5efa\u65b0\u7684\u4e00\u5217\uff08 \u5e38\u7528\u4e8e\u751f\u6210\u591a\u5217\u6d4b\u8bd5\u6570\u636e \uff09 mutate2 \u7528\u7c7b\u4f3cawk\u7684\u6570\u503c/\u8868\u8fbe\u5f0f\uff0c\u4ee5\u6b63\u5219\u8868\u8fbe\u5f0f\u57fa\u4e8e\u5df2\u6709\uff08\u591a\uff09\u5217\u521b\u5efa\u65b0\u7684\u4e00\u5217\uff08 \u5e38\u7528 \uff09 gather \u7c7b\u4f3c\u4e8eR\u91cc\u9762tidyr\u5305\u7684gather\u65b9\u6cd5 \u6392\u5e8f sort \u6309\u6307\u5b9a\uff08\u591a\uff09\u5217\u8fdb\u884c\u6392\u5e8f \u7ed8\u56fe plot \u57fa\u672c\u7ed8\u56fe plot hist histogram plot box boxplot plot line line plot and scatter plot \u5176\u5b83 version \u7248\u672c\u4fe1\u606f\u548c\u68c0\u67e5\u65b0\u7248\u672c genautocomplete \u751f\u6210\u652f\u6301Bash\u81ea\u52a8\u8865\u5168\u7684\u914d\u7f6e\u6587\u4ef6\uff0c\u91cd\u542fTerminal\u751f\u6548\u3002 \u4f7f\u7528 \u8f93\u5165\u6570\u636e\u8981\u6c42\u6bcf\u884c\u7684\u5217\u6570\u4e00\u81f4\uff0c\u7a7a\u884c\u4e5f\u4f1a\u62a5\u9519 csvtk\u9ed8\u8ba4\u8f93\u5165\u6570\u636e\u542b\u6709\u6807\u9898\u884c\uff0c\u5982\u6ca1\u6709\u8bf7\u5f00\u542f\u5168\u5c40\u53c2\u6570 -H csvtk\u9ed8\u8ba4\u8f93\u5165\u6570\u636e\u4e3aCSV\u683c\u5f0f\uff0c\u5982\u4e3aTSV\u8bf7\u5f00\u542f\u5168\u5c40\u53c2\u6570 -t \u8f93\u5165\u6570\u636e\u5217\u540d\u6700\u597d\u552f\u4e00\u65e0\u91cd\u590d \u5982\u679cTSV\u4e2d\u5b58\u5728\u53cc\u5f15\u53f7 \"\" \uff0c\u8bf7\u5f00\u542f\u5168\u5c40\u53c2\u6570 -l csvtk\u9ed8\u8ba4\u4ee5 # \u5f00\u59cb\u7684\u4e3a\u6ce8\u91ca\u884c\uff0c\u82e5\u6807\u9898\u884c\u542b # \uff0c\u8bf7\u7ed9\u5168\u5c40\u53c2\u6570 -C \u6307\u5b9a\u53e6\u4e00\u4e2a\u4e0d\u5e38\u89c1\u7684\u5b57\u7b26\uff08\u5982 $ \uff09 \u4f8b\u5b50 \u4ec5\u63d0\u4f9b\u5c11\u91cf\u4f8b\u5b50\uff0c\u66f4\u591a\u4f8b\u5b50\u8bf7\u770b\u4f7f\u7528\u624b\u518c http://bioinf.shenwei.me/csvtk/usage/ \u3002 \u793a\u4f8b\u6570\u636e $ cat names.csv id,first_name,last_name,username 11,\"Rob\",\"Pike\",rob 2,Ken,Thompson,ken 4,\"Robert\",\"Griesemer\",\"gri\" 1,\"Robert\",\"Thompson\",\"abc\" NA,\"Robert\",\"Abel\",\"123\" \u589e\u5f3a\u53ef\u8bfb\u6027 $ cat names.csv | csvtk pretty id first_name last_name username 11 Rob Pike rob 2 Ken Thompson ken 4 Robert Griesemer gri 1 Robert Thompson abc NA Robert Abel 123 \u8f6c\u4e3amarkdown $ cat names.csv | csvtk csv2md id |first_name|last_name|username :--|:---------|:--------|:------- 11 |Rob |Pike |rob 2 |Ken |Thompson |ken 4 |Robert |Griesemer|gri 1 |Robert |Thompson |abc NA |Robert |Abel |123 \u6548\u679c id first_name last_name username 11 Rob Pike rob 2 Ken Thompson ken 4 Robert Griesemer gri 1 Robert Thompson abc NA Robert Abel 123 \u7528\u5217\u6216\u5217\u540d\u6765\u9009\u62e9\u6307\u5b9a\u5217\uff0c\u53ef\u6539\u53d8\u5217\u7684\u987a\u5e8f $ cat names.csv | csvtk cut -f 3,1 | csvtk pretty $ cat names.csv | csvtk cut -f last_name,id | csvtk pretty last_name id Pike 11 Thompson 2 Griesemer 4 Thompson 1 Abel NA \u7528\u901a\u914d\u7b26\u9009\u62e9\u591a\u5217 $ cat names.csv | csvtk cut -F -f '*name,id' | csvtk pretty first_name last_name username id Rob Pike rob 11 Ken Thompson ken 2 Robert Griesemer gri 4 Robert Thompson abc 1 Robert Abel 123 NA \u5220\u9664\u7b2c2\uff0c3\u5217\uff08 \u4e0b\u5217\u7b2c\u4e8c\u79cd\u65b9\u6cd5\u662f\u9009\u5b9a\u8303\u56f4\uff0c\u4f46-3\u5728\u524d,-2\u5728\u540e \uff09 $ cat names.csv | csvtk cut -f -2,-3 | csvtk pretty $ cat names.csv | csvtk cut -f -3--2 | csvtk pretty $ cat names.csv | csvtk cut -f -first_name,-last_name | csvtk pretty id username 11 rob 2 ken 4 gri 1 abc NA 123 \u6309\u6307\u5b9a\u5217\u641c\u7d22\uff0c \u9ed8\u8ba4\u7cbe\u786e\u5339\u914d $ cat names.csv | csvtk grep -f id -p 1 | csvtk pretty id first_name last_name username 1 Robert Thompson abc \u6a21\u7cca\u641c\u7d22\uff08\u6b63\u5219\u8868\u8fbe\u5f0f\uff09 $ cat names.csv | csvtk grep -f id -p 1 -r | csvtk pretty id first_name last_name username 11 Rob Pike rob 1 Robert Thompson abc \u7528\u6587\u4ef6\u4f5c\u4e3a\u6a21\u5f0f\u6765\u6e90 $ cat names.csv | csvtk grep -f id -P id-files.txt \u5bf9\u6307\u5b9a\u5217\u505a\u7b80\u5355\u66ff\u6362 $ cat names.csv | csvtk replace -f id -p '(\\d+)' -r 'ID: $1' \\ | csvtk pretty id first_name last_name username ID: 11 Rob Pike rob ID: 2 Ken Thompson ken ID: 4 Robert Griesemer gri ID: 1 Robert Thompson abc NA Robert Abel 123 \u7528key-value\u6587\u4ef6\u6765\u66ff\u6362\uff08seqkit\u548cbrename\u90fd\u652f\u6301\u7c7b\u4f3c\u64cd\u4f5c\uff09 $ cat data.tsv name id A ID001 B ID002 C ID004 $ cat alias.tsv 001 Tom 002 Bob 003 Jim $ csvtk replace -t -f 2 -p \"ID(.+)\" -r \"N: {nr}, alias: {kv}\" -k \\ alias.tsv data.tsv name id A N: 1, alias: Tom B N: 2, alias: Bob C N: 3, alias: 004 \u5408\u5e76\u8868\u683c\uff0c\u9700\u8981\u5206\u522b\u6307\u5b9a\u5404\u6587\u4ef6\u4e2d\u7684key\u5217\uff1a\u9ed8\u8ba4\u5747\u4e3a\u7b2c\u4e00\u5217\uff1b\u82e5\u5217\uff08\u540d\uff09\u76f8\u540c\u63d0\u4f9b\u4e00\u4e2a\uff1b\u82e5\u4e0d\u540c\u7528\u5206\u53f7\u5206\u5272 $ cat testdata/phones.csv username,phone gri,11111 rob,12345 ken,22222 shenwei,999999 $ csvtk join -f 'username;username' --keep-unmatched names.csv phones.csv \\ | csvtk pretty id first_name last_name username phone 11 Rob Pike rob 12345 2 Ken Thompson ken 22222 4 Robert Griesemer gri 11111 1 Robert Thompson abc NA Robert Abel 123","title":"\u4e2d\u6587\u4ecb\u7ecd"},{"location":"chinese/#_1","text":"\u57fa\u672c\u4fe1\u606f \u5de5\u5177\u7c7b\u578b: \u547d\u4ee4\u884c\u5de5\u5177\uff0c\u5b50\u547d\u4ee4\u7ed3\u6784 \u652f\u6301\u683c\u5f0f: CSV/TSV, plain/gzip-compressed \u7f16\u7a0b\u8bed\u8a00: Go \u652f\u6301\u5e73\u53f0: Linux, OS X\uff0c Windows \u7b49 \u53d1\u5e03\u65b9\u5f0f: \u5355\u4e00\u53ef\u6267\u884c\u4e8c\u8fdb\u5236\u6587\u4ef6\uff0c\u4e0b\u8f7d\u5373\u7528 \u53d1\u5e03\u5e73\u53f0: Github, Bioconda \u9879\u76ee\u4e3b\u9875: http://bioinf.shenwei.me/csvtk/ \u5f00\u6e90\u5730\u5740: https://github.com/shenwei356/csvtk \u7279\u6027 \u8de8\u5e73\u53f0 \u8f7b\u91cf\uff0c\u65e0\u4efb\u4f55\u4f9d\u8d56\uff0c\u65e0\u9700\u7f16\u8bd1\u3001\u914d\u7f6e\uff0c\u4e0b\u8f7d\u5373\u7528 \u5feb\u901f \u652f\u6301stdin\u548cgzip\u538b\u7f29\u7684\u8f93\u5165\u548c\u8f93\u51fa\u6587\u4ef6\uff0c\u4fbf\u4e8e\u6d41\u5904\u7406 27\u4e2a\u5b50\u547d\u4ee4\u63d0\u4f9b\u591a\u79cd\u5b9e\u7528\u7684\u529f\u80fd\uff0c\u4e14\u80fd\u901a\u8fc7\u547d\u4ee4\u884c\u7ba1\u9053\u7ec4\u5408 \u652f\u6301Bash\u81ea\u52a8\u8865\u5168 \u652f\u6301\u7b80\u5355\u7684\u7ed8\u56fe","title":"\u4ecb\u7ecd"},{"location":"chinese/#_2","text":"\u5728\u5f00\u53d1csvtk\u4e4b\u524d\u7684\u4e24\u4e09\u5e74\u95f4\uff0c\u6211\u5df2\u7ecf\u5199\u4e86\u51e0\u4e2a\u53ef\u4ee5\u590d\u7528\u7684Python/Perl\u811a\u672c\uff08https://github.com/shenwei356/datakit\uff09 \uff0c\u5305\u62eccsv2tab\u3001csvtk_grep\u3001csv_join\u3001csv_melt\uff0cintersection\uff0cunique\u3002\u6240\u4ee5\u6211\u7684\u8ba1\u5212\u662f\u9996\u5148\u96c6\u6210\u8fd9\u4e9b\u5df2\u6709\u7684\u529f\u80fd\uff0c\u968f\u540e\u6839\u636e\u9700\u6c42\u8fdb\u884c\u6269\u5c55\u3002 \u5230\u76ee\u524d\u4e3a\u6b62\uff0ccsvtk\u5df2\u670927\u4e2a\u5b50\u547d\u4ee4\uff0c\u5206\u4e3a\u4ee5\u4e0b\u51e0\u5927\u7c7b\uff1a \u4fe1\u606f headers \u76f4\u89c2\u6253\u5370\u6807\u9898\u884c\uff08 \u64cd\u4f5c\u5217\u6570\u8f83\u591a\u7684CSV\u524d\u4f7f\u7528\u6700\u4f73 \uff09 stats \u57fa\u672c\u7edf\u8ba1 stats2 \u5bf9\u9009\u5b9a\u7684\u6570\u503c\u5217\u8fdb\u884c\u57fa\u672c\u7edf\u8ba1 \u683c\u5f0f\u8f6c\u5316 pretty \u8f6c\u4e3a\u7f8e\u89c2\u3001\u53ef\u8bfb\u6027\u5f3a\u7684\u683c\u5f0f\uff08 \u6700\u5e38\u7528\u547d\u4ee4\u4e4b\u4e00 \uff09 csv2tab \u8f6cCSV\u4e3a\u5236\u8868\u7b26\u5206\u5272\u683c\u5f0f\uff08TSV\uff09 tab2csv \u8f6cTSV\u4e3aCSV space2tab \u8f6c\u7a7a\u683c\u5206\u5272\u683c\u5f0f\u4e3aTSV transpose \u8f6c\u7f6eCSV/TSV csv2md \u8f6cCSV/TSV\u4e3amakrdown\u683c\u5f0f\uff08 \u5199\u6587\u6863\u5e38\u7528 \uff09 \u96c6\u5408\u64cd\u4f5c head \u6253\u5370\u524dN\u6761\u8bb0\u5f55 sample \u6309\u6bd4\u4f8b\u968f\u673a\u91c7\u6837 cut \u9009\u62e9\u7279\u5b9a\u5217\uff0c\u652f\u6301 \u6309\u5217\u6216\u5217\u540d\u8fdb\u884c\u57fa\u672c\u9009\u62e9\u3001\u8303\u56f4\u9009\u62e9\u3001\u6a21\u7cca\u9009\u62e9\u3001\u8d1f\u5411\u9009\u62e9 \uff08 \u6700\u5e38\u7528\u547d\u4ee4\u4e4b\u4e00\uff0c\u975e\u5e38\u5f3a\u5927 \uff09 uniq \u65e0\u987b\u6392\u5e8f\uff0c\u8fd4\u56de\u6309\u6307\u5b9a\uff08\u591a\uff09\u5217\u4f5c\u4e3akey\u7684\u552f\u4e00\u8bb0\u5f55\uff08\u597d\u7ed5\u3002\u3002\uff09 freq \u6309\u6307\u5b9a\uff08\u591a\uff09\u5217\u8fdb\u884c\u8ba1\u6570\uff08 \u5e38\u7528 \uff09 inter \u591a\u4e2a\u6587\u4ef6\u95f4\u7684\u4ea4\u96c6 grep \u6307\u5b9a\uff08\u591a\uff09\u5217\u4e3aKey\u8fdb\u884c\u641c\u7d22\uff08 \u6700\u5e38\u7528\u547d\u4ee4\u4e4b\u4e00\uff0c\u53ef\u6309\u6307\u5b9a\u5217\u641c\u7d22 \uff09 filter \u6309\u6307\u5b9a\uff08\u591a\uff09\u5217\u7684\u6570\u503c\u8fdb\u884c\u8fc7\u6ee4 filter2 \u7528\u7c7b\u4f3cawk\u7684\u6570\u503c/\u8868\u8fbe\u5f0f\uff0c\u6309\u6307\u5b9a\uff08\u591a\uff09\u5217\u7684\u6570\u503c\u8fdb\u884c\u8fc7\u6ee4 join \u5408\u5e76\u591a\u4e2a\u6587\u4ef6\uff08 \u5e38\u7528 \uff09 \u7f16\u8f91 rename \u76f4\u63a5\u91cd\u547d\u540d\u6307\u5b9a\uff08\u591a\uff09\u5217\u540d\uff08 \u7b80\u5355\u800c\u5b9e\u7528 \uff09 rename2 \u4ee5\u6b63\u5219\u8868\u8fbe\u5f0f\u91cd\u547d\u540d\u6307\u5b9a\uff08\u591a\uff09\u5217\u540d\uff08 \u7b80\u5355\u800c\u5b9e\u7528 \uff09 replace \u4ee5\u6b63\u5219\u8868\u8fbe\u5f0f\u5bf9\u6307\u5b9a\uff08\u591a\uff09\u5217\u8fdb\u884c\u66ff\u6362\u7f16\u8f91\uff08 \u6700\u5e38\u7528\u547d\u4ee4\u4e4b\u4e00\uff0c\u53ef\u6309\u6307\u5b9a\u5217\u7f16\u8f91 \uff09 mutate \u4ee5\u6b63\u5219\u8868\u8fbe\u5f0f\u57fa\u4e8e\u5df2\u6709\u5217\u521b\u5efa\u65b0\u7684\u4e00\u5217\uff08 \u5e38\u7528\u4e8e\u751f\u6210\u591a\u5217\u6d4b\u8bd5\u6570\u636e \uff09 mutate2 \u7528\u7c7b\u4f3cawk\u7684\u6570\u503c/\u8868\u8fbe\u5f0f\uff0c\u4ee5\u6b63\u5219\u8868\u8fbe\u5f0f\u57fa\u4e8e\u5df2\u6709\uff08\u591a\uff09\u5217\u521b\u5efa\u65b0\u7684\u4e00\u5217\uff08 \u5e38\u7528 \uff09 gather \u7c7b\u4f3c\u4e8eR\u91cc\u9762tidyr\u5305\u7684gather\u65b9\u6cd5 \u6392\u5e8f sort \u6309\u6307\u5b9a\uff08\u591a\uff09\u5217\u8fdb\u884c\u6392\u5e8f \u7ed8\u56fe plot \u57fa\u672c\u7ed8\u56fe plot hist histogram plot box boxplot plot line line plot and scatter plot \u5176\u5b83 version \u7248\u672c\u4fe1\u606f\u548c\u68c0\u67e5\u65b0\u7248\u672c genautocomplete \u751f\u6210\u652f\u6301Bash\u81ea\u52a8\u8865\u5168\u7684\u914d\u7f6e\u6587\u4ef6\uff0c\u91cd\u542fTerminal\u751f\u6548\u3002","title":"\u529f\u80fd"},{"location":"chinese/#_3","text":"\u8f93\u5165\u6570\u636e\u8981\u6c42\u6bcf\u884c\u7684\u5217\u6570\u4e00\u81f4\uff0c\u7a7a\u884c\u4e5f\u4f1a\u62a5\u9519 csvtk\u9ed8\u8ba4\u8f93\u5165\u6570\u636e\u542b\u6709\u6807\u9898\u884c\uff0c\u5982\u6ca1\u6709\u8bf7\u5f00\u542f\u5168\u5c40\u53c2\u6570 -H csvtk\u9ed8\u8ba4\u8f93\u5165\u6570\u636e\u4e3aCSV\u683c\u5f0f\uff0c\u5982\u4e3aTSV\u8bf7\u5f00\u542f\u5168\u5c40\u53c2\u6570 -t \u8f93\u5165\u6570\u636e\u5217\u540d\u6700\u597d\u552f\u4e00\u65e0\u91cd\u590d \u5982\u679cTSV\u4e2d\u5b58\u5728\u53cc\u5f15\u53f7 \"\" \uff0c\u8bf7\u5f00\u542f\u5168\u5c40\u53c2\u6570 -l csvtk\u9ed8\u8ba4\u4ee5 # \u5f00\u59cb\u7684\u4e3a\u6ce8\u91ca\u884c\uff0c\u82e5\u6807\u9898\u884c\u542b # \uff0c\u8bf7\u7ed9\u5168\u5c40\u53c2\u6570 -C \u6307\u5b9a\u53e6\u4e00\u4e2a\u4e0d\u5e38\u89c1\u7684\u5b57\u7b26\uff08\u5982 $ \uff09","title":"\u4f7f\u7528"},{"location":"chinese/#_4","text":"\u4ec5\u63d0\u4f9b\u5c11\u91cf\u4f8b\u5b50\uff0c\u66f4\u591a\u4f8b\u5b50\u8bf7\u770b\u4f7f\u7528\u624b\u518c http://bioinf.shenwei.me/csvtk/usage/ \u3002 \u793a\u4f8b\u6570\u636e $ cat names.csv id,first_name,last_name,username 11,\"Rob\",\"Pike\",rob 2,Ken,Thompson,ken 4,\"Robert\",\"Griesemer\",\"gri\" 1,\"Robert\",\"Thompson\",\"abc\" NA,\"Robert\",\"Abel\",\"123\" \u589e\u5f3a\u53ef\u8bfb\u6027 $ cat names.csv | csvtk pretty id first_name last_name username 11 Rob Pike rob 2 Ken Thompson ken 4 Robert Griesemer gri 1 Robert Thompson abc NA Robert Abel 123 \u8f6c\u4e3amarkdown $ cat names.csv | csvtk csv2md id |first_name|last_name|username :--|:---------|:--------|:------- 11 |Rob |Pike |rob 2 |Ken |Thompson |ken 4 |Robert |Griesemer|gri 1 |Robert |Thompson |abc NA |Robert |Abel |123 \u6548\u679c id first_name last_name username 11 Rob Pike rob 2 Ken Thompson ken 4 Robert Griesemer gri 1 Robert Thompson abc NA Robert Abel 123 \u7528\u5217\u6216\u5217\u540d\u6765\u9009\u62e9\u6307\u5b9a\u5217\uff0c\u53ef\u6539\u53d8\u5217\u7684\u987a\u5e8f $ cat names.csv | csvtk cut -f 3,1 | csvtk pretty $ cat names.csv | csvtk cut -f last_name,id | csvtk pretty last_name id Pike 11 Thompson 2 Griesemer 4 Thompson 1 Abel NA \u7528\u901a\u914d\u7b26\u9009\u62e9\u591a\u5217 $ cat names.csv | csvtk cut -F -f '*name,id' | csvtk pretty first_name last_name username id Rob Pike rob 11 Ken Thompson ken 2 Robert Griesemer gri 4 Robert Thompson abc 1 Robert Abel 123 NA \u5220\u9664\u7b2c2\uff0c3\u5217\uff08 \u4e0b\u5217\u7b2c\u4e8c\u79cd\u65b9\u6cd5\u662f\u9009\u5b9a\u8303\u56f4\uff0c\u4f46-3\u5728\u524d,-2\u5728\u540e \uff09 $ cat names.csv | csvtk cut -f -2,-3 | csvtk pretty $ cat names.csv | csvtk cut -f -3--2 | csvtk pretty $ cat names.csv | csvtk cut -f -first_name,-last_name | csvtk pretty id username 11 rob 2 ken 4 gri 1 abc NA 123 \u6309\u6307\u5b9a\u5217\u641c\u7d22\uff0c \u9ed8\u8ba4\u7cbe\u786e\u5339\u914d $ cat names.csv | csvtk grep -f id -p 1 | csvtk pretty id first_name last_name username 1 Robert Thompson abc \u6a21\u7cca\u641c\u7d22\uff08\u6b63\u5219\u8868\u8fbe\u5f0f\uff09 $ cat names.csv | csvtk grep -f id -p 1 -r | csvtk pretty id first_name last_name username 11 Rob Pike rob 1 Robert Thompson abc \u7528\u6587\u4ef6\u4f5c\u4e3a\u6a21\u5f0f\u6765\u6e90 $ cat names.csv | csvtk grep -f id -P id-files.txt \u5bf9\u6307\u5b9a\u5217\u505a\u7b80\u5355\u66ff\u6362 $ cat names.csv | csvtk replace -f id -p '(\\d+)' -r 'ID: $1' \\ | csvtk pretty id first_name last_name username ID: 11 Rob Pike rob ID: 2 Ken Thompson ken ID: 4 Robert Griesemer gri ID: 1 Robert Thompson abc NA Robert Abel 123 \u7528key-value\u6587\u4ef6\u6765\u66ff\u6362\uff08seqkit\u548cbrename\u90fd\u652f\u6301\u7c7b\u4f3c\u64cd\u4f5c\uff09 $ cat data.tsv name id A ID001 B ID002 C ID004 $ cat alias.tsv 001 Tom 002 Bob 003 Jim $ csvtk replace -t -f 2 -p \"ID(.+)\" -r \"N: {nr}, alias: {kv}\" -k \\ alias.tsv data.tsv name id A N: 1, alias: Tom B N: 2, alias: Bob C N: 3, alias: 004 \u5408\u5e76\u8868\u683c\uff0c\u9700\u8981\u5206\u522b\u6307\u5b9a\u5404\u6587\u4ef6\u4e2d\u7684key\u5217\uff1a\u9ed8\u8ba4\u5747\u4e3a\u7b2c\u4e00\u5217\uff1b\u82e5\u5217\uff08\u540d\uff09\u76f8\u540c\u63d0\u4f9b\u4e00\u4e2a\uff1b\u82e5\u4e0d\u540c\u7528\u5206\u53f7\u5206\u5272 $ cat testdata/phones.csv username,phone gri,11111 rob,12345 ken,22222 shenwei,999999 $ csvtk join -f 'username;username' --keep-unmatched names.csv phones.csv \\ | csvtk pretty id first_name last_name username phone 11 Rob Pike rob 12345 2 Ken Thompson ken 22222 4 Robert Griesemer gri 11111 1 Robert Thompson abc NA Robert Abel 123","title":"\u4f8b\u5b50"},{"location":"download/","text":"Download csvtk is implemented in Go programming language, executable binary files for most popular operating system are freely available in release page. OS Arch File, \u4e2d\u56fd\u955c\u50cf Download Count Linux 32-bit csvtk_linux_386.tar.gz , \u4e2d\u56fd\u955c\u50cf Linux 64-bit csvtk_linux_amd64.tar.gz , \u4e2d\u56fd\u955c\u50cf Linux 64-bit csvtk_linux_arm64.tar.gz , \u4e2d\u56fd\u955c\u50cf macOS 64-bit csvtk_darwin_amd64.tar.gz , \u4e2d\u56fd\u955c\u50cf macOS arm64 csvtk_darwin_arm64.tar.gz , \u4e2d\u56fd\u955c\u50cf Windows 32-bit csvtk_windows_386.exe.tar.gz , \u4e2d\u56fd\u955c\u50cf Windows 64-bit csvtk_windows_amd64.exe.tar.gz , \u4e2d\u56fd\u955c\u50cf Notes run csvtk version to check update !!! run csvtk genautocomplete to update Bash completion !!! Installation Download Page csvtk is implemented in Go programming language, executable binary files for most popular operating systems are freely available in release page. Method 1: Download binaries (latest stable/dev version) Just download compressed executable file of your operating system, and decompress it with tar -zxvf *.tar.gz command or other tools. And then: For Linux-like systems If you have root privilege simply copy it to /usr/local/bin : sudo cp csvtk /usr/local/bin/ Or copy to anywhere in the environment variable PATH : mkdir -p $HOME/bin/; cp csvtk $HOME/bin/ For windows , just copy csvtk.exe to C:\\WINDOWS\\system32 . Method 2: Install via conda (latest stable version) conda install -c bioconda csvtk Method 3: Install via homebrew (may be not the latest) brew install csvtk Method 4: For Go developer (latest stable/dev version) go get -u github.com/shenwei356/csvtk/csvtk Method 5: For ArchLinux AUR users (may be not the latest) yaourt -S csvtk Shell-completion Bash: # generate completion shell csvtk genautocomplete --shell bash # configure if never did. # install bash-completion if the \"complete\" command is not found. echo \"for bcfile in ~/.bash_completion.d/* ; do source \\$bcfile; done\" >> ~/.bash_completion echo \"source ~/.bash_completion\" >> ~/.bashrc Zsh: # generate completion shell csvtk genautocomplete --shell zsh --file ~/.zfunc/_csvtk # configure if never did echo 'fpath=( ~/.zfunc \"${fpath[@]}\" )' >> ~/.zshrc echo \"autoload -U compinit; compinit\" >> ~/.zshrc fish: csvtk genautocomplete --shell fish --file ~/.config/fish/completions/csvtk.fish Changelog csvtk v0.24.0 Incompatible changes : csvtk mutate2/summary : mutate2 : remove the option -L/--digits . use the same option -w/--decimal-width to limit floats to N decimal points. new command csvtk fmtdate : format date of selected fields. #159 csvtk grep : fix bug for searching with -r -p . . csvtk csv2rst : fix bug for data containing unicode. #137 csvtk filter2 : fix bug for date expression. #146 csvtk mutate2/filter2 : change the way of rexpression evaluation. add custom functions: len() . #153 fix bug when using two or more columns with common prefixes in column names . #173 fix value with single or double quotes. #174 csvtk cut : new flags -m/--allow-missing-col and -b/--blank-missing-col . #156 csvtk pretty : still add header row for empty column. csvtk csv2md : better format. csvtk join : new flag -n/--ignore-null . #163 csvtk v0.23.0 new comand: csvtk csv2rst for converting CSV to reStructuredText format. #137 csvtk pretty : add header separator line. #123 csvtk mutate2/summary : fix message and doc. Thanks @VladimirAlexiev #127 csvtk mutate2 : fix null coalescence: ??. #129 csvtk genautocomplete : supports bash|zsh|fish|powershell. #126 csvtk cat : fix progress bar. #130 csvtk grep : new flag immediate-output . csvtk csv2xlsx : fix bug for table with > 26 columns. 138 csvtk v0.22.0 csvtk : global flag -t does not overide -D anymore . #114 If the executable/symlink name is tsvtk the -t/--tabs option for tab input is set . Thanks @bsipos. #117 new command: csvtk csv2xlsx for converting CSV/TSV file(s) to a single .xlsx file. new command: csvtk unfold for unfolding multiple values in cells of a field. #103 rename csvtk collapse to csvtk fold , for folding multiple values of a field into cells of groups. csvtk cut : support range format 2- to choose 2nd column to the end . #106 csvtk round : fix bug of failing to round scientific notation with value small than one, e.g., 7.1E-1 . csvtk v0.21.0 new command: csvtk nrow/ncol for printing number of rows or columns. new command: round to round float to n decimal places. #112 csvtk headers : file name and column index is optional outputted with new flag -v/--verbose . csvtk dim : new flags --tabluar , --cols , --rows , -n/--no-files . csvtk dim/ncol/nrow : can handle empty files now. #108 csvtk csv2json #104 : new flag -b/--blank : do not convert \"\", \"na\", \"n/a\", \"none\", \"null\", \".\" to null new flag -n/--parse-num : parse numeric values for nth column(s), multiple values are supported and \"a\"/\"all\" for all columns. csvtk xlsx2csv : fix output for ragged table. #110 csvtk join : fix bug for joining >2 files. csvtk uniq : new flag -n/--keep-n for keeping first N records of every key. csvtk cut : support repeatedly selecting columns. #106 csvtk v0.20.0 new command csvtk comb : compute combinations of items at every row. new command csvtk sep : separate column into multiple columns. #96 csvtk : list lines' number of illegal ( -I ) and empty ( -E ) rows. #97 new flag --infile-list for giving file of input files list (one file per line), if given, they are appended to files from cli arguments csvtk join : reenable flag -i/--ignore-case . #99 outer join is supported . #23 new flag -L/--left-join : left join, equals to -k/--keep-unmatched, exclusive with --outer-join new flag -O/--outer-join : outer join, exclusive with --left-join rename flag --fill to --na . csvtk filter2 : fix bug when column names start with digits, e.g., 1000g2015aug . Thank @VorontsovIE ( #44 ) csvtk concat : allow one input file. #98 csvtk mutate : new flag -R/--remove for removing input column. csvtk v0.19.1 csvtk : fix checking file existence. show friendly error message when giving empty field like csvtk cut -f a, b . csvtk summary : fix err of q1 and q3. #90 csvtk version : making checking update optional. csvtk v0.19.0 new commands by @bsipos : watch : online monitoring and histogram of selected field. corr : calculate Pearson correlation between numeric columns. cat : stream file and report progress. csvtk split : fix bug of repeatedly output header line when number of output files exceed value of --buf-groups . #83 csvtk plot hist : new option --percentiles to add percentiles to histogram x label. #88 csvtk v0.18.2 csvtk replace/rename2/splitxlsx : fix flag conflicts with global flag -I since v0.18.0. csvtk replace/rename2 : removing shorthand flag -I for --key-capt-idx . csvtk splitxlsx : changing shorthand flag of --sheet-index from -I to -N . csvtk v0.18.1 csvtk sort : fix mutiple-key-sort containing natural order sorting. #79 csvtk xlsx2csv : reacts to global flags -t , -T , -D and -E . #78 csvtk v0.18.0 csvtk : add new flag --ignore-illegal-row to skip illegal rows. #72 csvtk summary : add more textual/numeric operations. #64 csvtk sort : fix bug for sorting by columns with empty values. #70 csvtk grep : add new flag --delete-matched to delete a pattern right after being matched, this keeps the firstly matched data and speedups when using regular expressions. #77 csvtk v0.17.0 new command: csvtk add-header and csvtk del-header for adding/deleting column names. [#62] csvtk v0.16.0 new command: csvtk csv2json : convert CSV to JSON format. remove comand: csvtk stats2 . new command csvtk summary : summary statistics of selected digital fields (groupby group fields), usage and examples . #59 csvtk replace : add flag --nr-width : minimum width for {nr} in flag -r/--replacement. e.g., formating \"1\" to \"001\" by --nr-width 3 (default 1) csvtk rename2/replace : add flag -A, --kv-file-all-left-columns-as-value , for treating all columns except 1th one as value for kv-file with more than 2 columns. #56 csvtk v0.15.0 csvtk : add global flag -E/--ignore-empty-row to skip empty row. #50 csvtk mutate2 : add flag -s/--digits-as-string for not converting big digits into scientific notation. #46 csvtk sort : add support for sorting in natural order. #49 csvtk v0.14.0 csvtk : supporting multi-line fields by replacing multicorecsv with standard library encoding/csv , while losing support for metaline which was supported since v0.7.0 . It also gain a little speedup. csvtk sample : add flag -n/--line-number to print line number as the first column (\"n\") csvtk filter2 : fix bug when column names start with digits, e.g., 1000g2015aug ( #44 ) csvtk rename2 : add support for similar repalecement symbols {kv} and {nr} in csvtk replace csvtk v0.13.0 new command concat for concatenating CSV/TSV files by rows #38 csvtk : add support for environment variables for frequently used global flags #39 CSVTK_T for flag -t/--tabs CSVTK_H for flag -H/--no-header-row mutate2 : add support for eval expression WITHOUT column index symbol, so we can add some string constants #37 pretty : better support for files with duplicated column names csvtk v0.12.0 new command collapse : collapsing one field with selected fields as keys freq : keeping orignal order of keys by default split : performance improvement add option -G/--out-gzip for forcing output gzipped file csvtk v0.11.0 add command split to split CSV/TSV into multiple files according to column values add command splitxlxs to split XLSX sheet into multiple sheets according to column values csvtk , automatically check BOM (byte-order mark) and discard it csvtk v0.10.0 add subcommand xlsx2csv to convert XLSX to CSV format grep , filter , filter2 : add flag -n/--line-number to print line-number as the first column cut : add flag -i/--ignore-case to ignore case of column name csvtk v0.9.1 csvtk replace : fix bug when replacing with key-value pairs brought in v0.8.0 csvtk v0.9.0 add subcommand csvtk mutate2 : create new column from selected fields by awk-like arithmetic/string expressions add new command genautocomplete to generate shell autocompletion script! csvtk v0.8.0 new command csvtk gather for gathering columns into key-value pairs . csvtk sort : support sorting by user-defined order . fix bug of unselecting field : wrongly reporting error of fields not existing. affected commands: cut , filter , fitler2 , freq , grep , inter , mutate , rename , rename2 , replace , stats2 , uniq . update help message of flag -F/--fuzzy-fields . update help message of global flag -t , which overrides both -d and -D . If you want other delimiter for tabular input, use -t $'\\t' -D \"delimiter\" . csvtk v0.7.1 csvtk plot box and csvtk plot line : fix bugs for special cases of input compile with go1.8.1 csvtk v0.7.0 fig bug of \"stricter field checking\" in v0.6.0 and v0.6.1 when using flag -F/--fuzzy-fields csvtk pretty and csvtk csv2md : add attention that these commands treat the first row as header line and require them to be unique. csvtk stat renamed to csvtk stats , old name is still available as an alias. csvtk stat2 renamed to csvtk stats2 , old name is still available as an alias. issues/13 seamlessly support for data with meta line of separator declaration used by MS Excel . csvtk v0.6.1 csvtk cut : minor bug: panic when no fields given. i.e., csvtk cut . All relevant commands have been fixed. csvtk v0.6.0 csvtk grep : large performance improvement by discarding goroutine (multiple threads), and keeping output in order of input . Better column name checking and stricter field checking, fields out of range are not ignored now . Affected commands include cut , filter , freq , grep , inter , mutate , rename , rename2 , replace , stat2 , and uniq . New command: csvtk filter2 , filtering rows by arithmetic/string expressions like awk . csvtk v0.5.0 csvtk cut : delete flag -n/--names , move it to a new command csvtk headers new command: csvtk headers new command: csvtk head new command: csvtk sample csvtk v0.4.6 csvtk grep : fix result highlight when flag -v is on. csvtk v0.4.5 csvtk join : support the 2nd or later files with entries with same ID. csvtk v0.4.4 add command csvtk freq : frequencies of selected fields add lots of examples in usage page csvtk v0.4.3 improvement of using experience: flag -n is not required anymore when flag -H in csvtk mutate csvtk v0.4.2 fix highlight bug of csvtk grep : if the pattern matches multiple parts, the text will be wrongly edited. changes: disable highlight when pattern file given. change the default output of all ploting commands to STDOUT, now you can pipe the image to \"display\" command of Imagemagic. csvtk v0.4.1 Nothing changed. Just fix the links due to inappropriate deployment of v0.4.0 csvtk v0.4.0 add flag for csvtk replace : -K ( --keep-key ) keep the key as value when no value found for the key. This is open in default in previous versions. csvtk v0.3.9 fix bug: header row incomplete in csvtk sort result csvtk v0.3.8.1 fix bug of flag parsing library pflag , detail . The bug affected the csvtk grep -r -p , when value of -p contain \"[\" and \"]\" at the beginning or end, they are wrongly parsed. csvtk v0.3.8 new feature: csvtk cut supports ordered fields output. e.g., csvtk cut -f 2,1 outputs the 2nd column in front of 1th column. new commands: csvtk plot can plot three types of plots by subcommands: csvtk plot hist : histogram csvtk plot box : boxplot csvtk plot line : line plot and scatter plot csvtk v0.3.7 fix a serious bug of using negative field of column name, e.g. -f \"-id\" csvtk v0.3.6 csvtk replace support replacement symbols {nr} (record number) and {kv} (corresponding value of the key ($1) by key-value file) csvtk v0.3.5.2 add flag --fill for csvtk join , so we can fill the unmatched data fix typo csvtk v0.3.5.1 fix minor bug of reading lines ending with \\r\\n from a dependency package csvtk v0.3.5 fix minor bug of csv2md add subcommand version which could check for update csvtk v0.3.4 fix bug of csvtk replace that head row should not be edited. csvtk v0.3.3 fix bug of csvtk grep -t -P csvtk v0.3.2 fix bug of inter csvtk v0.3.1 add support of search multiple fields for grep csvtk v0.3 add subcommand csv2md csvtk v0.2.9 add more flags to subcommand pretty fix bug of csvtk cut -n add subcommand filter csvtk v0.2.8 add subcommand pretty -- convert CSV to readable aligned table csvtk v0.2.7 fix highlight failing in windows csvtk v0.2.6 fix one error message of grep highlight matched fields in result of grep csvtk v0.2.5 fix bug of stat that failed to considerate files with header row add subcommand stat2 - summary of selected number fields make the output of stat prettier csvtk v0.2.4 fix bug of handling comment lines add some notes before using csvtk csvtk v0.2.3 add flag --colnames to cut flag -f ( --fields ) of join supports single value now csvtk v0.2.2 add flag --keep-unmathed to join csvtk v0.2 finish almost functions csvtk v0.2.1 fix bug of mutate /** * RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS. * LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables */ /* var disqus_config = function () { this.page.url = PAGE_URL; // Replace PAGE_URL with your page's canonical URL variable this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable }; */ (function() { // DON'T EDIT BELOW THIS LINE var d = document, s = d.createElement('script'); s.src = '//csvtk.disqus.com/embed.js'; s.setAttribute('data-timestamp', +new Date()); (d.head || d.body).appendChild(s); })(); Please enable JavaScript to view the comments powered by Disqus.","title":"Download"},{"location":"download/#download","text":"csvtk is implemented in Go programming language, executable binary files for most popular operating system are freely available in release page. OS Arch File, \u4e2d\u56fd\u955c\u50cf Download Count Linux 32-bit csvtk_linux_386.tar.gz , \u4e2d\u56fd\u955c\u50cf Linux 64-bit csvtk_linux_amd64.tar.gz , \u4e2d\u56fd\u955c\u50cf Linux 64-bit csvtk_linux_arm64.tar.gz , \u4e2d\u56fd\u955c\u50cf macOS 64-bit csvtk_darwin_amd64.tar.gz , \u4e2d\u56fd\u955c\u50cf macOS arm64 csvtk_darwin_arm64.tar.gz , \u4e2d\u56fd\u955c\u50cf Windows 32-bit csvtk_windows_386.exe.tar.gz , \u4e2d\u56fd\u955c\u50cf Windows 64-bit csvtk_windows_amd64.exe.tar.gz , \u4e2d\u56fd\u955c\u50cf Notes run csvtk version to check update !!! run csvtk genautocomplete to update Bash completion !!!","title":"Download"},{"location":"download/#installation","text":"Download Page csvtk is implemented in Go programming language, executable binary files for most popular operating systems are freely available in release page.","title":"Installation"},{"location":"download/#method-1-download-binaries-latest-stabledev-version","text":"Just download compressed executable file of your operating system, and decompress it with tar -zxvf *.tar.gz command or other tools. And then: For Linux-like systems If you have root privilege simply copy it to /usr/local/bin : sudo cp csvtk /usr/local/bin/ Or copy to anywhere in the environment variable PATH : mkdir -p $HOME/bin/; cp csvtk $HOME/bin/ For windows , just copy csvtk.exe to C:\\WINDOWS\\system32 .","title":"Method 1: Download binaries (latest stable/dev version)"},{"location":"download/#method-2-install-via-conda-latest-stable-version","text":"conda install -c bioconda csvtk","title":"Method 2: Install via conda (latest stable version)"},{"location":"download/#method-3-install-via-homebrew-may-be-not-the-latest","text":"brew install csvtk","title":"Method 3: Install via homebrew (may be not the latest)"},{"location":"download/#method-4-for-go-developer-latest-stabledev-version","text":"go get -u github.com/shenwei356/csvtk/csvtk","title":"Method 4: For Go developer (latest stable/dev version)"},{"location":"download/#method-5-for-archlinux-aur-users-may-be-not-the-latest","text":"yaourt -S csvtk","title":"Method 5: For ArchLinux AUR users (may be not the latest)"},{"location":"download/#shell-completion","text":"Bash: # generate completion shell csvtk genautocomplete --shell bash # configure if never did. # install bash-completion if the \"complete\" command is not found. echo \"for bcfile in ~/.bash_completion.d/* ; do source \\$bcfile; done\" >> ~/.bash_completion echo \"source ~/.bash_completion\" >> ~/.bashrc Zsh: # generate completion shell csvtk genautocomplete --shell zsh --file ~/.zfunc/_csvtk # configure if never did echo 'fpath=( ~/.zfunc \"${fpath[@]}\" )' >> ~/.zshrc echo \"autoload -U compinit; compinit\" >> ~/.zshrc fish: csvtk genautocomplete --shell fish --file ~/.config/fish/completions/csvtk.fish","title":"Shell-completion"},{"location":"download/#changelog","text":"csvtk v0.24.0 Incompatible changes : csvtk mutate2/summary : mutate2 : remove the option -L/--digits . use the same option -w/--decimal-width to limit floats to N decimal points. new command csvtk fmtdate : format date of selected fields. #159 csvtk grep : fix bug for searching with -r -p . . csvtk csv2rst : fix bug for data containing unicode. #137 csvtk filter2 : fix bug for date expression. #146 csvtk mutate2/filter2 : change the way of rexpression evaluation. add custom functions: len() . #153 fix bug when using two or more columns with common prefixes in column names . #173 fix value with single or double quotes. #174 csvtk cut : new flags -m/--allow-missing-col and -b/--blank-missing-col . #156 csvtk pretty : still add header row for empty column. csvtk csv2md : better format. csvtk join : new flag -n/--ignore-null . #163 csvtk v0.23.0 new comand: csvtk csv2rst for converting CSV to reStructuredText format. #137 csvtk pretty : add header separator line. #123 csvtk mutate2/summary : fix message and doc. Thanks @VladimirAlexiev #127 csvtk mutate2 : fix null coalescence: ??. #129 csvtk genautocomplete : supports bash|zsh|fish|powershell. #126 csvtk cat : fix progress bar. #130 csvtk grep : new flag immediate-output . csvtk csv2xlsx : fix bug for table with > 26 columns. 138 csvtk v0.22.0 csvtk : global flag -t does not overide -D anymore . #114 If the executable/symlink name is tsvtk the -t/--tabs option for tab input is set . Thanks @bsipos. #117 new command: csvtk csv2xlsx for converting CSV/TSV file(s) to a single .xlsx file. new command: csvtk unfold for unfolding multiple values in cells of a field. #103 rename csvtk collapse to csvtk fold , for folding multiple values of a field into cells of groups. csvtk cut : support range format 2- to choose 2nd column to the end . #106 csvtk round : fix bug of failing to round scientific notation with value small than one, e.g., 7.1E-1 . csvtk v0.21.0 new command: csvtk nrow/ncol for printing number of rows or columns. new command: round to round float to n decimal places. #112 csvtk headers : file name and column index is optional outputted with new flag -v/--verbose . csvtk dim : new flags --tabluar , --cols , --rows , -n/--no-files . csvtk dim/ncol/nrow : can handle empty files now. #108 csvtk csv2json #104 : new flag -b/--blank : do not convert \"\", \"na\", \"n/a\", \"none\", \"null\", \".\" to null new flag -n/--parse-num : parse numeric values for nth column(s), multiple values are supported and \"a\"/\"all\" for all columns. csvtk xlsx2csv : fix output for ragged table. #110 csvtk join : fix bug for joining >2 files. csvtk uniq : new flag -n/--keep-n for keeping first N records of every key. csvtk cut : support repeatedly selecting columns. #106 csvtk v0.20.0 new command csvtk comb : compute combinations of items at every row. new command csvtk sep : separate column into multiple columns. #96 csvtk : list lines' number of illegal ( -I ) and empty ( -E ) rows. #97 new flag --infile-list for giving file of input files list (one file per line), if given, they are appended to files from cli arguments csvtk join : reenable flag -i/--ignore-case . #99 outer join is supported . #23 new flag -L/--left-join : left join, equals to -k/--keep-unmatched, exclusive with --outer-join new flag -O/--outer-join : outer join, exclusive with --left-join rename flag --fill to --na . csvtk filter2 : fix bug when column names start with digits, e.g., 1000g2015aug . Thank @VorontsovIE ( #44 ) csvtk concat : allow one input file. #98 csvtk mutate : new flag -R/--remove for removing input column. csvtk v0.19.1 csvtk : fix checking file existence. show friendly error message when giving empty field like csvtk cut -f a, b . csvtk summary : fix err of q1 and q3. #90 csvtk version : making checking update optional. csvtk v0.19.0 new commands by @bsipos : watch : online monitoring and histogram of selected field. corr : calculate Pearson correlation between numeric columns. cat : stream file and report progress. csvtk split : fix bug of repeatedly output header line when number of output files exceed value of --buf-groups . #83 csvtk plot hist : new option --percentiles to add percentiles to histogram x label. #88 csvtk v0.18.2 csvtk replace/rename2/splitxlsx : fix flag conflicts with global flag -I since v0.18.0. csvtk replace/rename2 : removing shorthand flag -I for --key-capt-idx . csvtk splitxlsx : changing shorthand flag of --sheet-index from -I to -N . csvtk v0.18.1 csvtk sort : fix mutiple-key-sort containing natural order sorting. #79 csvtk xlsx2csv : reacts to global flags -t , -T , -D and -E . #78 csvtk v0.18.0 csvtk : add new flag --ignore-illegal-row to skip illegal rows. #72 csvtk summary : add more textual/numeric operations. #64 csvtk sort : fix bug for sorting by columns with empty values. #70 csvtk grep : add new flag --delete-matched to delete a pattern right after being matched, this keeps the firstly matched data and speedups when using regular expressions. #77 csvtk v0.17.0 new command: csvtk add-header and csvtk del-header for adding/deleting column names. [#62] csvtk v0.16.0 new command: csvtk csv2json : convert CSV to JSON format. remove comand: csvtk stats2 . new command csvtk summary : summary statistics of selected digital fields (groupby group fields), usage and examples . #59 csvtk replace : add flag --nr-width : minimum width for {nr} in flag -r/--replacement. e.g., formating \"1\" to \"001\" by --nr-width 3 (default 1) csvtk rename2/replace : add flag -A, --kv-file-all-left-columns-as-value , for treating all columns except 1th one as value for kv-file with more than 2 columns. #56 csvtk v0.15.0 csvtk : add global flag -E/--ignore-empty-row to skip empty row. #50 csvtk mutate2 : add flag -s/--digits-as-string for not converting big digits into scientific notation. #46 csvtk sort : add support for sorting in natural order. #49 csvtk v0.14.0 csvtk : supporting multi-line fields by replacing multicorecsv with standard library encoding/csv , while losing support for metaline which was supported since v0.7.0 . It also gain a little speedup. csvtk sample : add flag -n/--line-number to print line number as the first column (\"n\") csvtk filter2 : fix bug when column names start with digits, e.g., 1000g2015aug ( #44 ) csvtk rename2 : add support for similar repalecement symbols {kv} and {nr} in csvtk replace csvtk v0.13.0 new command concat for concatenating CSV/TSV files by rows #38 csvtk : add support for environment variables for frequently used global flags #39 CSVTK_T for flag -t/--tabs CSVTK_H for flag -H/--no-header-row mutate2 : add support for eval expression WITHOUT column index symbol, so we can add some string constants #37 pretty : better support for files with duplicated column names csvtk v0.12.0 new command collapse : collapsing one field with selected fields as keys freq : keeping orignal order of keys by default split : performance improvement add option -G/--out-gzip for forcing output gzipped file csvtk v0.11.0 add command split to split CSV/TSV into multiple files according to column values add command splitxlxs to split XLSX sheet into multiple sheets according to column values csvtk , automatically check BOM (byte-order mark) and discard it csvtk v0.10.0 add subcommand xlsx2csv to convert XLSX to CSV format grep , filter , filter2 : add flag -n/--line-number to print line-number as the first column cut : add flag -i/--ignore-case to ignore case of column name csvtk v0.9.1 csvtk replace : fix bug when replacing with key-value pairs brought in v0.8.0 csvtk v0.9.0 add subcommand csvtk mutate2 : create new column from selected fields by awk-like arithmetic/string expressions add new command genautocomplete to generate shell autocompletion script! csvtk v0.8.0 new command csvtk gather for gathering columns into key-value pairs . csvtk sort : support sorting by user-defined order . fix bug of unselecting field : wrongly reporting error of fields not existing. affected commands: cut , filter , fitler2 , freq , grep , inter , mutate , rename , rename2 , replace , stats2 , uniq . update help message of flag -F/--fuzzy-fields . update help message of global flag -t , which overrides both -d and -D . If you want other delimiter for tabular input, use -t $'\\t' -D \"delimiter\" . csvtk v0.7.1 csvtk plot box and csvtk plot line : fix bugs for special cases of input compile with go1.8.1 csvtk v0.7.0 fig bug of \"stricter field checking\" in v0.6.0 and v0.6.1 when using flag -F/--fuzzy-fields csvtk pretty and csvtk csv2md : add attention that these commands treat the first row as header line and require them to be unique. csvtk stat renamed to csvtk stats , old name is still available as an alias. csvtk stat2 renamed to csvtk stats2 , old name is still available as an alias. issues/13 seamlessly support for data with meta line of separator declaration used by MS Excel . csvtk v0.6.1 csvtk cut : minor bug: panic when no fields given. i.e., csvtk cut . All relevant commands have been fixed. csvtk v0.6.0 csvtk grep : large performance improvement by discarding goroutine (multiple threads), and keeping output in order of input . Better column name checking and stricter field checking, fields out of range are not ignored now . Affected commands include cut , filter , freq , grep , inter , mutate , rename , rename2 , replace , stat2 , and uniq . New command: csvtk filter2 , filtering rows by arithmetic/string expressions like awk . csvtk v0.5.0 csvtk cut : delete flag -n/--names , move it to a new command csvtk headers new command: csvtk headers new command: csvtk head new command: csvtk sample csvtk v0.4.6 csvtk grep : fix result highlight when flag -v is on. csvtk v0.4.5 csvtk join : support the 2nd or later files with entries with same ID. csvtk v0.4.4 add command csvtk freq : frequencies of selected fields add lots of examples in usage page csvtk v0.4.3 improvement of using experience: flag -n is not required anymore when flag -H in csvtk mutate csvtk v0.4.2 fix highlight bug of csvtk grep : if the pattern matches multiple parts, the text will be wrongly edited. changes: disable highlight when pattern file given. change the default output of all ploting commands to STDOUT, now you can pipe the image to \"display\" command of Imagemagic. csvtk v0.4.1 Nothing changed. Just fix the links due to inappropriate deployment of v0.4.0 csvtk v0.4.0 add flag for csvtk replace : -K ( --keep-key ) keep the key as value when no value found for the key. This is open in default in previous versions. csvtk v0.3.9 fix bug: header row incomplete in csvtk sort result csvtk v0.3.8.1 fix bug of flag parsing library pflag , detail . The bug affected the csvtk grep -r -p , when value of -p contain \"[\" and \"]\" at the beginning or end, they are wrongly parsed. csvtk v0.3.8 new feature: csvtk cut supports ordered fields output. e.g., csvtk cut -f 2,1 outputs the 2nd column in front of 1th column. new commands: csvtk plot can plot three types of plots by subcommands: csvtk plot hist : histogram csvtk plot box : boxplot csvtk plot line : line plot and scatter plot csvtk v0.3.7 fix a serious bug of using negative field of column name, e.g. -f \"-id\" csvtk v0.3.6 csvtk replace support replacement symbols {nr} (record number) and {kv} (corresponding value of the key ($1) by key-value file) csvtk v0.3.5.2 add flag --fill for csvtk join , so we can fill the unmatched data fix typo csvtk v0.3.5.1 fix minor bug of reading lines ending with \\r\\n from a dependency package csvtk v0.3.5 fix minor bug of csv2md add subcommand version which could check for update csvtk v0.3.4 fix bug of csvtk replace that head row should not be edited. csvtk v0.3.3 fix bug of csvtk grep -t -P csvtk v0.3.2 fix bug of inter csvtk v0.3.1 add support of search multiple fields for grep csvtk v0.3 add subcommand csv2md csvtk v0.2.9 add more flags to subcommand pretty fix bug of csvtk cut -n add subcommand filter csvtk v0.2.8 add subcommand pretty -- convert CSV to readable aligned table csvtk v0.2.7 fix highlight failing in windows csvtk v0.2.6 fix one error message of grep highlight matched fields in result of grep csvtk v0.2.5 fix bug of stat that failed to considerate files with header row add subcommand stat2 - summary of selected number fields make the output of stat prettier csvtk v0.2.4 fix bug of handling comment lines add some notes before using csvtk csvtk v0.2.3 add flag --colnames to cut flag -f ( --fields ) of join supports single value now csvtk v0.2.2 add flag --keep-unmathed to join csvtk v0.2 finish almost functions csvtk v0.2.1 fix bug of mutate /** * RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS. * LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables */ /* var disqus_config = function () { this.page.url = PAGE_URL; // Replace PAGE_URL with your page's canonical URL variable this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable }; */ (function() { // DON'T EDIT BELOW THIS LINE var d = document, s = d.createElement('script'); s.src = '//csvtk.disqus.com/embed.js'; s.setAttribute('data-timestamp', +new Date()); (d.head || d.body).appendChild(s); })(); Please enable JavaScript to view the comments powered by Disqus.","title":"Changelog"},{"location":"tutorial/","text":"Tutorial Analyzing OTU table Data Here is a mock OTU table from 16S rRNA sequencing result. Columns are sample IDs in format of \"GROUP.ID\" $ cat otu_table.csv Taxonomy,A.1,A.2,A.3,B.1,B.2,B.3,C.1,C.2 Proteobacteria,.13,.29,.13,.16,.13,.22,.30,.23 Firmicutes,.42,.06,.49,.41,.55,.41,.32,.38 Bacteroidetes,.19,.62,.12,.33,.16,.29,.34,.35 Deferribacteres,.17,.00,.24,.01,.01,.01,.01,.01 What a mess! Let's make it prettier! $ csvtk pretty otu_table.csv Taxonomy A.1 A.2 A.3 B.1 B.2 B.3 C.1 C.2 Proteobacteria .13 .29 .13 .16 .13 .22 .30 .23 Firmicutes .42 .06 .49 .41 .55 .41 .32 .38 Bacteroidetes .19 .62 .12 .33 .16 .29 .34 .35 Deferribacteres .17 .00 .24 .01 .01 .01 .01 .01 Steps Counting $ csvtk stat otu_table.csv file num_cols num_rows otu_table.csv 9 4 Column names $ csvtk headers otu_table.csv # otu_table.csv 1 Taxonomy 2 A.1 3 A.2 4 A.3 5 B.1 6 B.2 7 B.3 8 C.1 9 C.2 Convert to tab-delimited table $ csvtk csv2tab otu_table.csv Taxonomy A.1 A.2 A.3 B.1 B.2 B.3 C.1 C.2 Proteobacteria .13 .29 .13 .16 .13 .22 .30 .23 Firmicutes .42 .06 .49 .41 .55 .41 .32 .38 Bacteroidetes .19 .62 .12 .33 .16 .29 .34 .35 Deferribacteres .17 .00 .24 .01 .01 .01 .01 .01 Extract data of group A and B and save to file -o otu_table.gAB.csv $ csvtk cut -F -f \"Taxonomy,A.*,B.*\" otu_table.csv -o otu_table.gAB.csv $ csvtk pretty otu_table.gAB.csv Taxonomy A.1 A.2 A.3 B.1 B.2 B.3 Proteobacteria .13 .29 .13 .16 .13 .22 Firmicutes .42 .06 .49 .41 .55 .41 Bacteroidetes .19 .62 .12 .33 .16 .29 Deferribacteres .17 .00 .24 .01 .01 .01 Search some rows by fields. Matched parts will be highlighted as red $ csvtk grep -f Taxonomy -r -p \"tes\" otu_table.gAB.csv -T Result: Transpose $ csvtk transpose otu_table.gAB.csv -o otu_table.gAB.t.csv $ csvtk pretty otu_table.gAB.t.csv Taxonomy Proteobacteria Firmicutes Bacteroidetes Deferribacteres A.1 .13 .42 .19 .17 A.2 .29 .06 .62 .00 A.3 .13 .49 .12 .24 B.1 .16 .41 .33 .01 B.2 .13 .55 .16 .01 B.3 .22 .41 .29 .01 Rename name of the first column $ csvtk rename -f 1 -n \"sample\" otu_table.gAB.t.csv -o otu_table.gAB.t.r.csv $ csvtk pretty otu_table.gAB.t.r.csv sample Proteobacteria Firmicutes Bacteroidetes Deferribacteres A.1 .13 .42 .19 .17 A.2 .29 .06 .62 .00 A.3 .13 .49 .12 .24 B.1 .16 .41 .33 .01 B.2 .13 .55 .16 .01 B.3 .22 .41 .29 .01 Add group column $ csvtk mutate -p \"(.+?)\\.\" -n group otu_table.gAB.t.r.csv -o otu_table2.csv $ csvtk pretty otu_table2.csv sample Proteobacteria Firmicutes Bacteroidetes Deferribacteres group A.1 .13 .42 .19 .17 A A.2 .29 .06 .62 .00 A A.3 .13 .49 .12 .24 A B.1 .16 .41 .33 .01 B B.2 .13 .55 .16 .01 B B.3 .22 .41 .29 .01 B Rename groups: $ csvtk replace -f group -p \"A\" -r \"Ctrl\" otu_table2.csv \\ | csvtk replace -f group -p \"B\" -r \"Treatment\" \\ > otu_table3.csv $ csvtk pretty -s \" \" otu_table3.csv sample Proteobacteria Firmicutes Bacteroidetes Deferribacteres group A.1 .13 .42 .19 .17 Ctrl A.2 .29 .06 .62 .00 Ctrl A.3 .13 .49 .12 .24 Ctrl B.1 .16 .41 .33 .01 Treatment B.2 .13 .55 .16 .01 Treatment B.3 .22 .41 .29 .01 Treatment Sort by abundance of Proteobacteria in descending order. $ csvtk sort -k Proteobacteria:nr otu_table3.csv \\ | csvtk pretty -s \" \" sample Proteobacteria Firmicutes Bacteroidetes Deferribacteres group A.2 .29 .06 .62 .00 Ctrl B.3 .22 .41 .29 .01 Treatment B.1 .16 .41 .33 .01 Treatment B.2 .13 .55 .16 .01 Treatment A.3 .13 .49 .12 .24 Ctrl A.1 .13 .42 .19 .17 Ctrl Sort by abundance of Proteobacteria in descending order and Firmicutes in ascending order $ csvtk sort -k Proteobacteria:nr -k Firmicutes:n otu_table3.csv \\ | csvtk pretty -s \" \" sample Proteobacteria Firmicutes Bacteroidetes Deferribacteres group A.2 .29 .06 .62 .00 Ctrl B.3 .22 .41 .29 .01 Treatment B.1 .16 .41 .33 .01 Treatment A.1 .13 .42 .19 .17 Ctrl A.3 .13 .49 .12 .24 Ctrl B.2 .13 .55 .16 .01 Treatment Filter samples with abundance greater than 0 in all taxons (columns except for sample and group, you can also use -f \"2-5>0\" ). $ cat otu_table3.csv \\ | csvtk filter -f \"2-5>0\" \\ | csvtk pretty -s \" \" sample Proteobacteria Firmicutes Bacteroidetes Deferribacteres group A.1 .13 .42 .19 .17 Ctrl A.3 .13 .49 .12 .24 Ctrl B.1 .16 .41 .33 .01 Treatment B.2 .13 .55 .16 .01 Treatment B.3 .22 .41 .29 .01 Treatment Most of the time, we may want to remove samples with abundance of 0 in all taxons. $ cat otu_table3.csv \\ | csvtk filter -f \"2-5>0\" --any \\ | csvtk pretty -s \" \" sample Proteobacteria Firmicutes Bacteroidetes Deferribacteres group A.1 .13 .42 .19 .17 Ctrl A.2 .29 .06 .62 .00 Ctrl A.3 .13 .49 .12 .24 Ctrl B.1 .16 .41 .33 .01 Treatment B.2 .13 .55 .16 .01 Treatment B.3 .22 .41 .29 .01 Treatment /** * RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS. * LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables */ /* var disqus_config = function () { this.page.url = PAGE_URL; // Replace PAGE_URL with your page's canonical URL variable this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable }; */ (function() { // DON'T EDIT BELOW THIS LINE var d = document, s = d.createElement('script'); s.src = '//csvtk.disqus.com/embed.js'; s.setAttribute('data-timestamp', +new Date()); (d.head || d.body).appendChild(s); })(); Please enable JavaScript to view the comments powered by Disqus.","title":"Tutorial"},{"location":"tutorial/#tutorial","text":"","title":"Tutorial"},{"location":"tutorial/#analyzing-otu-table","text":"","title":"Analyzing OTU table"},{"location":"tutorial/#data","text":"Here is a mock OTU table from 16S rRNA sequencing result. Columns are sample IDs in format of \"GROUP.ID\" $ cat otu_table.csv Taxonomy,A.1,A.2,A.3,B.1,B.2,B.3,C.1,C.2 Proteobacteria,.13,.29,.13,.16,.13,.22,.30,.23 Firmicutes,.42,.06,.49,.41,.55,.41,.32,.38 Bacteroidetes,.19,.62,.12,.33,.16,.29,.34,.35 Deferribacteres,.17,.00,.24,.01,.01,.01,.01,.01 What a mess! Let's make it prettier! $ csvtk pretty otu_table.csv Taxonomy A.1 A.2 A.3 B.1 B.2 B.3 C.1 C.2 Proteobacteria .13 .29 .13 .16 .13 .22 .30 .23 Firmicutes .42 .06 .49 .41 .55 .41 .32 .38 Bacteroidetes .19 .62 .12 .33 .16 .29 .34 .35 Deferribacteres .17 .00 .24 .01 .01 .01 .01 .01","title":"Data"},{"location":"tutorial/#steps","text":"Counting $ csvtk stat otu_table.csv file num_cols num_rows otu_table.csv 9 4 Column names $ csvtk headers otu_table.csv # otu_table.csv 1 Taxonomy 2 A.1 3 A.2 4 A.3 5 B.1 6 B.2 7 B.3 8 C.1 9 C.2 Convert to tab-delimited table $ csvtk csv2tab otu_table.csv Taxonomy A.1 A.2 A.3 B.1 B.2 B.3 C.1 C.2 Proteobacteria .13 .29 .13 .16 .13 .22 .30 .23 Firmicutes .42 .06 .49 .41 .55 .41 .32 .38 Bacteroidetes .19 .62 .12 .33 .16 .29 .34 .35 Deferribacteres .17 .00 .24 .01 .01 .01 .01 .01 Extract data of group A and B and save to file -o otu_table.gAB.csv $ csvtk cut -F -f \"Taxonomy,A.*,B.*\" otu_table.csv -o otu_table.gAB.csv $ csvtk pretty otu_table.gAB.csv Taxonomy A.1 A.2 A.3 B.1 B.2 B.3 Proteobacteria .13 .29 .13 .16 .13 .22 Firmicutes .42 .06 .49 .41 .55 .41 Bacteroidetes .19 .62 .12 .33 .16 .29 Deferribacteres .17 .00 .24 .01 .01 .01 Search some rows by fields. Matched parts will be highlighted as red $ csvtk grep -f Taxonomy -r -p \"tes\" otu_table.gAB.csv -T Result: Transpose $ csvtk transpose otu_table.gAB.csv -o otu_table.gAB.t.csv $ csvtk pretty otu_table.gAB.t.csv Taxonomy Proteobacteria Firmicutes Bacteroidetes Deferribacteres A.1 .13 .42 .19 .17 A.2 .29 .06 .62 .00 A.3 .13 .49 .12 .24 B.1 .16 .41 .33 .01 B.2 .13 .55 .16 .01 B.3 .22 .41 .29 .01 Rename name of the first column $ csvtk rename -f 1 -n \"sample\" otu_table.gAB.t.csv -o otu_table.gAB.t.r.csv $ csvtk pretty otu_table.gAB.t.r.csv sample Proteobacteria Firmicutes Bacteroidetes Deferribacteres A.1 .13 .42 .19 .17 A.2 .29 .06 .62 .00 A.3 .13 .49 .12 .24 B.1 .16 .41 .33 .01 B.2 .13 .55 .16 .01 B.3 .22 .41 .29 .01 Add group column $ csvtk mutate -p \"(.+?)\\.\" -n group otu_table.gAB.t.r.csv -o otu_table2.csv $ csvtk pretty otu_table2.csv sample Proteobacteria Firmicutes Bacteroidetes Deferribacteres group A.1 .13 .42 .19 .17 A A.2 .29 .06 .62 .00 A A.3 .13 .49 .12 .24 A B.1 .16 .41 .33 .01 B B.2 .13 .55 .16 .01 B B.3 .22 .41 .29 .01 B Rename groups: $ csvtk replace -f group -p \"A\" -r \"Ctrl\" otu_table2.csv \\ | csvtk replace -f group -p \"B\" -r \"Treatment\" \\ > otu_table3.csv $ csvtk pretty -s \" \" otu_table3.csv sample Proteobacteria Firmicutes Bacteroidetes Deferribacteres group A.1 .13 .42 .19 .17 Ctrl A.2 .29 .06 .62 .00 Ctrl A.3 .13 .49 .12 .24 Ctrl B.1 .16 .41 .33 .01 Treatment B.2 .13 .55 .16 .01 Treatment B.3 .22 .41 .29 .01 Treatment Sort by abundance of Proteobacteria in descending order. $ csvtk sort -k Proteobacteria:nr otu_table3.csv \\ | csvtk pretty -s \" \" sample Proteobacteria Firmicutes Bacteroidetes Deferribacteres group A.2 .29 .06 .62 .00 Ctrl B.3 .22 .41 .29 .01 Treatment B.1 .16 .41 .33 .01 Treatment B.2 .13 .55 .16 .01 Treatment A.3 .13 .49 .12 .24 Ctrl A.1 .13 .42 .19 .17 Ctrl Sort by abundance of Proteobacteria in descending order and Firmicutes in ascending order $ csvtk sort -k Proteobacteria:nr -k Firmicutes:n otu_table3.csv \\ | csvtk pretty -s \" \" sample Proteobacteria Firmicutes Bacteroidetes Deferribacteres group A.2 .29 .06 .62 .00 Ctrl B.3 .22 .41 .29 .01 Treatment B.1 .16 .41 .33 .01 Treatment A.1 .13 .42 .19 .17 Ctrl A.3 .13 .49 .12 .24 Ctrl B.2 .13 .55 .16 .01 Treatment Filter samples with abundance greater than 0 in all taxons (columns except for sample and group, you can also use -f \"2-5>0\" ). $ cat otu_table3.csv \\ | csvtk filter -f \"2-5>0\" \\ | csvtk pretty -s \" \" sample Proteobacteria Firmicutes Bacteroidetes Deferribacteres group A.1 .13 .42 .19 .17 Ctrl A.3 .13 .49 .12 .24 Ctrl B.1 .16 .41 .33 .01 Treatment B.2 .13 .55 .16 .01 Treatment B.3 .22 .41 .29 .01 Treatment Most of the time, we may want to remove samples with abundance of 0 in all taxons. $ cat otu_table3.csv \\ | csvtk filter -f \"2-5>0\" --any \\ | csvtk pretty -s \" \" sample Proteobacteria Firmicutes Bacteroidetes Deferribacteres group A.1 .13 .42 .19 .17 Ctrl A.2 .29 .06 .62 .00 Ctrl A.3 .13 .49 .12 .24 Ctrl B.1 .16 .41 .33 .01 Treatment B.2 .13 .55 .16 .01 Treatment B.3 .22 .41 .29 .01 Treatment /** * RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS. * LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables */ /* var disqus_config = function () { this.page.url = PAGE_URL; // Replace PAGE_URL with your page's canonical URL variable this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable }; */ (function() { // DON'T EDIT BELOW THIS LINE var d = document, s = d.createElement('script'); s.src = '//csvtk.disqus.com/embed.js'; s.setAttribute('data-timestamp', +new Date()); (d.head || d.body).appendChild(s); })(); Please enable JavaScript to view the comments powered by Disqus.","title":"Steps"},{"location":"usage/","text":"Usage and Examples Before use Attention The CSV parser requires all the lines have same number of fields/columns. Even lines with spaces will cause error. Use '-I/--ignore-illegal-row' to skip these lines if neccessary. By default, csvtk thinks your files have header row, if not, switch flag \"-H\" on. Column names better be unique. By default, lines starting with \"#\" will be ignored, if the header row starts with \"#\", please assign flag \"-C\" another rare symbol, e.g. '$'. By default, csvtk handles CSV files, use flag \"-t\" for tab-delimited files. If double quotes exist in fields, use flag \"-l\". Do not mix use field (column) numbers and names. Table of Contents csvtk Information headers dim/nrow/ncol summary corr watch Format conversion pretty transpose csv2md csv2json csv2xlsx xlsx2csv Set operations head concat sample cut grep uniq freq inter filter filter2 join split splitxlsx comb Edit add-header del-header rename rename2 replace round mutate mutate2 sep gather unfold fold Ordering sort Ploting plot plot hist plot box plot line Misc cat genautocomplete csvtk Usage csvtk -- a cross-platform, efficient and practical CSV/TSV toolkit Version: 0.24.0 Author: Wei Shen <shenwei356@gmail.com> Documents : http://shenwei356.github.io/csvtk Source code: https://github.com/shenwei356/csvtk Attention: 1. The CSV parser requires all the lines have same number of fields/columns. Even lines with spaces will cause error. Use '-I/--ignore-illegal-row' to skip these lines if neccessary. 2. By default, csvtk thinks your files have header row, if not, switch flag \"-H\" on. 3. Column names better be unique. 4. By default, lines starting with \"#\" will be ignored, if the header row starts with \"#\", please assign flag \"-C\" another rare symbol, e.g. '$'. 5. By default, csvtk handles CSV files, use flag \"-t\" for tab-delimited files. 6. If double quotes exist in fields, use flag \"-l\". 7. Do not mix use field (column) numbers and names. Environment variables for frequently used global flags: - \"CSVTK_T\" for flag \"-t/--tabs\" - \"CSVTK_H\" for flag \"-H/--no-header-row\" You can also create a soft link named \"tsvtk\" for \"csvtk\", which sets \"-t/--tabs\" by default. Usage: csvtk [command] Available Commands: add-header add column names cat stream file to stdout and report progress on stderr comb compute combinations of items at every row concat concatenate CSV/TSV files by rows corr calculate Pearson correlation between two columns csv2json convert CSV to JSON format csv2md convert CSV to markdown format csv2rst convert CSV to reStructuredText format csv2tab convert CSV to tabular format csv2xlsx convert CSV/TSV files to XLSX file cut select and arrange fields del-header delete column names dim dimensions of CSV file filter filter rows by values of selected fields with arithmetic expression filter2 filter rows by awk-like arithmetic/string expressions fmtdate format date of selected fields fold fold multiple values of a field into cells of groups freq frequencies of selected fields gather gather columns into key-value pairs genautocomplete generate shell autocompletion script (bash|zsh|fish|powershell) grep grep data by selected fields with patterns/regular expressions head print first N records headers print headers help Help about any command inter intersection of multiple files join join files by selected fields (inner, left and outer join) mutate create new column from selected fields by regular expression mutate2 create new column from selected fields by awk-like arithmetic/string expressions ncol print number of columns nrow print number of records plot plot common figures pretty convert CSV to readable aligned table rename rename column names with new names rename2 rename column names by regular expression replace replace data of selected fields by regular expression round round float to n decimal places sample sampling by proportion sep separate column into multiple columns sort sort by selected fields space2tab convert space delimited format to CSV split split CSV/TSV into multiple files according to column values splitxlsx split XLSX sheet into multiple sheets according to column values summary summary statistics of selected numeric or text fields (groupby group fields) tab2csv convert tabular format to CSV transpose transpose CSV data unfold unfold multiple values in cells of a field uniq unique data without sorting version print version information and check for update watch monitor the specified fields xlsx2csv convert XLSX to CSV format Flags: -c, --chunk-size int chunk size of CSV reader (default 50) -C, --comment-char string lines starting with commment-character will be ignored. if your header row starts with '#', please assign \"-C\" another rare symbol, e.g. '$' (default \"#\") -d, --delimiter string delimiting character of the input CSV file (default \",\") -h, --help help for csvtk -E, --ignore-empty-row ignore empty rows -I, --ignore-illegal-row ignore illegal rows --infile-list string file of input files list (one file per line), if given, they are appended to files from cli arguments -l, --lazy-quotes if given, a quote may appear in an unquoted field and a non-doubled quote may appear in a quoted field -H, --no-header-row specifies that the input CSV file does not have header row -j, --num-cpus int number of CPUs to use (default value depends on your computer) (default 16) -D, --out-delimiter string delimiting character of the output CSV file, e.g., -D $'\\t' for tab (default \",\") -o, --out-file string out file (\"-\" for stdout, suffix .gz for gzipped out) (default \"-\") -T, --out-tabs specifies that the output is delimited with tabs. Overrides \"-D\" -t, --tabs specifies that the input CSV file is delimited with tabs. Overrides \"-d\" Use \"csvtk [command] --help\" for more information about a command. headers Usage print headers Usage: csvtk headers [flags] Flags: -h, --help help for headers -v, --verbose print verbose information Examples $ csvtk headers testdata/[12].csv name attr name major $ csvtk headers testdata/[12].csv -v # testdata/1.csv 1 name 2 attr # testdata/2.csv 1 name 2 major dim/nrow/ncol Usage dim: dimensions of CSV file Usage: csvtk dim [flags] Aliases: dim, size, stats, stat Flags: --cols only print number of columns -h, --help help for dim -n, --no-files do not print file names --rows only print number of rows --tabular output in machine-friendly tabular format nrow: print number of records Usage: csvtk nrow [flags] Aliases: nrow, nrows Flags: -n, --file-name print file names -h, --help help for nrow ncol: print number of columns Usage: csvtk ncol [flags] Aliases: ncol, ncols Flags: -n, --file-name print file names -h, --help help for ncol Examples with header row $ cat testdata/names.csv id,first_name,last_name,username 11,\"Rob\",\"Pike\",rob 2,Ken,Thompson,ken 4,\"Robert\",\"Griesemer\",\"gri\" 1,\"Robert\",\"Thompson\",\"abc\" NA,\"Robert\",\"Abel\",\"123\" $ cat testdata/names.csv | csvtk size file num_cols num_rows - 4 5 $ cat testdata/names.csv | csvtk nrow 5 $ cat testdata/names.csv | csvtk ncol 4 $ csvtk nrow testdata/names.csv testdata/phones.csv -n 5 testdata/names.csv 4 testdata/phones.csv no header row $ cat testdata/digitals.tsv 4 5 6 1 2 3 7 8 0 8 1,000 4 $ cat testdata/digitals.tsv \\ | csvtk size -t -H file num_cols num_rows - 3 4 $ cat testdata/names.csv | csvtk nrow -H 3 $ cat testdata/names.csv | csvtk ncol -H 4 summary Usage summary statistics of selected numeric or text fields (groupby group fields) Attention: 1. Do not mix use field (column) numbers and names. Available operations: # numeric/statistical operations # provided by github.com/gonum/stat and github.com/gonum/floats countn (count numeric values), min, max, sum, mean, stdev, variance, median, q1, q2, q3, entropy (Shannon entropy), prod (product of the elements) # textual/numeric operations count, first, last, rand, unique, collapse, countunique Usage: csvtk summary [flags] Flags: -n, --decimal-width int limit floats to N decimal points (default 2) -f, --fields strings operations on these fields. e.g -f 1:count,1:sum or -f colA:mean. available operations: collapse, count, countn, countunique, entropy, first, last, max, mean, median, min, prod, q1, q2, q3, rand, stdev, sum, uniq, variance -g, --groups string group via fields. e.g -f 1,2 or -f columnA,columnB -h, --help help for summary -i, --ignore-non-numbers ignore non-digital values like \"NA\" or \"N/A\" -S, --rand-seed int rand seed for operation \"rand\" (default 11) -s, --separater string separater for collapsed data (default \"; \") Examples data $ cat testdata/digitals2.csv f1,f2,f3,f4,f5 foo,bar,xyz,1,0 foo,bar2,xyz,1.5,-1 foo,bar2,xyz,3,2 foo,bar,xyz,5,3 foo,bar2,xyz,N/A,4 bar,xyz,abc,NA,2 bar,xyz,abc2,1,-1 bar,xyz,abc,2,0 bar,xyz,abc,1,5 bar,xyz,abc,3,100 bar,xyz2,abc3,2,3 bar,xyz2,abc3,2,1 use flag -i/--ignore-non-numbers $ cat testdata/digitals2.csv \\ | csvtk summary -f f4:sum [ERRO] column 4 has non-digital data: N/A, you can use flag -i/--ignore-non-numbers to skip these data $ cat testdata/digitals2.csv \\ | csvtk summary -f f4:sum -i f4:sum 21.50 multiple fields suported $ cat testdata/digitals2.csv \\ | csvtk summary -f f4:sum,f5:sum -i f4:sum,f5:sum 21.50,118.00 using fields instead of colname is still supported $ cat testdata/digitals2.csv \\ | csvtk summary -f 4:sum,5:sum -i f4:sum,f5:sum 21.50,118.00 but remember do not mix use column numbers and names $ cat testdata/digitals2.csv \\ | csvtk summary -f f4:sum,5:sum -i [ERRO] column \"5\" not existed in file: - $ cat testdata/digitals2.csv \\ | csvtk summary -f 4:sum,f5:sum -i [ERRO] failed to parse f5 as a field number, you may mix the use of field numbers and column names groupby $ cat testdata/digitals2.csv \\ | csvtk summary -i -f f4:sum,f5:sum -g f1,f2 \\ | csvtk pretty f1 f2 f4:sum f5:sum bar xyz 7.00 106.00 bar xyz2 4.00 4.00 foo bar 6.00 3.00 foo bar2 4.50 5.00 for data without header line $ cat testdata/digitals2.csv | sed 1d \\ | csvtk summary -H -i -f 4:sum,5:sum -g 1,2 \\ | csvtk pretty bar xyz 7.00 106.00 bar xyz2 4.00 4.00 foo bar 6.00 3.00 foo bar2 4.50 5.00 numeric/statistical operations $ cat testdata/digitals2.csv \\ | csvtk summary -i -g f1 -f f4:countn,f4:mean,f4:stdev,f4:q1,f4:q2,f4:mean,f4:q3,f4:min,f4:max \\ | csvtk pretty f1 f4:countn f4:mean f4:stdev f4:q1 f4:q2 f4:mean f4:q3 f4:min f4:max bar 6.00 1.83 0.75 1.00 2.00 1.83 2.00 1.00 3.00 foo 4.00 2.62 1.80 1.25 2.25 2.62 4.00 1.00 5.00 textual/numeric operations $ cat testdata/digitals2.csv \\ | csvtk summary -i -g f1 -f f2:count,f2:first,f2:last,f2:rand,f2:collapse,f2:uniq,f2:countunique \\ | csvtk pretty f1 f2:count f2:first f2:last f2:rand f2:collapse f2:uniq f2:countunique bar 7 xyz xyz2 xyz2 xyz; xyz; xyz; xyz; xyz; xyz2; xyz2 xyz2; xyz 2 foo 5 bar bar2 bar2 bar; bar2; bar2; bar; bar2 bar; bar2 2 mixed operations $ cat testdata/digitals2.csv \\ | csvtk summary -i -g f1 -f f4:collapse,f4:max \\ | csvtk pretty f1 f4:collapse f4:max bar NA; 1; 2; 1; 3; 2; 2 3.00 foo 1; 1.5; 3; 5; N/A 5.00 count and countn (count of digits) $ cat testdata/digitals2.csv \\ | csvtk summary -f f4:count,f4:countn -i \\ | csvtk pretty f4:count f4:countn 12 10 # details: $ cat testdata/digitals2.csv \\ | csvtk summary -f f4:count,f4:countn,f4:collapse -i -g f1 \\ | csvtk pretty f1 f4:count f4:countn f4:collapse bar 7 6 NA; 1; 2; 1; 3; 2; 2 foo 5 4 1; 1.5; 3; 5; N/A watch Usage monitor the specified fields Usage: csvtk watch [flags] Flags: -B, --bins int number of histogram bins (default -1) -W, --delay int sleep this many seconds after plotting (default 1) -y, --dump print histogram data to stderr instead of plotting -f, --field string field to watch -h, --help help for watch -O, --image string save histogram to this PDF/image file -L, --log log10(x+1) transform numeric values -x, --pass passthrough mode (forward input to output) -p, --print-freq int print/report after this many records (-1 for print after EOF) (default -1) -Q, --quiet supress all plotting to stderr -R, --reset reset histogram after every report Examples Read whole file, plot histogram of field on the terminal and PDF csvtk -t watch -O hist.pdf -f MyField input.tsv Monitor a TSV stream, print histogram every 1000 records cat input.tsv | csvtk -t watch -f MyField -p 1000 - Monitor a TSV stream, print histogram every 1000 records, hang forever for updates tail -f +0 input.tsv | csvtk -t watch -f MyField -p 1000 - corr Usage calculate Pearson correlation between two columns Usage: csvtk corr [flags] Flags: -f, --fields string comma separated fields -h, --help help for corr -i, --ignore_nan Ignore non-numeric fields to avoid returning NaN -L, --log Calcute correlations on Log10 transformed data -x, --pass passthrough mode (forward input to output) Examples Calculate pairwise correlations between field, ignore non-numeric values csvtk -t corr -i -f 1,Foo,Bar input.tsv pretty Usage convert CSV to readable aligned table Usage: csvtk pretty [flags] Flags: -r, --align-right align right -h, --help help for pretty -W, --max-width int max width -w, --min-width int min width -s, --separator string fields/columns separator (default \" \") Examples: default $ csvtk pretty testdata/names.csv id first_name last_name username -- ---------- --------- -------- 11 Rob Pike rob 2 Ken Thompson ken 4 Robert Griesemer gri 1 Robert Thompson abc NA Robert Abel 123 align right $ csvtk pretty testdata/names.csv -r id first_name last_name username -- ---------- --------- -------- 11 Rob Pike rob 2 Ken Thompson ken 4 Robert Griesemer gri 1 Robert Thompson abc NA Robert Abel 123 custom separator $ csvtk pretty testdata/names.csv -s \" | \" id | first_name | last_name | username -- | ---------- | --------- | -------- 11 | Rob | Pike | rob 2 | Ken | Thompson | ken 4 | Robert | Griesemer | gri 1 | Robert | Thompson | abc NA | Robert | Abel | 123 transpose Usage transpose CSV data Usage: csvtk transpose [flags] Examples $ cat testdata/digitals.tsv 4 5 6 1 2 3 7 8 0 8 1,000 4 $ csvtk transpose -t testdata/digitals.tsv 4 1 7 8 5 2 8 1,000 6 3 0 4 csv2json Usage convert CSV to JSON format Usage: csvtk csv2json [flags] Flags: -b, --blanks do not convert \"\", \"na\", \"n/a\", \"none\", \"null\", \".\" to null -h, --help help for csv2json -i, --indent string indent. if given blank, output json in one line. (default \" \") -k, --key string output json as an array of objects keyed by a given filed rather than as a list. e.g -k 1 or -k columnA -n, --parse-num strings parse numeric values for nth column(s), multiple values are supported and \"a\"/\"all\" for all columns Examples test data $ cat testdata/data4json.csv ID,room,name,status 3,G13,Simon,true 5,103,Anna,TRUE 1e-3,2,,N/A default operation $ cat testdata/data4json.csv | csvtk csv2json [ { \"ID\": \"3\", \"room\": \"G13\", \"name\": \"Simon\", \"status\": true }, { \"ID\": \"5\", \"room\": \"103\", \"name\": \"Anna\", \"status\": true }, { \"ID\": \"1e-3\", \"room\": \"2\", \"name\": null, \"status\": null } ] change indent $ cat testdata/data4json.csv | csvtk csv2json -i \"\" [{\"ID\":\"3\",\"room\":\"G13\",\"name\":\"Simon\",\"status\":true},{\"ID\":\"5\",\"room\":\"103\",\"name\":\"Anna\",\"status\":true},{\"ID\":\"1e-3\",\"room\":\"2\",\"name\":null,\"status\":null}] output json as an array of objects keyed by a given filed rather than as a list. $ cat testdata/data4json.csv | csvtk csv2json -k ID { \"3\": { \"ID\": \"3\", \"room\": \"G13\", \"name\": \"Simon\", \"status\": true }, \"5\": { \"ID\": \"5\", \"room\": \"103\", \"name\": \"Anna\", \"status\": true }, \"1e-3\": { \"ID\": \"1e-3\", \"room\": \"2\", \"name\": null, \"status\": null } } for CSV without header row $ cat testdata/data4json.csv | csvtk csv2json -H [ [ \"ID\", \"room\", \"name\", \"status\" ], [ \"3\", \"G13\", \"Simon\", \"true\" ], [ \"5\", \"103\", \"Anna\", \"TRUE\" ], [ \"1e-3\", \"2\", \"\", \"N/A\" ] ] parse numeric values. # cat testdata/data4json.csv | csvtk csv2json -n all # for all columns # cat testdata/data4json.csv | csvtk csv2json -n 1,2 # for multiple columns $ cat testdata/data4json.csv | csvtk csv2json -n 1 # for single column [ { \"ID\": 3, \"room\": \"G13\", \"name\": \"Simon\", \"status\": true }, { \"ID\": 5, \"room\": \"103\", \"name\": \"Anna\", \"status\": true }, { \"ID\": 1e-3, \"room\": \"2\", \"name\": null, \"status\": null } ] do not convert \"\", \"na\", \"n/a\", \"none\", \"null\", \".\" to null (just like csvjon --blanks in csvkit) $ cat testdata/data4json.csv | csvtk csv2json --blanks [ { \"ID\": \"3\", \"room\": \"G13\", \"name\": \"Simon\", \"status\": true }, { \"ID\": \"5\", \"room\": \"103\", \"name\": \"Anna\", \"status\": true }, { \"ID\": \"1e-3\", \"room\": \"2\", \"name\": \"\", \"status\": \"\" } ] csv2md Usage convert CSV to markdown format Attention: csv2md treats the first row as header line and requires them to be unique Usage: csvtk csv2md [flags] Flags: -a, --alignments string comma separated alignments. e.g. -a l,c,c,c or -a c (default \"l\") -w, --min-width int min width (at least 3) (default 3) Examples give single alignment symbol $ cat testdata/names.csv | csvtk csv2md -a left |id |first_name|last_name|username| |:--|:---------|:--------|:-------| |11 |Rob |Pike |rob | |2 |Ken |Thompson |ken | |4 |Robert |Griesemer|gri | |1 |Robert |Thompson |abc | |NA |Robert |Abel |123 | result: id first_name last_name username 11 Rob Pike rob 2 Ken Thompson ken 4 Robert Griesemer gri 1 Robert Thompson abc NA Robert Abel 123 give alignment symbols of all fields $ cat testdata/names.csv | csvtk csv2md -a c,l,l,l |id |first_name|last_name|username| |:-:|:---------|:--------|:-------| |11 |Rob |Pike |rob | |2 |Ken |Thompson |ken | |4 |Robert |Griesemer|gri | |1 |Robert |Thompson |abc | |NA |Robert |Abel |123 | result id first_name last_name username 11 Rob Pike rob 2 Ken Thompson ken 4 Robert Griesemer gri 1 Robert Thompson abc NA Robert Abel 123 csv2rst Usage convert CSV to readable aligned table Attention: 1. row span is not supported. Usage: csvtk csv2rst [flags] Flags: -k, --cross string charactor of cross (default \"+\") -s, --header string charactor of separator between header row and data rowws (default \"=\") -h, --help help for csv2rst -b, --horizontal-border string charactor of horizontal border (default \"-\") -p, --padding string charactor of padding (default \" \") -B, --vertical-border string charactor of vertical border (default \"|\") Example With header row $ csvtk csv2rst testdata/names.csv +----+------------+-----------+----------+ | id | first_name | last_name | username | +====+============+===========+==========+ | 11 | Rob | Pike | rob | +----+------------+-----------+----------+ | 2 | Ken | Thompson | ken | +----+------------+-----------+----------+ | 4 | Robert | Griesemer | gri | +----+------------+-----------+----------+ | 1 | Robert | Thompson | abc | +----+------------+-----------+----------+ | NA | Robert | Abel | 123 | +----+------------+-----------+----------+ No header row $ csvtk csv2rst -H -t testdata/digitals.tsv +---+-------+---+ | 4 | 5 | 6 | +---+-------+---+ | 1 | 2 | 3 | +---+-------+---+ | 7 | 8 | 0 | +---+-------+---+ | 8 | 1,000 | 4 | +---+-------+---+ Unicode $ cat testdata/unicode.csv | csvtk csv2rst +-------+---------+ | value | name | +=======+=========+ | 1 | \u6c88\u4f1f | +-------+---------+ | 2 | \u6c88\u4f1fb | +-------+---------+ | 3 | \u6c88\u5c0f\u4f1f | +-------+---------+ | 4 | \u6c88\u5c0f\u4f1fb | +-------+---------+ Misc $ cat testdata/names.csv | head -n 1 | csvtk csv2rst +----+------------+-----------+----------+ | id | first_name | last_name | username | +====+============+===========+==========+ $ cat testdata/names.csv | head -n 1 | csvtk csv2rst -H +----+------------+-----------+----------+ | id | first_name | last_name | username | +----+------------+-----------+----------+ $ echo | csvtk csv2rst -H [ERRO] xopen: no content $ echo \"a\" | csvtk csv2rst -H +---+ | a | +---+ $ echo \"\u6c88\u4f1f\" | csvtk csv2rst -H +------+ | \u6c88\u4f1f | +------+ csv2xlsx Usage convert CSV/TSV files to XLSX file Attention: 1. Multiple CSV/TSV files are saved as separated sheets in .xlsx file. 2. All input files should all be CSV or TSV. 3. First rows are freezed unless given '-H/--no-header-row'. Usage: csvtk csv2xlsx [flags] Flags: -h, --help help for csv2xlsx Examples Single input $ csvtk csv2xlsx ../testdata/names.csv -o output.xlsx # check content $ csvtk xlsx2csv -a output.xlsx index sheet 1 Sheet1 $ csvtk xlsx2csv output.xlsx | md5sum 8e9d38a012cb02279a396a2f2dbbbca9 - $ csvtk cut -f 1- ../testdata/names.csv | md5sum 8e9d38a012cb02279a396a2f2dbbbca9 - Merging multiple CSV/TSV files into one .xlsx file. $ csvtk csv2xlsx ../testdata/names*.csv -o output.xlsx $ csvtk xlsx2csv -a output.xlsx index sheet 1 names 2 names.reorder 3 names.with-unmatched-colname xlsx2csv Usage convert XLSX to CSV format Usage: csvtk xlsx2csv [flags] Flags: -h, --help help for xlsx2csv -a, --list-sheets list all sheets -i, --sheet-index int Nth sheet to retrieve (default 1) -n, --sheet-name string sheet to retrieve Examples list all sheets $ csvtk xlsx2csv ../testdata/accounts.xlsx -a index sheet 1 names 2 phones 3 region retrieve sheet by index $ csvtk xlsx2csv ../testdata/accounts.xlsx -i 3 name,region ken,nowhere gri,somewhere shenwei,another Thompson,there retrieve sheet by name $ csvtk xlsx2sv ../testdata/accounts.xlsx -n region name,region ken,nowhere gri,somewhere shenwei,another Thompson,there head Usage print first N records Usage: csvtk head [flags] Flags: -n, --number int print first N records (default 10) Examples with header line $ csvtk head -n 2 testdata/1.csv name,attr foo,cool bar,handsome no header line $ csvtk head -H -n 2 testdata/1.csv name,attr foo,cool concat Usage concatenate CSV/TSV files by rows Note that the second and later files are concatenated to the first one, so only columns match that of the first files kept. Usage: csvtk concat [flags] Flags: -h, --help help for concat -i, --ignore-case ignore case (column name) -k, --keep-unmatched keep blanks even if no any data of a file matches -u, --unmatched-repl string replacement for unmatched data Examples data $ csvtk pretty names.csv id first_name last_name username 11 Rob Pike rob 2 Ken Thompson ken 4 Robert Griesemer gri 1 Robert Thompson abc NA Robert Abel 123 $ csvtk pretty names.reorder.csv last_name username id first_name Pike rob 11 Rob Thompson ken 2 Ken Griesemer gri 4 Robert Thompson abc 1 Robert Abel 123 NA Robert $ csvtk pretty names.with-unmatched-colname.csv id2 First_name Last_name Username col 22 Rob33 Pike222 rob111 abc 44 Ken33 Thompson22 ken111 def simple one $ csvtk concat names.csv names.reorder.csv \\ | csvtk pretty id first_name last_name username 11 Rob Pike rob 2 Ken Thompson ken 4 Robert Griesemer gri 1 Robert Thompson abc NA Robert Abel 123 11 Rob Pike rob 2 Ken Thompson ken 4 Robert Griesemer gri 1 Robert Thompson abc NA Robert Abel 123 data with unmatched column names, and ignoring cases $ csvtk concat names.csv names.with-unmatched-colname.csv -i \\ | csvtk pretty id first_name last_name username 11 Rob Pike rob 2 Ken Thompson ken 4 Robert Griesemer gri 1 Robert Thompson abc NA Robert Abel 123 Rob33 Pike222 rob111 Ken33 Thompson22 ken111 $ csvtk concat names.csv names.with-unmatched-colname.csv -i -u Unmached \\ | csvtk pretty id first_name last_name username 11 Rob Pike rob 2 Ken Thompson ken 4 Robert Griesemer gri 1 Robert Thompson abc NA Robert Abel 123 Unmached Rob33 Pike222 rob111 Unmached Ken33 Thompson22 ken111 Sometimes data of one file does not matche any column, they are discared by default. But you can keep them using flag -k/--keep-unmatched $ csvtk concat names.with-unmatched-colname.csv names.csv \\ | csvtk pretty id2 First_name Last_name Username col 22 Rob33 Pike222 rob111 abc 44 Ken33 Thompson22 ken111 def $ csvtk concat names.with-unmatched-colname.csv names.csv -u -k NA \\ | csvtk pretty id2 First_name Last_name Username col 22 Rob33 Pike222 rob111 abc 44 Ken33 Thompson22 ken111 def NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA sample Usage sampling by proportion Usage: csvtk sample [flags] Flags: -h, --help help for sample -n, --line-number print line number as the first column (\"n\") -p, --proportion float sample by proportion -s, --rand-seed int rand seed (default 11) Examples $ seq 100 | csvtk sample -H -p 0.5 | wc -l 46 $ seq 100 | csvtk sample -H -p 0.5 | wc -l 46 $ seq 100 | csvtk sample -H -p 0.1 | wc -l 10 $ seq 100 | csvtk sample -H -p 0.05 -n 50,50 52,52 65,65 cut Usage select and arrange fields Examples: 1. Single column csvtk cut -f 1 csvtk cut -f colA 2. Multiple columns (replicates allowed) csvtk cut -f 1,3,2,1 csvtk cut -f colA,colB,colA 3. Column ranges csvtk cut -f 1,3-5 # 1, 3, 4, 5 csvtk cut -f 3,5- # 3rd col, and 5th col to the end csvtk cut -f 1- # for all csvtk cut -f 2-,1 # move 1th col to the end 4. Unselect csvtk cut -f -1,-3 # discard 1st and 3rd column csvtk cut -f -1--3 # discard 1st to 3rd column csvtk cut -f -2- # discard 2nd and all columns on the right. csvtu cut -f -colA,-colB # discard colA and colB Usage: csvtk cut [flags] Flags: -m, --allow-missing-col allow missing column -b, --blank-missing-col blank missing column -f, --fields string select only these fields. type \"csvtk cut -h\" for examples -F, --fuzzy-fields using fuzzy fields, e.g., -F -f \"*name\" or -F -f \"id123*\" -h, --help help for cut -i, --ignore-case ignore case (column name) -u, --uniq-column deduplicate columns matched by multiple fuzzy column names Examples data: $ cat testdata/names.csv id,first_name,last_name,username 11,\"Rob\",\"Pike\",rob 2,Ken,Thompson,ken 4,\"Robert\",\"Griesemer\",\"gri\" 1,\"Robert\",\"Thompson\",\"abc\" NA,\"Robert\",\"Abel\",\"123\" Select columns by column index: csvtk cut -f 1,2 $ cat testdata/names.csv \\ | csvtk cut -f 1,2 id,first_name 11,Rob 2,Ken 4,Robert 1,Robert NA,Robert # select more than once $ cat testdata/names.csv \\ | csvtk cut -f 1,2,2 id,first_name,first_name 11,Rob,Rob 2,Ken,Ken 4,Robert,Robert 1,Robert,Robert NA,Robert,Robert Select columns by column names: csvtk cut -f first_name,username $ cat testdata/names.csv \\ | csvtk cut -f first_name,username first_name,username Rob,rob Ken,ken Robert,gri Robert,abc Robert,123 # select more than once $ cat testdata/names.csv \\ | csvtk cut -f first_name,username,username first_name,username,username Rob,rob,rob Ken,ken,ken Robert,gri,gri Robert,abc,abc Robert,123,123 Unselect : select 3+ columns: csvtk cut -f -1,-2 $ cat testdata/names.csv \\ | csvtk cut -f -1,-2 last_name,username Pike,rob Thompson,ken Griesemer,gri Thompson,abc Abel,123 select columns except first_name : csvtk cut -f -first_name $ cat testdata/names.csv \\ | csvtk cut -f -first_name id,last_name,username 11,Pike,rob 2,Thompson,ken 4,Griesemer,gri 1,Thompson,abc NA,Abel,123 Fuzzy fields using wildcard character, csvtk cut -F -f \"*_name,username\" $ cat testdata/names.csv \\ | csvtk cut -F -f \"*_name,username\" first_name,last_name,username Rob,Pike,rob Ken,Thompson,ken Robert,Griesemer,gri Robert,Thompson,abc Robert,Abel,123 All fields: csvtk cut -F -f \"*\" or csvtk cut -f 1- . $ cat testdata/names.csv \\ | csvtk cut -F -f \"*\" id,first_name,last_name,username 11,Rob,Pike,rob 2,Ken,Thompson,ken 4,Robert,Griesemer,gri 1,Robert,Thompson,abc NA,Robert,Abel,123 Field ranges (read help message (\"csvtk cut -f\") for more examples) csvtk cut -f 2-4 for column 2,3,4 $ cat testdata/names.csv \\ | csvtk cut -f 2-4 first_name,last_name,username Rob,Pike,rob Ken,Thompson,ken Robert,Griesemer,gri Robert,Thompson,abc Robert,Abel,123 csvtk cut -f -3--1 for discarding column 1,2,3 $ cat testdata/names.csv \\ | csvtk cut -f -3--1 username rob ken gri abc 123 csvtk cut -f 2-,1 for moving 1th column to the end. $ cat testdata/names.csv \\ | csvtk cut -f 2-,1 first_name,last_name,username,id Rob,Pike,rob,11 Ken,Thompson,ken,2 Robert,Griesemer,gri,4 Robert,Thompson,abc,1 Robert,Abel,123,NA csvtk cut -f 1,1 for duplicating columns $ cat testdata/names.csv \\ | csvtk cut -f 1,1 id,id 11,11 2,2 4,4 1,1 NA,NA uniq Usage unique data without sorting Usage: csvtk uniq [flags] Flags: -f, --fields string select these fields as keys. e.g -f 1,2 or -f columnA,columnB (default \"1\") -F, --fuzzy-fields using fuzzy fields, e.g., -F -f \"*name\" or -F -f \"id123*\" -h, --help help for uniq -i, --ignore-case ignore case -n, --keep-n int keep at most N records for a key (default 1) Examples: data: $ cat testdata/names.csv id,first_name,last_name,username 11,\"Rob\",\"Pike\",rob 2,Ken,Thompson,ken 4,\"Robert\",\"Griesemer\",\"gri\" 1,\"Robert\",\"Thompson\",\"abc\" NA,\"Robert\",\"Abel\",\"123\" unique first_name (it removes rows with duplicated first_name) $ cat testdata/names.csv \\ | csvtk uniq -f first_name id,first_name,last_name,username 11,Rob,Pike,rob 2,Ken,Thompson,ken 4,Robert,Griesemer,gri unique first_name, a more common way $ cat testdata/names.csv \\ | csvtk cut -f first_name \\ | csvtk uniq -f 1 first_name Rob Ken Robert keep top 2 items for every group. $ cat testdata/players.csv gender,id,name male,1,A male,2,B male,3,C female,11,a female,12,b female,13,c female,14,d $ cat testdata/players.csv \\ | csvtk sort -k gender:N -k id:nr \\ | csvtk uniq -f gender -n 2 gender,id,name female,14,d female,13,c male,3,C male,2,B freq Usage frequencies of selected fields Usage: csvtk freq [flags] Flags: -f, --fields string select only these fields. e.g -f 1,2 or -f columnA,columnB (default \"1\") -F, --fuzzy-fields using fuzzy fields, e.g., -F -f \"*name\" or -F -f \"id123*\" -i, --ignore-case ignore case -r, --reverse reverse order while sorting -n, --sort-by-freq sort by frequency -k, --sort-by-key sort by key Examples one filed $ cat testdata/names.csv \\ | csvtk freq -f first_name | csvtk pretty first_name frequency Ken 1 Rob 1 Robert 3 sort by frequency. you can also use csvtk sort with more sorting options $ cat testdata/names.csv \\ | csvtk freq -f first_name -n -r \\ | csvtk pretty first_name frequency Robert 3 Ken 1 Rob 1 sorty by key $ cat testdata/names.csv \\ | csvtk freq -f first_name -k \\ | csvtk pretty first_name frequency Ken 1 Rob 1 Robert 3 multiple fields $ cat testdata/names.csv \\ | csvtk freq -f first_name,last_name \\ | csvtk pretty first_name last_name frequency Robert Abel 1 Ken Thompson 1 Rob Pike 1 Robert Thompson 1 Robert Griesemer 1 data without header row $ cat testdata/ testdata/digitals.tsv \\ | csvtk -t -H freq -f 1 8 1 1 1 4 1 7 1 inter Usage intersection of multiple files Attention: 1. fields in all files should be the same, if not, extracting to another file using \"csvtk cut\". Usage: csvtk inter [flags] Flags: -f, --fields string select these fields as the key. e.g -f 1,2 or -f columnA,columnB (default \"1\") -F, --fuzzy-fields using fuzzy fields, e.g., -F -f \"*name\" or -F -f \"id123*\" -i, --ignore-case ignore case Examples: $ cat testdata/phones.csv username,phone gri,11111 rob,12345 ken,22222 shenwei,999999 $ cat testdata/region.csv name,region ken,nowhere gri,somewhere shenwei,another Thompson,there $ csvtk inter testdata/phones.csv testdata/region.csv username gri ken shenwei grep Usage grep data by selected fields with patterns/regular expressions Attentions: 1. By default, we directly compare the column value with patterns, use \"-r/--use-regexp\" for partly matching. 2. Multiple patterns can be given by setting '-p/--pattern' more than once, or giving comma separated values (CSV formats). Therefore, please use double quotation marks for patterns containing comma, e.g., -p '\"A{2,}\"' Usage: csvtk grep [flags] Flags: --delete-matched delete a pattern right after being matched, this keeps the firstly matched data and speedups when using regular expressions -f, --fields string comma separated key fields, column name or index. e.g. -f 1-3 or -f id,id2 or -F -f \"group*\" (default \"1\") -F, --fuzzy-fields using fuzzy fields, e.g., -F -f \"*name\" or -F -f \"id123*\" -h, --help help for grep -i, --ignore-case ignore case --immediate-output print output immediately, do not use write buffer -v, --invert invert match -n, --line-number print line number as the first column (\"n\") -N, --no-highlight no highlight -p, --pattern strings query pattern (multiple values supported). Attention: use double quotation marks for patterns containing comma, e.g., -p '\"A{2,}\"' -P, --pattern-file string pattern files (one pattern per line) -r, --use-regexp patterns are regular expression --verbose verbose output Examples Matched parts will be highlight . By exact keys $ cat testdata/names.csv \\ | csvtk grep -f last_name -p Pike -p Abel \\ | csvtk pretty id first_name last_name username 11 Rob Pike rob NA Robert Abel 123 # another form of multiple keys $ csvtk grep -f last_name -p Pike,Abel,Tom By regular expression: csvtk grep -f first_name -r -p Rob $ cat testdata/names.csv \\ | csvtk grep -f first_name -r -p Rob \\ | csvtk pretty id first_name last_name username 11 Rob Pike rob 4 Robert Griesemer gri 1 Robert Thompson abc NA Robert Abel 123 By pattern list $ csvtk grep -f first_name -P name_list.txt Remore rows containing any missing data (NA): $ csvtk grep -F -f \"*\" -r -p \"^$\" -v Show line number $ cat names.csv \\ | csvtk pretty id first_name last_name username 11 Rob Pike rob 2 Ken Thompson ken 4 Robert Griesemer gri 1 Robert Thompson abc NA Robert Abel 123 $ cat names.csv \\ | csvtk grep -f first_name -r -i -p rob -n \\ | csvtk pretty n id first_name last_name username 1 11 Rob Pike rob 3 4 Robert Griesemer gri 4 1 Robert Thompson abc 5 NA Robert Abel 123 filter Usage filter rows by values of selected fields with arithmetic expression Usage: csvtk filter [flags] Flags: --any print record if any of the field satisfy the condition -f, --filter string filter condition. e.g. -f \"age>12\" or -f \"1,3<=2\" or -F -f \"c*!=0\" -F, --fuzzy-fields using fuzzy fields, e.g., -F -f \"*name\" or -F -f \"id123*\" -h, --help help for filter -n, --line-number print line number as the first column (\"n\") Examples single field $ cat testdata/names.csv id,first_name,last_name,username 11,\"Rob\",\"Pike\",rob 2,Ken,Thompson,ken 4,\"Robert\",\"Griesemer\",\"gri\" 1,\"Robert\",\"Thompson\",\"abc\" NA,\"Robert\",\"Abel\",\"123\" $ cat testdata/names.csv \\ | csvtk filter -f \"id>0\" \\ | csvtk pretty id first_name last_name username 11 Rob Pike rob 2 Ken Thompson ken 4 Robert Griesemer gri 1 Robert Thompson abc multiple fields $ cat testdata/digitals.tsv 4 5 6 1 2 3 7 8 0 8 1,000 4 $ cat testdata/digitals.tsv \\ | csvtk -t -H filter -f \"1-3>0\" 4 5 6 1 2 3 8 1,000 4 using --any to print record if any of the field satisfy the condition $ cat testdata/digitals.tsv \\ | csvtk -t -H filter -f \"1-3>0\" --any 4 5 6 1 2 3 7 8 0 8 1,000 4 fuzzy fields $ cat testdata/names.csv \\ | csvtk filter -F -f \"i*!=0\" id,first_name,last_name,username 11,Rob,Pike,rob 2,Ken,Thompson,ken 4,Robert,Griesemer,gri 1,Robert,Thompson,abc filter2 Usage filter rows by awk-like arithmetic/string expressions The arithmetic/string expression is supported by: https://github.com/Knetic/govaluate Supported operators and types: Modifiers: + - / * & | ^ ** % >> << Comparators: > >= < <= == != =~ !~ Logical ops: || && Numeric constants, as 64-bit floating point (12345.678) String constants (single quotes: 'foobar') Date constants (single quotes) Boolean constants: true false Parenthesis to control order of evaluation ( ) Arrays (anything separated by , within parenthesis: (1, 2, 'foo')) Prefixes: ! - ~ Ternary conditional: ? : Null coalescence: ?? Custom functions: - len(), length of strings, e.g., len($1), len($a), len($1, $2) - ulen(), length of unicode strings/width of unicode strings rendered to a terminal, e.g., len(\"\u6c88\u4f1f\")==6, ulen(\"\u6c88\u4f1f\")==4 Usage: csvtk filter2 [flags] Flags: -f, --filter string awk-like filter condition. e.g. '$age>12' or '$1 > $3' or '$name==\"abc\"' or '$1 % 2 == 0' -h, --help help for filter2 -n, --line-number print line number as the first column (\"n\") -s, --numeric-as-string treat even numeric fields as strings to avoid converting big numbers into scientific notation Examples: filter rows with id greater than 3: $ cat testdata/names.csv id,first_name,last_name,username 11,\"Rob\",\"Pike\",rob 2,Ken,Thompson,ken 4,\"Robert\",\"Griesemer\",\"gri\" 1,\"Robert\",\"Thompson\",\"abc\" NA,\"Robert\",\"Abel\",\"123\" $ cat testdata/names.csv \\ | csvtk filter2 -f '$id > 3' id,first_name,last_name,username 11,Rob,Pike,rob 4,Robert,Griesemer,gri arithmetic and string expressions $ cat testdata/names.csv \\ | csvtk filter2 -f '$id > 3 || $username==\"ken\"' id,first_name,last_name,username 11,Rob,Pike,rob 2,Ken,Thompson,ken 4,Robert,Griesemer,gri More arithmetic expressions $ cat testdata/digitals.tsv 4 5 6 1 2 3 7 8 0 8 1,000 4 $ cat testdata/digitals.tsv \\ | csvtk filter2 -H -t -f '$1 > 2 && $2 % 2 == 0' 7 8 0 8 1,000 4 # comparison between fields and support $ cat testdata/digitals.tsv \\ | csvtk filter2 -H -t -f '$2 <= $3 || ( $1 / $2 > 0.5 )' 4 5 6 1 2 3 7 8 0 join Usage join files by selected fields (inner, left and outer join). Attention: 1. Multiple keys supported 2. Default operation is inner join, use --left-join for left join and --outer-join for outer join. Usage: csvtk join [flags] Aliases: join, merge Flags: -f, --fields string Semicolon separated key fields of all files, if given one, we think all the files have the same key columns. Fields of different files should be separated by \";\", e.g -f \"1;2\" or -f \"A,B;C,D\" or -f id (default \"1\") -F, --fuzzy-fields using fuzzy fields, e.g., -F -f \"*name\" or -F -f \"id123*\" -h, --help help for join -i, --ignore-case ignore case -n, --ignore-null do not match NULL values -k, --keep-unmatched keep unmatched data of the first file (left join) -L, --left-join left join, equals to -k/--keep-unmatched, exclusive with --outer-join --na string content for filling NA data -O, --outer-join outer join, exclusive with --left-join Examples: data $ cat testdata/phones.csv username,phone gri,11111 rob,12345 ken,22222 shenwei,999999 $ cat testdata/region.csv name,region ken,nowhere gri,somewhere shenwei,another Thompson,there All files have same key column: csvtk join -f id file1.csv file2.csv $ csvtk join -f 1 testdata/phones.csv testdata/region.csv \\ | csvtk pretty username phone region gri 11111 somewhere ken 22222 nowhere shenwei 999999 another keep unmatched (left join) $ csvtk join -f 1 testdata/phones.csv testdata/region.csv --left-join \\ | csvtk pretty username phone region gri 11111 somewhere rob 12345 ken 22222 nowhere shenwei 999999 another keep unmatched and fill with something $ csvtk join -f 1 testdata/phones.csv testdata/region.csv --left-join --na NA \\ | csvtk pretty username phone region gri 11111 somewhere rob 12345 NA ken 22222 nowhere shenwei 999999 another Outer join $ csvtk join -f 1 testdata/phones.csv testdata/region.csv --outer-join --na NA \\ | csvtk pretty username phone region gri 11111 somewhere rob 12345 NA ken 22222 nowhere shenwei 999999 another Thompson NA there Files have different key columns: csvtk join -f \"username;username;name\" testdata/names.csv phone.csv adress.csv -k . Note that fields are separated with ; not , . $ csvtk join -f \"username;name\" testdata/phones.csv testdata/region.csv --left-join --na NA \\ | csvtk pretty username phone region gri 11111 somewhere rob 12345 NA ken 22222 nowhere shenwei 999999 another Some special cases $ cat testdata/1.csv name,attr foo,cool bar,handsome bob,beutiful $ cat testdata/2.csv name,major bar,bioinformatics bob,microbiology bob,computer science $ cat testdata/3.csv id,name,hobby 1,bar,baseball 2,bob,basketball 3,foo,football 4,wei,programming # nothing special $ csvtk join testdata/{1,2,3}.csv -f name --outer-join --na NA \\ | csvtk pretty name attr major id hobby foo cool NA 3 football bar handsome bioinformatics 1 baseball bob beutiful microbiology 2 basketball bob beutiful computer science 2 basketball wei NA NA 4 programming # just reorder files $ csvtk join testdata/{3,2,1}.csv -f name --outer-join --na NA \\ | csvtk pretty id name hobby major attr 1 bar baseball bioinformatics handsome 2 bob basketball microbiology beutiful 2 bob basketball computer science beutiful 3 foo football NA cool 4 wei programming NA NA # special case: names in 3.csv contain all names in all files $ csvtk join testdata/{3,2,1}.csv -f name --left-join --na NA \\ | csvtk pretty id name hobby major attr 1 bar baseball bioinformatics handsome 2 bob basketball microbiology beutiful 2 bob basketball computer science beutiful 3 foo football NA cool 4 wei programming NA NA split Usage split CSV/TSV into multiple files according to column values Note: 1. flag -o/--out-file can specify out directory for splitted files Usage: csvtk split [flags] Flags: -g, --buf-groups int buffering N groups before writing to file (default 100) -b, --buf-rows int buffering N rows for every group before writing to file (default 100000) -f, --fields string comma separated key fields, column name or index. e.g. -f 1-3 or -f id,id2 or -F -f \"group*\" (default \"1\") -F, --fuzzy-fields using fuzzy fields, e.g., -F -f \"*name\" or -F -f \"id123*\" -h, --help help for split -i, --ignore-case ignore case -G, --out-gzip force output gzipped file Examples Test data $ cat names.csv id,first_name,last_name,username 11,\"Rob\",\"Pike\",rob 2,Ken,Thompson,ken 4,\"Robert\",\"Griesemer\",\"gri\" 1,\"Robert\",\"Thompson\",\"abc\" NA,\"Robert\",\"Abel\",\"123\" split according to first_name $ csvtk split names.csv -f first_name $ ls *.csv names.csv names-Ken.csv names-Rob.csv names-Robert.csv $ cat names-Ken.csv id,first_name,last_name,username 2,Ken,Thompson,ken $ cat names-Rob.csv id,first_name,last_name,username 11,Rob,Pike,rob $ cat names-Robert.csv id,first_name,last_name,username 4,Robert,Griesemer,gri 1,Robert,Thompson,abc NA,Robert,Abel,123 split according to first_name and last_name $ csvtk split names.csv -f first_name,last_name $ ls *.csv names.csv names-Robert-Abel.csv names-Robert-Thompson.csv names-Ken-Thompson.csv names-Robert-Griesemer.csv names-Rob-Pike.csv flag -o/--out-file can specify out directory for splitted files $ seq 10000 | csvtk split -H -o result $ ls result/*.csv | wc -l 10000 extreme example 1: lots (1M) of rows in groups $ yes 2 | head -n 10000000 | gzip -c > t.gz $ memusg -t csvtk -H split t.gz elapsed time: 7.959s peak rss: 35.7 MB # check $ zcat t-2.gz | wc -l 10000000 $ zcat t-2.gz | md5sum f194afd7cecf645c0e3cce50c9bc526e - $ zcat t.gz | md5sum f194afd7cecf645c0e3cce50c9bc526e - extreme example 2: lots (10K) of groups $ seq 10000 | gzip -c > t2.gz $ memusg -t csvtk -H split t2.gz -o t2 elapsed time: 20.856s peak rss: 23.77 MB # check $ ls t2/*.gz | wc -l 10000 $ zcat t2/*.gz | sort -k 1,1n | md5sum 72d4ff27a28afbc066d5804999d5a504 - $ zcat t2.gz | md5sum 72d4ff27a28afbc066d5804999d5a504 - splitxlsx Usage split XLSX sheet into multiple sheets according to column values Strengths: Sheet properties are remained unchanged. Weakness : Complicated sheet structures are not well supported, e.g., 1. merged cells 2. more than one header row Usage: csvtk splitxlsx [flags] Flags: -f, --fields string comma separated key fields, column name or index. e.g. -f 1-3 or -f id,id2 or -F -f \"group*\" (default \"1\") -F, --fuzzy-fields using fuzzy fields, e.g., -F -f \"*name\" or -F -f \"id123*\" -h, --help help for splitxlsx -i, --ignore-case ignore case (cell value) -a, --list-sheets list all sheets -N, --sheet-index int Nth sheet to retrieve (default 1) -n, --sheet-name string sheet to retrieve Examples example data # list all sheets $ csvtk xlsx2csv -a accounts.xlsx index sheet 1 names 2 phones 3 region # data of sheet \"names\" $ csvtk xlsx2csv accounts.xlsx | csvtk pretty id first_name last_name username 11 Rob Pike rob 2 Ken Thompson ken 4 Robert Griesemer gri 1 Robert Thompson abc NA Robert Abel 123 split sheet \"names\" according to first_name $ csvtk splitxlsx accounts.xlsx -n names -f first_name $ ls accounts.* accounts.split.xlsx accounts.xlsx $ csvtk splitxlsx -a accounts.split.xlsx index sheet 1 names 2 phones 3 region 4 Rob 5 Ken 6 Robert $ csvtk xlsx2csv accounts.split.xlsx -n Rob \\ | csvtk pretty id first_name last_name username 11 Rob Pike rob $ csvtk xlsx2csv accounts.split.xlsx -n Robert \\ | csvtk pretty id first_name last_name username 4 Robert Griesemer gri 1 Robert Thompson abc NA Robert Abel 123 comb Usage compute combinations of items at every row Usage: csvtk comb [flags] Aliases: comb, combination Flags: -h, --help help for comb -i, --ignore-case ignore-case -S, --nat-sort sort items in natural order -n, --number int number of items in a combination, 0 for no limit, i.e., return all combinations (default 2) -s, --sort sort items in a combination Examples: $ cat players.csv gender,id,name male,1,A male,2,B male,3,C female,11,a female,12,b female,13,c female,14,d # put names of one group in one row $ cat players.csv \\ | csvtk collapse -f 1 -v 3 -s ';' \\ | csvtk cut -f 2 name A;B;C a;b;c;d # n = 2 $ cat players.csv \\ | csvtk collapse -f 1 -v 3 -s ';' \\ | csvtk cut -f 2 \\ | csvtk comb -d ';' -n 2 A,B A,C B,C a,b a,c b,c a,d b,d c,d # n = 3 $ cat players.csv \\ | csvtk collapse -f 1 -v 3 -s ';' \\ | csvtk cut -f 2 \\ | csvtk comb -d ';' -n 3 A,B,C a,b,c a,b,d a,c,d b,c,d # n = 0 $ cat players.csv \\ | csvtk collapse -f 1 -v 3 -s ';' \\ | csvtk cut -f 2 \\ | csvtk comb -d ';' -n 0 A B A,B C A,C B,C A,B,C a b a,b c a,c b,c a,b,c d a,d b,d a,b,d c,d a,c,d b,c,d a,b,c,d add-header Usage add column names Usage: csvtk add-header [flags] Flags: -h, --help help for add-header -n, --names strings column names to add, in CSV format Examples: No new colnames given: $ seq 3 | csvtk mutate -H \\ | csvtk add-header [WARN] colnames not given, c1, c2, c3... will be used c1,c2 1,1 2,2 3,3 Adding new colnames: $ seq 3 | csvtk mutate -H \\ | csvtk add-header -n a,b a,b 1,1 2,2 3,3 $ seq 3 | csvtk mutate -H \\ | csvtk add-header -n a -n b a,b 1,1 2,2 3,3 $ seq 3 | csvtk mutate -H -t \\ | csvtk add-header -t -n a,b a b 1 1 2 2 3 3 del-header Usage delete column names Usage: csvtk del-header [flags] Flags: -h, --help help for del-header Examples: $ seq 3 | csvtk add-header c1 1 2 3 $ seq 3 | csvtk add-header | csvtk del-header 1 2 3 $ seq 3 | csvtk del-header -H 1 2 3 rename Usage rename column names with new names Usage: csvtk rename [flags] Flags: -f, --fields string select only these fields. e.g -f 1,2 or -f columnA,columnB -F, --fuzzy-fields using fuzzy fields, e.g., -F -f \"*name\" or -F -f \"id123*\" -n, --names string comma separated new names Examples: Setting new names: csvtk rename -f A,B -n a,b or csvtk rename -f 1-3 -n a,b,c $ cat testdata/phones.csv username,phone gri,11111 rob,12345 ken,22222 shenwei,999999 $ cat testdata/phones.csv \\ | csvtk rename -f 1-2 -n \u59d3\u540d,\u7535\u8bdd \\ | csvtk pretty \u59d3\u540d \u7535\u8bdd gri 11111 rob 12345 ken 22222 shenwei 999999 rename2 Usage rename column names by regular expression Special replacement symbols: {nr} ascending number, starting from 1 {kv} Corresponding value of the key (captured variable $n) by key-value file, n can be specified by flag --key-capt-idx (default: 1) Usage: csvtk rename2 [flags] Flags: -f, --fields string select only these fields. e.g -f 1,2 or -f columnA,columnB -F, --fuzzy-fields using fuzzy fields, e.g., -F -f \"*name\" or -F -f \"id123*\" -h, --help help for rename2 -i, --ignore-case ignore case -K, --keep-key keep the key as value when no value found for the key --key-capt-idx int capture variable index of key (1-based) (default 1) --key-miss-repl string replacement for key with no corresponding value -k, --kv-file string tab-delimited key-value file for replacing key with value when using \"{kv}\" in -r (--replacement) -p, --pattern string search regular expression -r, --replacement string renamement. supporting capture variables. e.g. $1 represents the text of the first submatch. ATTENTION: use SINGLE quote NOT double quotes in *nix OS or use the \\ escape character. Ascending number is also supported by \"{nr}\".use ${1} instead of $1 when {kv} given! Examples: Add suffix to all column names. $ cat testdata/phones.csv username,phone gri,11111 rob,12345 ken,22222 shenwei,999999 $ cat testdata/phones.csv \\ | csvtk rename2 -F -f \"*\" -p \"(.*)\" -r 'prefix_${1}_suffix' prefix_username_suffix,prefix_phone_suffix gri,11111 rob,12345 ken,22222 shenwei,999999 supporting {kv} and {nr} in csvtk replace . e.g., replace barcode with sample name. $ cat barcodes.tsv Sample Barcode sc1 CCTAGATTAAT sc2 GAAGACTTGGT sc3 GAAGCAGTATG sc4 GGTAACCTGAC sc5 ATAGTTCTCGT $ cat table.tsv gene ATAGTTCTCGT GAAGCAGTATG GAAGACTTGGT AAAAAAAAAA gene1 0 0 3 0 gen1e2 0 0 0 0 # note that, we must arrange the order of barcodes.tsv to KEY-VALUE $ csvtk cut -t -f 2,1 barcodes.tsv Barcode Sample CCTAGATTAAT sc1 GAAGACTTGGT sc2 GAAGCAGTATG sc3 GGTAACCTGAC sc4 ATAGTTCTCGT sc5 # here we go!!!! $ csvtk rename2 -t -k <(csvtk cut -t -f 2,1 barcodes.tsv) \\ -f -1 -p '(.+)' -r '{kv}' --key-miss-repl unknown table.tsv gene sc5 sc3 sc2 unknown gene1 0 0 3 0 gen1e2 0 0 0 0 {nr} , incase you need this $ echo \"a,b,c,d\" \\ | csvtk rename2 -p '(.+)' -r 'col_{nr}' -f -1 --start-num 2 a,col_2,col_3,col_4 replace Usage replace data of selected fields by regular expression Note that the replacement supports capture variables. e.g. $1 represents the text of the first submatch. ATTENTION: use SINGLE quote NOT double quotes in *nix OS. Examples: Adding space to cell values. csvtk replace -p \"(.)\" -r '$1 ' Or use the \\ escape character. csvtk replace -p \"(.)\" -r \"\\$1 \" more on: http://shenwei356.github.io/csvtk/usage/#replace Special replacement symbols: {nr} Record number, starting from 1 {kv} Corresponding value of the key (captured variable $n) by key-value file, n can be specified by flag --key-capt-idx (default: 1) Usage: csvtk replace [flags] Flags: -f, --fields string select only these fields. e.g -f 1,2 or -f columnA,columnB (default \"1\") -F, --fuzzy-fields using fuzzy fields, e.g., -F -f \"*name\" or -F -f \"id123*\" -i, --ignore-case ignore case -K, --keep-key keep the key as value when no value found for the key --key-capt-idx int capture variable index of key (1-based) (default 1) --key-miss-repl string replacement for key with no corresponding value -k, --kv-file string tab-delimited key-value file for replacing key with value when using \"{kv}\" in -r (--replacement) -p, --pattern string search regular expression -r, --replacement string replacement. supporting capture variables. e.g. $1 represents the text of the first submatch. ATTENTION: for *nix OS, use SINGLE quote NOT double quotes or use the \\ escape character. Record number is also supported by \"{nr}\".use ${1} instead of $1 when {kv} given! Examples remove Chinese charactors $ csvtk replace -F -f \"*_name\" -p \"\\p{Han}+\" -r \"\" replace by key-value files $ cat data.tsv name id A ID001 B ID002 C ID004 $ cat alias.tsv 001 Tom 002 Bob 003 Jim $ csvtk replace -t -f 2 -p \"ID(.+)\" -r \"N: {nr}, alias: {kv}\" -k alias.tsv data.tsv [INFO] read key-value file: alias.tsv [INFO] 3 pairs of key-value loaded name id A N: 1, alias: Tom B N: 2, alias: Bob C N: 3, alias: 004 round Usage round float to n decimal places Usage: csvtk round [flags] Flags: -a, --all-fields all fields, overides -f/--fields -n, --decimal-width int limit floats to N decimal points (default 2) -f, --fields string select only these fields. e.g -f 1,2 or -f columnA,columnB (default \"1\") -F, --fuzzy-fields using fuzzy fields, e.g., -F -f \"*name\" or -F -f \"id123*\" -h, --help help for round Examples: $ cat testdata/floats.csv | csvtk pretty a b 0.12345 abc NA 0.9999198549640733 12.3 e3 1.4814505299984235e-05 -3.1415926E05 # one or more fields $ cat testdata/floats.csv | csvtk round -n 2 -f b | csvtk pretty a b 0.12345 abc NA 1.00 12.3 e3 1.4814505299984235e-05 -3.14E05 # all fields $ cat testdata/floats.csv | csvtk round -n 2 -a | csvtk pretty a b 0.12 abc NA 1.00 12.30 e3 1.48e-05 -3.14E05 mutate Usage create new column from selected fields by regular expression Usage: csvtk mutate [flags] Flags: -f, --fields string select only these fields. e.g -f 1,2 or -f columnA,columnB (default \"1\") -i, --ignore-case ignore case --na for unmatched data, use blank instead of original data -n, --name string new column name -p, --pattern string search regular expression with capture bracket. e.g. (default \"^(.+)$\") Examples By default, copy a column: csvtk mutate -f id -n newname Extract prefix of data as group name using regular expression (get \"A\" from \"A.1\" as group name): csvtk mutate -f sample -n group -p \"^(.+?)\\.\" get the first letter as new column $ cat testdata/phones.csv username,phone gri,11111 rob,12345 ken,22222 shenwei,999999 $ cat testdata/phones.csv \\ | csvtk mutate -f username -p \"^(\\w)\" -n first_letter username,phone,first_letter gri,11111,g rob,12345,r ken,22222,k shenwei,999999,s mutate2 Usage create new column from selected fields by awk-like arithmetic/string expressions The arithmetic/string expression is supported by: https://github.com/Knetic/govaluate Supported operators and types: Modifiers: + - / * & | ^ ** % >> << Comparators: > >= < <= == != =~ !~ Logical ops: || && Numeric constants, as 64-bit floating point (12345.678) String constants (single quotes: 'foobar') Date constants (single quotes) Boolean constants: true false Parenthesis to control order of evaluation ( ) Arrays (anything separated by , within parenthesis: (1, 2, 'foo')) Prefixes: ! - ~ Ternary conditional: ? : Null coalescence: ?? Custom functions: - len(), length of strings, e.g., len($1), len($a), len($1, $2) - ulen(), length of unicode strings/width of unicode strings rendered to a terminal, e.g., len(\"\u6c88\u4f1f\")==6, ulen(\"\u6c88\u4f1f\")==4 Usage: csvtk mutate2 [flags] Flags: -w, --decimal-width int limit floats to N decimal points (default 2) -e, --expression string arithmetic/string expressions. e.g. \"'string'\", '\"abc\"', ' $a + \"-\" + $b ', '$1 + $2', '$a / $b', ' $1 > 100 ? \"big\" : \"small\" ' -h, --help help for mutate2 -n, --name string new column name -s, --numeric-as-string treat even numeric fields as strings to avoid converting big numbers into scientific notation Example Constants $ cat testdata/digitals.tsv \\ | csvtk mutate2 -t -H -e \" 'abc' \" 4 5 6 abc 1 2 3 abc 7 8 0 abc 8 1,000 4 abc $ val=123 \\ && cat testdata/digitals.tsv \\ | csvtk mutate2 -t -H -e \" $val \" 4 5 6 123 1 2 3 123 7 8 0 123 8 1,000 4 123 String concatenation $ cat testdata/names.csv \\ | csvtk mutate2 -n full_name -e ' $first_name + \" \" + $last_name ' \\ | csvtk pretty id first_name last_name username full_name 11 Rob Pike rob Rob Pike 2 Ken Thompson ken Ken Thompson 4 Robert Griesemer gri Robert Griesemer 1 Robert Thompson abc Robert Thompson NA Robert Abel 123 Robert Abel Math $ cat testdata/digitals.tsv | csvtk mutate2 -t -H -e '$1 + $3' -L 0 4 5 6 10 1 2 3 4 7 8 0 7 8 1,000 4 12 Bool $ cat testdata/digitals.tsv | csvtk mutate2 -t -H -e '$1 > 5' 4 5 6 false 1 2 3 false 7 8 0 true 8 1,000 4 true Ternary condition ( ? : ) $ cat testdata/digitals.tsv | csvtk mutate2 -t -H -e '$1 > 5 ? \"big\" : \"small\" ' 4 5 6 small 1 2 3 small 7 8 0 big 8 1,000 4 big Null coalescence ( ?? ) $ echo -e \"one,two\\na1,a2\\n,b2\\na2,\" | csvtk pretty one two --- --- a1 a2 b2 a2 $ echo -e \"one,two\\na1,a2\\n,b2\\na2,\" \\ | csvtk mutate2 -n three -e '$one ?? $two' \\ | csvtk pretty one two three --- --- ----- a1 a2 a1 b2 b2 a2 a2 sep Usage separate column into multiple columns Usage: csvtk sep [flags] Flags: --drop drop extra data, exclusive with --merge -f, --fields string select only these fields. e.g -f 1,2 or -f columnA,columnB (default \"1\") -h, --help help for sep -i, --ignore-case ignore case --merge only splits at most N times, exclusive with --drop --na string content for filling NA data -n, --names strings new column names -N, --num-cols int preset number of new created columns -R, --remove remove input column -s, --sep string separator -r, --use-regexp separator is a regular expression Examples: $ cat players.csv | csvtk collapse -f 1 -v 3 -s ';' gender,name male,A;B;C female,a;b;c;d # set number of new columns as 3. $ cat players.csv | csvtk collapse -f 1 -v 3 -s ';' \\ | csvtk sep -f 2 -s ';' -n p1,p2,p3,p4 -N 4 --na NA \\ | csvtk pretty gender name p1 p2 p3 p4 male A;B;C A B C NA female a;b;c;d a b c d # set number of new columns as 3, drop extra values $ cat players.csv | csvtk collapse -f 1 -v 3 -s ';' \\ | csvtk sep -f 2 -s ';' -n p1,p2,p3 --drop \\ | csvtk pretty gender name p1 p2 p3 male A;B;C A B C female a;b;c;d a b c # set number of new columns as 3, split as most 3 parts $ cat players.csv | csvtk collapse -f 1 -v 3 -s ';' \\ | csvtk sep -f 2 -s ';' -n p1,p2,p3 --merge \\ | csvtk pretty gender name p1 p2 p3 male A;B;C A B C female a;b;c;d a b c;d # $ echo -ne \"taxid\\tlineage\\n9606\\tEukaryota;Chordata;Mammalia;Primates;Hominidae;Homo;Homo sapiens\\n\" taxid lineage 9606 Eukaryota;Chordata;Mammalia;Primates;Hominidae;Homo;Homo sapiens $ echo -ne \"taxid\\tlineage\\n9606\\tEukaryota;Chordata;Mammalia;Primates;Hominidae;Homo;Homo sapiens\\n\" \\ | csvtk sep -t -f 2 -s ';' -n kindom,phylum,class,order,family,genus,species --remove \\ | csvtk pretty -t taxid kindom phylum class order family genus species 9606 Eukaryota Chordata Mammalia Primates Hominidae Homo Homo sapiens gather Usage gather columns into key-value pairs Usage: csvtk gather [flags] Flags: -f, --fields string fields for gathering. e.g -f 1,2 or -f columnA,columnB, or -f -columnA for unselect columnA -F, --fuzzy-fields using fuzzy fields, e.g., -F -f \"*name\" or -F -f \"id123*\" -k, --key string name of key column to create in output -v, --value string name of value column to create in output Examples: $ cat testdata/names.csv id,first_name,last_name,username 11,\"Rob\",\"Pike\",rob 2,Ken,Thompson,ken 4,\"Robert\",\"Griesemer\",\"gri\" 1,\"Robert\",\"Thompson\",\"abc\" NA,\"Robert\",\"Abel\",\"123 $ cat testdata/names.csv \\ | csvtk gather -k item -v value -f -1 id,item,value 11,first_name,Rob 11,last_name,Pike 11,username,rob 2,first_name,Ken 2,last_name,Thompson 2,username,ken 4,first_name,Robert 4,last_name,Griesemer 4,username,gri 1,first_name,Robert 1,last_name,Thompson 1,username,abc NA,first_name,Robert NA,last_name,Abel NA,username,123 unfold Usage unfold multiple values in cells of a field Example: $ echo -ne \"id,values,meta\\n1,a;b,12\\n2,c,23\\n3,d;e;f,34\\n\" \\ | csvtk pretty id values meta 1 a;b 12 2 c 23 3 d;e;f 34 $ echo -ne \"id,values,meta\\n1,a;b,12\\n2,c,23\\n3,d;e;f,34\\n\" \\ | csvtk unfold -f values -s \";\" \\ | csvtk pretty id values meta 1 a 12 1 b 12 2 c 23 3 d 34 3 e 34 3 f 34 Usage: csvtk unfold [flags] Flags: -f, --fields string field to expand, only one field is allowed. type \"csvtk unfold -h\" for examples -h, --help help for unfold -s, --separater string separater for folded values (default \"; \") fold Usage fold multiple values of a field into cells of groups Attention: Only grouping fields and value filed are outputted. Example: $ echo -ne \"id,value,meta\\n1,a,12\\n1,b,34\\n2,c,56\\n2,d,78\\n\" \\ | csvtk pretty id value meta 1 a 12 1 b 34 2 c 56 2 d 78 $ echo -ne \"id,value,meta\\n1,a,12\\n1,b,34\\n2,c,56\\n2,d,78\\n\" \\ | csvtk fold -f id -v value -s \";\" \\ | csvtk pretty id value 1 a;b 2 c;d $ echo -ne \"id,value,meta\\n1,a,12\\n1,b,34\\n2,c,56\\n2,d,78\\n\" \\ | csvtk fold -f id -v value -s \";\" \\ | csvtk unfold -f value -s \";\" \\ | csvtk pretty id value 1 a 1 b 2 c 2 d Usage: csvtk fold [flags] Aliases: fold, collapse Flags: -f, --fields string key fields for grouping. e.g -f 1,2 or -f columnA,columnB (default \"1\") -F, --fuzzy-fields using fuzzy fields (only for key fields), e.g., -F -f \"*name\" or -F -f \"id123*\" -h, --help help for fold -i, --ignore-case ignore case -s, --separater string separater for folded values (default \"; \") -v, --vfield string value field for folding examples data $ csvtk pretty teachers.csv lab teacher class computational biology Tom Bioinformatics computational biology Tom Statistics computational biology Rob Bioinformatics sequencing center Jerry Bioinformatics sequencing center Nick Molecular Biology sequencing center Nick Microbiology List teachers for every lab/class. uniq is used to deduplicate items. $ cat teachers.csv \\ | csvtk uniq -f lab,teacher \\ | csvtk fold -f lab -v teacher \\ | csvtk pretty lab teacher computational biology Tom; Rob sequencing center Jerry; Nick $ cat teachers.csv \\ | csvtk uniq -f class,teacher \\ | csvtk fold -f class -v teacher -s \", \" \\ | csvtk pretty class teacher Statistics Tom Bioinformatics Tom, Rob, Jerry Molecular Biology Nick Microbiology Nick Multiple key fields supported $ cat teachers.csv \\ | csvtk fold -f teacher,lab -v class \\ | csvtk pretty teacher lab class Tom computational biology Bioinformatics; Statistics Rob computational biology Bioinformatics Jerry sequencing center Bioinformatics Nick sequencing center Molecular Biology; Microbiology fmtdate Usage format date of selected fields Date parsing is supported by: https://github.com/araddon/dateparse Date formating is supported by: https://github.com/metakeule/fmtdate Time zones: format: Asia/Shanghai whole list: https://en.wikipedia.org/wiki/List_of_tz_database_time_zones Output format is in MS Excel (TM) syntax. Placeholders: M - month (1) MM - month (01) MMM - month (Jan) MMMM - month (January) D - day (2) DD - day (02) DDD - day (Mon) DDDD - day (Monday) YY - year (06) YYYY - year (2006) hh - hours (15) mm - minutes (04) ss - seconds (05) AM/PM hours: 'h' followed by optional 'mm' and 'ss' followed by 'pm', e.g. hpm - hours (03PM) h:mmpm - hours:minutes (03:04PM) h:mm:sspm - hours:minutes:seconds (03:04:05PM) Time zones: a time format followed by 'ZZZZ', 'ZZZ' or 'ZZ', e.g. hh:mm:ss ZZZZ (16:05:06 +0100) hh:mm:ss ZZZ (16:05:06 CET) hh:mm:ss ZZ (16:05:06 +01:00) Usage: csvtk fmtdate [flags] Flags: -f, --fields string select only these fields. e.g -f 1,2 or -f columnA,columnB (default \"1\") --format string output date format in MS Excel (TM) syntax, type \"csvtk fmtdate -h\" for details (default \"YYYY-MM-DD hh:mm:ss\") -F, --fuzzy-fields using fuzzy fields, e.g., -F -f \"*name\" or -F -f \"id123*\" -h, --help help for fmtdate -k, --keep-unparsed keep the key as value when no value found for the key -z, --time-zone string timezone aka \"Asia/Shanghai\" or \"America/Los_Angeles\" formatted time-zone, type \"csvtk fmtdate -h\" for details Examples $ csvtk xlsx2csv date.xlsx | csvtk pretty data value ------------------- ----- 2021-08-25 11:24:21 1 08/25/21 11:24 p8 2 NA 3 4 $ csvtk xlsx2csv date.xlsx \\ | csvtk fmtdate --format \"YYYY-MM-DD hh:mm:ss\" \\ | csvtk pretty data value ------------------- ----- 2021-08-25 11:24:21 1 2021-08-25 11:24:00 2 3 4 $ csvtk xlsx2csv date.xlsx \\ | csvtk fmtdate --format \"YYYY-MM-DD hh:mm:ss\" -k \\ | csvtk pretty data value ------------------- ----- 2021-08-25 11:24:21 1 2021-08-25 11:24:00 2 NA 3 4 sort Usage sort by selected fields Usage: csvtk sort [flags] Flags: -h, --help help for sort -i, --ignore-case ignore-case -k, --keys strings keys (multiple values supported). sort type supported, \"N\" for natural order, \"n\" for number, \"u\" for user-defined order and \"r\" for reverse. e.g., \"-k 1\" or \"-k A:r\" or \"\"-k 1:nr -k 2\" (default [1]) -L, --levels strings user-defined level file (one level per line, multiple values supported). format: <field>:<level-file>. e.g., \"-k name:u -L name:level.txt\" Examples data $ cat testdata/names.csv id,first_name,last_name,username 11,\"Rob\",\"Pike\",rob 2,Ken,Thompson,ken 4,\"Robert\",\"Griesemer\",\"gri\" 1,\"Robert\",\"Thompson\",\"abc\" NA,\"Robert\",\"Abel\",\"123\" By single column : csvtk sort -k 1 or csvtk sort -k last_name in alphabetical order $ cat testdata/names.csv \\ | csvtk sort -k first_name id,first_name,last_name,username 2,Ken,Thompson,ken 11,Rob,Pike,rob NA,Robert,Abel,123 1,Robert,Thompson,abc 4,Robert,Griesemer,gri in reversed alphabetical order ( key:r ) $ cat testdata/names.csv \\ | csvtk sort -k first_name:r id,first_name,last_name,username NA,Robert,Abel,123 1,Robert,Thompson,abc 4,Robert,Griesemer,gri 11,Rob,Pike,rob 2,Ken,Thompson,ken in numerical order ( key:n ) $ cat testdata/names.csv \\ | csvtk sort -k id:n id,first_name,last_name,username NA,Robert,Abel,123 1,Robert,Thompson,abc 2,Ken,Thompson,ken 4,Robert,Griesemer,gri 11,Rob,Pike,rob in natural order ( key:N ) $ cat testdata/names.csv | csvtk sort -k id:N id,first_name,last_name,username 1,Robert,Thompson,abc 2,Ken,Thompson,ken 4,Robert,Griesemer,gri 11,Rob,Pike,rob NA,Robert,Abel,123 in natural order ( key:N ), a bioinformatics example $ echo \"X,Y,1,10,2,M,11,1_c,Un_g,1_g\" | csvtk transpose X Y 1 10 2 M 11 1_c Un_g 1_g $ echo \"X,Y,1,10,2,M,11,1_c,Un_g,1_g\" \\ | csvtk transpose \\ | csvtk sort -H -k 1:N 1 1_c 1_g 2 10 11 M Un_g X Y By multiple columns: csvtk sort -k 1,2 or csvtk sort -k 1 -k 2 or csvtk sort -k last_name,age # by first_name and then last_name $ cat testdata/names.csv | csvtk sort -k first_name -k last_name id,first_name,last_name,username 2,Ken,Thompson,ken 11,Rob,Pike,rob NA,Robert,Abel,123 4,Robert,Griesemer,gri 1,Robert,Thompson,abc # by first_name and then ID $ cat testdata/names.csv | csvtk sort -k first_name -k id:n id,first_name,last_name,username 2,Ken,Thompson,ken 11,Rob,Pike,rob NA,Robert,Abel,123 1,Robert,Thompson,abc 4,Robert,Griesemer,gri By user-defined order # user-defined order/level $ cat testdata/size_level.txt tiny mini small medium big # original data $ cat testdata/size.csv id,size 1,Huge 2,Tiny 3,Big 4,Small 5,Medium $ csvtk sort -k 2:u -i -L 2:testdata/size_level.txt testdata/size.csv id,size 2,Tiny 4,Small 5,Medium 3,Big 1,Huge plot Usage plot common figures Notes: 1. Output file can be set by flag -o/--out-file. 2. File format is determined by the out file suffix. Supported formats: eps, jpg|jpeg, pdf, png, svg, and tif|tiff 3. If flag -o/--out-file not set (default), image is written to stdout, you can display the image by pipping to \"display\" command of Imagemagic or just redirect to file. Usage: csvtk plot [command] Available Commands: box plot boxplot hist plot histogram line line plot and scatter plot Flags: --axis-width float axis width (default 1.5) -f, --data-field string column index or column name of data (default \"1\") --format string image format for stdout when flag -o/--out-file not given. available values: eps, jpg|jpeg, pdf, png, svg, and tif|tiff. (default \"png\") -g, --group-field string column index or column name of group --height float Figure height (default 4.5) --label-size int label font size (default 14) --tick-width float axis tick width (default 1.5) --title string Figure title --title-size int title font size (default 16) --width float Figure width (default 6) --x-max string maximum value of X axis --x-min string minimum value of X axis --xlab string x label text --y-max string maximum value of Y axis --y-min string minimum value of Y axis --ylab string y label text Note that most of the flags of plot are global flags of the subcommands hist , box and line Notes of image output Output file can be set by flag -o/--out-file. File format is determined by the out file suffix. Supported formats: eps, jpg|jpeg, pdf, png, svg, and tif|tiff If flag -o/--out-file not set (default), image is written to stdout, you can display the image by pipping to display command of Imagemagic or just redirect to file. plot hist Usage plot histogram Notes: 1. Output file can be set by flag -o/--out-file. 2. File format is determined by the out file suffix. Supported formats: eps, jpg|jpeg, pdf, png, svg, and tif|tiff 3. If flag -o/--out-file not set (default), image is written to stdout, you can display the image by pipping to \"display\" command of Imagemagic or just redirect to file. Usage: csvtk plot hist [flags] Flags: --bins int number of bins (default 50) --color-index int color index, 1-7 (default 1) Examples example data $ zcat testdata/grouped_data.tsv.gz | head -n 5 | csvtk -t pretty Group Length GC Content Group A 97 57.73 Group A 95 49.47 Group A 97 49.48 Group A 100 51.00 plot histogram with data of the second column: $ csvtk -t plot hist testdata/grouped_data.tsv.gz -f 2 \\ --title Histogram -o histogram.png You can also write image to stdout and pipe to \"display\" command of Imagemagic: $ csvtk -t plot hist testdata/grouped_data.tsv.gz -f 2 | display plot box Usage plot boxplot Notes: 1. Output file can be set by flag -o/--out-file. 2. File format is determined by the out file suffix. Supported formats: eps, jpg|jpeg, pdf, png, svg, and tif|tiff 3. If flag -o/--out-file not set (default), image is written to stdout, you can display the image by pipping to \"display\" command of Imagemagic or just redirect to file. Usage: csvtk plot box [flags] Flags: --box-width float box width --horiz horize box plot Examples plot boxplot with data of the \"GC Content\" (third) column, group information is the \"Group\" column. csvtk -t plot box testdata/grouped_data.tsv.gz -g \"Group\" -f \"GC Content\" \\ --width 3 --title \"Box plot\" \\ > boxplot.png plot horiz boxplot with data of the \"Length\" (second) column, group information is the \"Group\" column. $ csvtk -t plot box testdata/grouped_data.tsv.gz -g \"Group\" -f \"Length\" \\ --height 3 --width 5 --horiz --title \"Horiz box plot\" \\ > boxplot2.png` plot line Usage line plot and scatter plot Notes: 1. Output file can be set by flag -o/--out-file. 2. File format is determined by the out file suffix. Supported formats: eps, jpg|jpeg, pdf, png, svg, and tif|tiff 3. If flag -o/--out-file not set (default), image is written to stdout, you can display the image by pipping to \"display\" command of Imagemagic or just redirect to file. Usage: csvtk plot line [flags] Flags: -x, --data-field-x string column index or column name of X for command line -y, --data-field-y string column index or column name of Y for command line --legend-left locate legend along the left edge of the plot --legend-top locate legend along the top edge of the plot --line-width float line width (default 1.5) --point-size float point size (default 3) --scatter only plot points Examples example data $ head -n 5 testdata/xy.tsv Group X Y A 0 1 A 1 1.3 A 1.5 1.5 A 2.0 2 plot line plot with X-Y data $ csvtk -t plot line testdata/xy.tsv -x X -y Y -g Group \\ --title \"Line plot\" \\ > lineplot.png plot scatter $ csvtk -t plot line testdata/xy.tsv -x X -y Y -g Group \\ --title \"Scatter\" --scatter \\ > lineplot.png cat Usage stream file to stdout and report progress on stderr Usage: csvtk cat [flags] Flags: -b, --buffsize int buffer size (default 8192) -h, --help help for cat -L, --lines count lines instead of bytes -p, --print-freq int print frequency (-1 for print after parsing) (default 1) -s, --total int expected total bytes/lines (default -1) Examples Stream file, report progress in bytes csvtk cat file.tsv Stream file from stdin, report progress in lines tac input.tsv | csvtk cat -L -s `wc -l < input.tsv` - genautocomplete Usage generate shell autocompletion script Supported shell: bash|zsh|fish|powershell Bash: # generate completion shell csvtk genautocomplete --shell bash # configure if never did. # install bash-completion if the \"complete\" command is not found. echo \"for bcfile in ~/.bash_completion.d/* ; do source \\$bcfile; done\" >> ~/.bash_completion echo \"source ~/.bash_completion\" >> ~/.bashrc Zsh: # generate completion shell csvtk genautocomplete --shell zsh --file ~/.zfunc/_csvtk # configure if never did echo 'fpath=( ~/.zfunc \"${fpath[@]}\" )' >> ~/.zshrc echo \"autoload -U compinit; compinit\" >> ~/.zshrc fish: csvtk genautocomplete --shell fish --file ~/.config/fish/completions/csvtk.fish Usage: csvtk genautocomplete [flags] Flags: --file string autocompletion file (default \"/home/shenwei/.bash_completion.d/csvtk.sh\") -h, --help help for genautocomplete --shell string autocompletion type (bash|zsh|fish|powershell) (default \"bash\") /** * RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS. * LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables */ /* var disqus_config = function () { this.page.url = PAGE_URL; // Replace PAGE_URL with your page's canonical URL variable this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable }; */ (function() { // DON'T EDIT BELOW THIS LINE var d = document, s = d.createElement('script'); s.src = '//csvtk.disqus.com/embed.js'; s.setAttribute('data-timestamp', +new Date()); (d.head || d.body).appendChild(s); })(); Please enable JavaScript to view the comments powered by Disqus.","title":"Usage"},{"location":"usage/#usage-and-examples","text":"","title":"Usage and Examples"},{"location":"usage/#before-use","text":"Attention The CSV parser requires all the lines have same number of fields/columns. Even lines with spaces will cause error. Use '-I/--ignore-illegal-row' to skip these lines if neccessary. By default, csvtk thinks your files have header row, if not, switch flag \"-H\" on. Column names better be unique. By default, lines starting with \"#\" will be ignored, if the header row starts with \"#\", please assign flag \"-C\" another rare symbol, e.g. '$'. By default, csvtk handles CSV files, use flag \"-t\" for tab-delimited files. If double quotes exist in fields, use flag \"-l\". Do not mix use field (column) numbers and names.","title":"Before use"},{"location":"usage/#table-of-contents","text":"csvtk Information headers dim/nrow/ncol summary corr watch Format conversion pretty transpose csv2md csv2json csv2xlsx xlsx2csv Set operations head concat sample cut grep uniq freq inter filter filter2 join split splitxlsx comb Edit add-header del-header rename rename2 replace round mutate mutate2 sep gather unfold fold Ordering sort Ploting plot plot hist plot box plot line Misc cat genautocomplete","title":"Table of Contents"},{"location":"usage/#csvtk","text":"Usage csvtk -- a cross-platform, efficient and practical CSV/TSV toolkit Version: 0.24.0 Author: Wei Shen <shenwei356@gmail.com> Documents : http://shenwei356.github.io/csvtk Source code: https://github.com/shenwei356/csvtk Attention: 1. The CSV parser requires all the lines have same number of fields/columns. Even lines with spaces will cause error. Use '-I/--ignore-illegal-row' to skip these lines if neccessary. 2. By default, csvtk thinks your files have header row, if not, switch flag \"-H\" on. 3. Column names better be unique. 4. By default, lines starting with \"#\" will be ignored, if the header row starts with \"#\", please assign flag \"-C\" another rare symbol, e.g. '$'. 5. By default, csvtk handles CSV files, use flag \"-t\" for tab-delimited files. 6. If double quotes exist in fields, use flag \"-l\". 7. Do not mix use field (column) numbers and names. Environment variables for frequently used global flags: - \"CSVTK_T\" for flag \"-t/--tabs\" - \"CSVTK_H\" for flag \"-H/--no-header-row\" You can also create a soft link named \"tsvtk\" for \"csvtk\", which sets \"-t/--tabs\" by default. Usage: csvtk [command] Available Commands: add-header add column names cat stream file to stdout and report progress on stderr comb compute combinations of items at every row concat concatenate CSV/TSV files by rows corr calculate Pearson correlation between two columns csv2json convert CSV to JSON format csv2md convert CSV to markdown format csv2rst convert CSV to reStructuredText format csv2tab convert CSV to tabular format csv2xlsx convert CSV/TSV files to XLSX file cut select and arrange fields del-header delete column names dim dimensions of CSV file filter filter rows by values of selected fields with arithmetic expression filter2 filter rows by awk-like arithmetic/string expressions fmtdate format date of selected fields fold fold multiple values of a field into cells of groups freq frequencies of selected fields gather gather columns into key-value pairs genautocomplete generate shell autocompletion script (bash|zsh|fish|powershell) grep grep data by selected fields with patterns/regular expressions head print first N records headers print headers help Help about any command inter intersection of multiple files join join files by selected fields (inner, left and outer join) mutate create new column from selected fields by regular expression mutate2 create new column from selected fields by awk-like arithmetic/string expressions ncol print number of columns nrow print number of records plot plot common figures pretty convert CSV to readable aligned table rename rename column names with new names rename2 rename column names by regular expression replace replace data of selected fields by regular expression round round float to n decimal places sample sampling by proportion sep separate column into multiple columns sort sort by selected fields space2tab convert space delimited format to CSV split split CSV/TSV into multiple files according to column values splitxlsx split XLSX sheet into multiple sheets according to column values summary summary statistics of selected numeric or text fields (groupby group fields) tab2csv convert tabular format to CSV transpose transpose CSV data unfold unfold multiple values in cells of a field uniq unique data without sorting version print version information and check for update watch monitor the specified fields xlsx2csv convert XLSX to CSV format Flags: -c, --chunk-size int chunk size of CSV reader (default 50) -C, --comment-char string lines starting with commment-character will be ignored. if your header row starts with '#', please assign \"-C\" another rare symbol, e.g. '$' (default \"#\") -d, --delimiter string delimiting character of the input CSV file (default \",\") -h, --help help for csvtk -E, --ignore-empty-row ignore empty rows -I, --ignore-illegal-row ignore illegal rows --infile-list string file of input files list (one file per line), if given, they are appended to files from cli arguments -l, --lazy-quotes if given, a quote may appear in an unquoted field and a non-doubled quote may appear in a quoted field -H, --no-header-row specifies that the input CSV file does not have header row -j, --num-cpus int number of CPUs to use (default value depends on your computer) (default 16) -D, --out-delimiter string delimiting character of the output CSV file, e.g., -D $'\\t' for tab (default \",\") -o, --out-file string out file (\"-\" for stdout, suffix .gz for gzipped out) (default \"-\") -T, --out-tabs specifies that the output is delimited with tabs. Overrides \"-D\" -t, --tabs specifies that the input CSV file is delimited with tabs. Overrides \"-d\" Use \"csvtk [command] --help\" for more information about a command.","title":"csvtk"},{"location":"usage/#headers","text":"Usage print headers Usage: csvtk headers [flags] Flags: -h, --help help for headers -v, --verbose print verbose information Examples $ csvtk headers testdata/[12].csv name attr name major $ csvtk headers testdata/[12].csv -v # testdata/1.csv 1 name 2 attr # testdata/2.csv 1 name 2 major","title":"headers"},{"location":"usage/#dimnrowncol","text":"Usage dim: dimensions of CSV file Usage: csvtk dim [flags] Aliases: dim, size, stats, stat Flags: --cols only print number of columns -h, --help help for dim -n, --no-files do not print file names --rows only print number of rows --tabular output in machine-friendly tabular format nrow: print number of records Usage: csvtk nrow [flags] Aliases: nrow, nrows Flags: -n, --file-name print file names -h, --help help for nrow ncol: print number of columns Usage: csvtk ncol [flags] Aliases: ncol, ncols Flags: -n, --file-name print file names -h, --help help for ncol Examples with header row $ cat testdata/names.csv id,first_name,last_name,username 11,\"Rob\",\"Pike\",rob 2,Ken,Thompson,ken 4,\"Robert\",\"Griesemer\",\"gri\" 1,\"Robert\",\"Thompson\",\"abc\" NA,\"Robert\",\"Abel\",\"123\" $ cat testdata/names.csv | csvtk size file num_cols num_rows - 4 5 $ cat testdata/names.csv | csvtk nrow 5 $ cat testdata/names.csv | csvtk ncol 4 $ csvtk nrow testdata/names.csv testdata/phones.csv -n 5 testdata/names.csv 4 testdata/phones.csv no header row $ cat testdata/digitals.tsv 4 5 6 1 2 3 7 8 0 8 1,000 4 $ cat testdata/digitals.tsv \\ | csvtk size -t -H file num_cols num_rows - 3 4 $ cat testdata/names.csv | csvtk nrow -H 3 $ cat testdata/names.csv | csvtk ncol -H 4","title":"dim/nrow/ncol"},{"location":"usage/#summary","text":"Usage summary statistics of selected numeric or text fields (groupby group fields) Attention: 1. Do not mix use field (column) numbers and names. Available operations: # numeric/statistical operations # provided by github.com/gonum/stat and github.com/gonum/floats countn (count numeric values), min, max, sum, mean, stdev, variance, median, q1, q2, q3, entropy (Shannon entropy), prod (product of the elements) # textual/numeric operations count, first, last, rand, unique, collapse, countunique Usage: csvtk summary [flags] Flags: -n, --decimal-width int limit floats to N decimal points (default 2) -f, --fields strings operations on these fields. e.g -f 1:count,1:sum or -f colA:mean. available operations: collapse, count, countn, countunique, entropy, first, last, max, mean, median, min, prod, q1, q2, q3, rand, stdev, sum, uniq, variance -g, --groups string group via fields. e.g -f 1,2 or -f columnA,columnB -h, --help help for summary -i, --ignore-non-numbers ignore non-digital values like \"NA\" or \"N/A\" -S, --rand-seed int rand seed for operation \"rand\" (default 11) -s, --separater string separater for collapsed data (default \"; \") Examples data $ cat testdata/digitals2.csv f1,f2,f3,f4,f5 foo,bar,xyz,1,0 foo,bar2,xyz,1.5,-1 foo,bar2,xyz,3,2 foo,bar,xyz,5,3 foo,bar2,xyz,N/A,4 bar,xyz,abc,NA,2 bar,xyz,abc2,1,-1 bar,xyz,abc,2,0 bar,xyz,abc,1,5 bar,xyz,abc,3,100 bar,xyz2,abc3,2,3 bar,xyz2,abc3,2,1 use flag -i/--ignore-non-numbers $ cat testdata/digitals2.csv \\ | csvtk summary -f f4:sum [ERRO] column 4 has non-digital data: N/A, you can use flag -i/--ignore-non-numbers to skip these data $ cat testdata/digitals2.csv \\ | csvtk summary -f f4:sum -i f4:sum 21.50 multiple fields suported $ cat testdata/digitals2.csv \\ | csvtk summary -f f4:sum,f5:sum -i f4:sum,f5:sum 21.50,118.00 using fields instead of colname is still supported $ cat testdata/digitals2.csv \\ | csvtk summary -f 4:sum,5:sum -i f4:sum,f5:sum 21.50,118.00 but remember do not mix use column numbers and names $ cat testdata/digitals2.csv \\ | csvtk summary -f f4:sum,5:sum -i [ERRO] column \"5\" not existed in file: - $ cat testdata/digitals2.csv \\ | csvtk summary -f 4:sum,f5:sum -i [ERRO] failed to parse f5 as a field number, you may mix the use of field numbers and column names groupby $ cat testdata/digitals2.csv \\ | csvtk summary -i -f f4:sum,f5:sum -g f1,f2 \\ | csvtk pretty f1 f2 f4:sum f5:sum bar xyz 7.00 106.00 bar xyz2 4.00 4.00 foo bar 6.00 3.00 foo bar2 4.50 5.00 for data without header line $ cat testdata/digitals2.csv | sed 1d \\ | csvtk summary -H -i -f 4:sum,5:sum -g 1,2 \\ | csvtk pretty bar xyz 7.00 106.00 bar xyz2 4.00 4.00 foo bar 6.00 3.00 foo bar2 4.50 5.00 numeric/statistical operations $ cat testdata/digitals2.csv \\ | csvtk summary -i -g f1 -f f4:countn,f4:mean,f4:stdev,f4:q1,f4:q2,f4:mean,f4:q3,f4:min,f4:max \\ | csvtk pretty f1 f4:countn f4:mean f4:stdev f4:q1 f4:q2 f4:mean f4:q3 f4:min f4:max bar 6.00 1.83 0.75 1.00 2.00 1.83 2.00 1.00 3.00 foo 4.00 2.62 1.80 1.25 2.25 2.62 4.00 1.00 5.00 textual/numeric operations $ cat testdata/digitals2.csv \\ | csvtk summary -i -g f1 -f f2:count,f2:first,f2:last,f2:rand,f2:collapse,f2:uniq,f2:countunique \\ | csvtk pretty f1 f2:count f2:first f2:last f2:rand f2:collapse f2:uniq f2:countunique bar 7 xyz xyz2 xyz2 xyz; xyz; xyz; xyz; xyz; xyz2; xyz2 xyz2; xyz 2 foo 5 bar bar2 bar2 bar; bar2; bar2; bar; bar2 bar; bar2 2 mixed operations $ cat testdata/digitals2.csv \\ | csvtk summary -i -g f1 -f f4:collapse,f4:max \\ | csvtk pretty f1 f4:collapse f4:max bar NA; 1; 2; 1; 3; 2; 2 3.00 foo 1; 1.5; 3; 5; N/A 5.00 count and countn (count of digits) $ cat testdata/digitals2.csv \\ | csvtk summary -f f4:count,f4:countn -i \\ | csvtk pretty f4:count f4:countn 12 10 # details: $ cat testdata/digitals2.csv \\ | csvtk summary -f f4:count,f4:countn,f4:collapse -i -g f1 \\ | csvtk pretty f1 f4:count f4:countn f4:collapse bar 7 6 NA; 1; 2; 1; 3; 2; 2 foo 5 4 1; 1.5; 3; 5; N/A","title":"summary"},{"location":"usage/#watch","text":"Usage monitor the specified fields Usage: csvtk watch [flags] Flags: -B, --bins int number of histogram bins (default -1) -W, --delay int sleep this many seconds after plotting (default 1) -y, --dump print histogram data to stderr instead of plotting -f, --field string field to watch -h, --help help for watch -O, --image string save histogram to this PDF/image file -L, --log log10(x+1) transform numeric values -x, --pass passthrough mode (forward input to output) -p, --print-freq int print/report after this many records (-1 for print after EOF) (default -1) -Q, --quiet supress all plotting to stderr -R, --reset reset histogram after every report Examples Read whole file, plot histogram of field on the terminal and PDF csvtk -t watch -O hist.pdf -f MyField input.tsv Monitor a TSV stream, print histogram every 1000 records cat input.tsv | csvtk -t watch -f MyField -p 1000 - Monitor a TSV stream, print histogram every 1000 records, hang forever for updates tail -f +0 input.tsv | csvtk -t watch -f MyField -p 1000 -","title":"watch"},{"location":"usage/#corr","text":"Usage calculate Pearson correlation between two columns Usage: csvtk corr [flags] Flags: -f, --fields string comma separated fields -h, --help help for corr -i, --ignore_nan Ignore non-numeric fields to avoid returning NaN -L, --log Calcute correlations on Log10 transformed data -x, --pass passthrough mode (forward input to output) Examples Calculate pairwise correlations between field, ignore non-numeric values csvtk -t corr -i -f 1,Foo,Bar input.tsv","title":"corr"},{"location":"usage/#pretty","text":"Usage convert CSV to readable aligned table Usage: csvtk pretty [flags] Flags: -r, --align-right align right -h, --help help for pretty -W, --max-width int max width -w, --min-width int min width -s, --separator string fields/columns separator (default \" \") Examples: default $ csvtk pretty testdata/names.csv id first_name last_name username -- ---------- --------- -------- 11 Rob Pike rob 2 Ken Thompson ken 4 Robert Griesemer gri 1 Robert Thompson abc NA Robert Abel 123 align right $ csvtk pretty testdata/names.csv -r id first_name last_name username -- ---------- --------- -------- 11 Rob Pike rob 2 Ken Thompson ken 4 Robert Griesemer gri 1 Robert Thompson abc NA Robert Abel 123 custom separator $ csvtk pretty testdata/names.csv -s \" | \" id | first_name | last_name | username -- | ---------- | --------- | -------- 11 | Rob | Pike | rob 2 | Ken | Thompson | ken 4 | Robert | Griesemer | gri 1 | Robert | Thompson | abc NA | Robert | Abel | 123","title":"pretty"},{"location":"usage/#transpose","text":"Usage transpose CSV data Usage: csvtk transpose [flags] Examples $ cat testdata/digitals.tsv 4 5 6 1 2 3 7 8 0 8 1,000 4 $ csvtk transpose -t testdata/digitals.tsv 4 1 7 8 5 2 8 1,000 6 3 0 4","title":"transpose"},{"location":"usage/#csv2json","text":"Usage convert CSV to JSON format Usage: csvtk csv2json [flags] Flags: -b, --blanks do not convert \"\", \"na\", \"n/a\", \"none\", \"null\", \".\" to null -h, --help help for csv2json -i, --indent string indent. if given blank, output json in one line. (default \" \") -k, --key string output json as an array of objects keyed by a given filed rather than as a list. e.g -k 1 or -k columnA -n, --parse-num strings parse numeric values for nth column(s), multiple values are supported and \"a\"/\"all\" for all columns Examples test data $ cat testdata/data4json.csv ID,room,name,status 3,G13,Simon,true 5,103,Anna,TRUE 1e-3,2,,N/A default operation $ cat testdata/data4json.csv | csvtk csv2json [ { \"ID\": \"3\", \"room\": \"G13\", \"name\": \"Simon\", \"status\": true }, { \"ID\": \"5\", \"room\": \"103\", \"name\": \"Anna\", \"status\": true }, { \"ID\": \"1e-3\", \"room\": \"2\", \"name\": null, \"status\": null } ] change indent $ cat testdata/data4json.csv | csvtk csv2json -i \"\" [{\"ID\":\"3\",\"room\":\"G13\",\"name\":\"Simon\",\"status\":true},{\"ID\":\"5\",\"room\":\"103\",\"name\":\"Anna\",\"status\":true},{\"ID\":\"1e-3\",\"room\":\"2\",\"name\":null,\"status\":null}] output json as an array of objects keyed by a given filed rather than as a list. $ cat testdata/data4json.csv | csvtk csv2json -k ID { \"3\": { \"ID\": \"3\", \"room\": \"G13\", \"name\": \"Simon\", \"status\": true }, \"5\": { \"ID\": \"5\", \"room\": \"103\", \"name\": \"Anna\", \"status\": true }, \"1e-3\": { \"ID\": \"1e-3\", \"room\": \"2\", \"name\": null, \"status\": null } } for CSV without header row $ cat testdata/data4json.csv | csvtk csv2json -H [ [ \"ID\", \"room\", \"name\", \"status\" ], [ \"3\", \"G13\", \"Simon\", \"true\" ], [ \"5\", \"103\", \"Anna\", \"TRUE\" ], [ \"1e-3\", \"2\", \"\", \"N/A\" ] ] parse numeric values. # cat testdata/data4json.csv | csvtk csv2json -n all # for all columns # cat testdata/data4json.csv | csvtk csv2json -n 1,2 # for multiple columns $ cat testdata/data4json.csv | csvtk csv2json -n 1 # for single column [ { \"ID\": 3, \"room\": \"G13\", \"name\": \"Simon\", \"status\": true }, { \"ID\": 5, \"room\": \"103\", \"name\": \"Anna\", \"status\": true }, { \"ID\": 1e-3, \"room\": \"2\", \"name\": null, \"status\": null } ] do not convert \"\", \"na\", \"n/a\", \"none\", \"null\", \".\" to null (just like csvjon --blanks in csvkit) $ cat testdata/data4json.csv | csvtk csv2json --blanks [ { \"ID\": \"3\", \"room\": \"G13\", \"name\": \"Simon\", \"status\": true }, { \"ID\": \"5\", \"room\": \"103\", \"name\": \"Anna\", \"status\": true }, { \"ID\": \"1e-3\", \"room\": \"2\", \"name\": \"\", \"status\": \"\" } ]","title":"csv2json"},{"location":"usage/#csv2md","text":"Usage convert CSV to markdown format Attention: csv2md treats the first row as header line and requires them to be unique Usage: csvtk csv2md [flags] Flags: -a, --alignments string comma separated alignments. e.g. -a l,c,c,c or -a c (default \"l\") -w, --min-width int min width (at least 3) (default 3) Examples give single alignment symbol $ cat testdata/names.csv | csvtk csv2md -a left |id |first_name|last_name|username| |:--|:---------|:--------|:-------| |11 |Rob |Pike |rob | |2 |Ken |Thompson |ken | |4 |Robert |Griesemer|gri | |1 |Robert |Thompson |abc | |NA |Robert |Abel |123 | result: id first_name last_name username 11 Rob Pike rob 2 Ken Thompson ken 4 Robert Griesemer gri 1 Robert Thompson abc NA Robert Abel 123 give alignment symbols of all fields $ cat testdata/names.csv | csvtk csv2md -a c,l,l,l |id |first_name|last_name|username| |:-:|:---------|:--------|:-------| |11 |Rob |Pike |rob | |2 |Ken |Thompson |ken | |4 |Robert |Griesemer|gri | |1 |Robert |Thompson |abc | |NA |Robert |Abel |123 | result id first_name last_name username 11 Rob Pike rob 2 Ken Thompson ken 4 Robert Griesemer gri 1 Robert Thompson abc NA Robert Abel 123","title":"csv2md"},{"location":"usage/#csv2rst","text":"Usage convert CSV to readable aligned table Attention: 1. row span is not supported. Usage: csvtk csv2rst [flags] Flags: -k, --cross string charactor of cross (default \"+\") -s, --header string charactor of separator between header row and data rowws (default \"=\") -h, --help help for csv2rst -b, --horizontal-border string charactor of horizontal border (default \"-\") -p, --padding string charactor of padding (default \" \") -B, --vertical-border string charactor of vertical border (default \"|\") Example With header row $ csvtk csv2rst testdata/names.csv +----+------------+-----------+----------+ | id | first_name | last_name | username | +====+============+===========+==========+ | 11 | Rob | Pike | rob | +----+------------+-----------+----------+ | 2 | Ken | Thompson | ken | +----+------------+-----------+----------+ | 4 | Robert | Griesemer | gri | +----+------------+-----------+----------+ | 1 | Robert | Thompson | abc | +----+------------+-----------+----------+ | NA | Robert | Abel | 123 | +----+------------+-----------+----------+ No header row $ csvtk csv2rst -H -t testdata/digitals.tsv +---+-------+---+ | 4 | 5 | 6 | +---+-------+---+ | 1 | 2 | 3 | +---+-------+---+ | 7 | 8 | 0 | +---+-------+---+ | 8 | 1,000 | 4 | +---+-------+---+ Unicode $ cat testdata/unicode.csv | csvtk csv2rst +-------+---------+ | value | name | +=======+=========+ | 1 | \u6c88\u4f1f | +-------+---------+ | 2 | \u6c88\u4f1fb | +-------+---------+ | 3 | \u6c88\u5c0f\u4f1f | +-------+---------+ | 4 | \u6c88\u5c0f\u4f1fb | +-------+---------+ Misc $ cat testdata/names.csv | head -n 1 | csvtk csv2rst +----+------------+-----------+----------+ | id | first_name | last_name | username | +====+============+===========+==========+ $ cat testdata/names.csv | head -n 1 | csvtk csv2rst -H +----+------------+-----------+----------+ | id | first_name | last_name | username | +----+------------+-----------+----------+ $ echo | csvtk csv2rst -H [ERRO] xopen: no content $ echo \"a\" | csvtk csv2rst -H +---+ | a | +---+ $ echo \"\u6c88\u4f1f\" | csvtk csv2rst -H +------+ | \u6c88\u4f1f | +------+","title":"csv2rst"},{"location":"usage/#csv2xlsx","text":"Usage convert CSV/TSV files to XLSX file Attention: 1. Multiple CSV/TSV files are saved as separated sheets in .xlsx file. 2. All input files should all be CSV or TSV. 3. First rows are freezed unless given '-H/--no-header-row'. Usage: csvtk csv2xlsx [flags] Flags: -h, --help help for csv2xlsx Examples Single input $ csvtk csv2xlsx ../testdata/names.csv -o output.xlsx # check content $ csvtk xlsx2csv -a output.xlsx index sheet 1 Sheet1 $ csvtk xlsx2csv output.xlsx | md5sum 8e9d38a012cb02279a396a2f2dbbbca9 - $ csvtk cut -f 1- ../testdata/names.csv | md5sum 8e9d38a012cb02279a396a2f2dbbbca9 - Merging multiple CSV/TSV files into one .xlsx file. $ csvtk csv2xlsx ../testdata/names*.csv -o output.xlsx $ csvtk xlsx2csv -a output.xlsx index sheet 1 names 2 names.reorder 3 names.with-unmatched-colname","title":"csv2xlsx"},{"location":"usage/#xlsx2csv","text":"Usage convert XLSX to CSV format Usage: csvtk xlsx2csv [flags] Flags: -h, --help help for xlsx2csv -a, --list-sheets list all sheets -i, --sheet-index int Nth sheet to retrieve (default 1) -n, --sheet-name string sheet to retrieve Examples list all sheets $ csvtk xlsx2csv ../testdata/accounts.xlsx -a index sheet 1 names 2 phones 3 region retrieve sheet by index $ csvtk xlsx2csv ../testdata/accounts.xlsx -i 3 name,region ken,nowhere gri,somewhere shenwei,another Thompson,there retrieve sheet by name $ csvtk xlsx2sv ../testdata/accounts.xlsx -n region name,region ken,nowhere gri,somewhere shenwei,another Thompson,there","title":"xlsx2csv"},{"location":"usage/#head","text":"Usage print first N records Usage: csvtk head [flags] Flags: -n, --number int print first N records (default 10) Examples with header line $ csvtk head -n 2 testdata/1.csv name,attr foo,cool bar,handsome no header line $ csvtk head -H -n 2 testdata/1.csv name,attr foo,cool","title":"head"},{"location":"usage/#concat","text":"Usage concatenate CSV/TSV files by rows Note that the second and later files are concatenated to the first one, so only columns match that of the first files kept. Usage: csvtk concat [flags] Flags: -h, --help help for concat -i, --ignore-case ignore case (column name) -k, --keep-unmatched keep blanks even if no any data of a file matches -u, --unmatched-repl string replacement for unmatched data Examples data $ csvtk pretty names.csv id first_name last_name username 11 Rob Pike rob 2 Ken Thompson ken 4 Robert Griesemer gri 1 Robert Thompson abc NA Robert Abel 123 $ csvtk pretty names.reorder.csv last_name username id first_name Pike rob 11 Rob Thompson ken 2 Ken Griesemer gri 4 Robert Thompson abc 1 Robert Abel 123 NA Robert $ csvtk pretty names.with-unmatched-colname.csv id2 First_name Last_name Username col 22 Rob33 Pike222 rob111 abc 44 Ken33 Thompson22 ken111 def simple one $ csvtk concat names.csv names.reorder.csv \\ | csvtk pretty id first_name last_name username 11 Rob Pike rob 2 Ken Thompson ken 4 Robert Griesemer gri 1 Robert Thompson abc NA Robert Abel 123 11 Rob Pike rob 2 Ken Thompson ken 4 Robert Griesemer gri 1 Robert Thompson abc NA Robert Abel 123 data with unmatched column names, and ignoring cases $ csvtk concat names.csv names.with-unmatched-colname.csv -i \\ | csvtk pretty id first_name last_name username 11 Rob Pike rob 2 Ken Thompson ken 4 Robert Griesemer gri 1 Robert Thompson abc NA Robert Abel 123 Rob33 Pike222 rob111 Ken33 Thompson22 ken111 $ csvtk concat names.csv names.with-unmatched-colname.csv -i -u Unmached \\ | csvtk pretty id first_name last_name username 11 Rob Pike rob 2 Ken Thompson ken 4 Robert Griesemer gri 1 Robert Thompson abc NA Robert Abel 123 Unmached Rob33 Pike222 rob111 Unmached Ken33 Thompson22 ken111 Sometimes data of one file does not matche any column, they are discared by default. But you can keep them using flag -k/--keep-unmatched $ csvtk concat names.with-unmatched-colname.csv names.csv \\ | csvtk pretty id2 First_name Last_name Username col 22 Rob33 Pike222 rob111 abc 44 Ken33 Thompson22 ken111 def $ csvtk concat names.with-unmatched-colname.csv names.csv -u -k NA \\ | csvtk pretty id2 First_name Last_name Username col 22 Rob33 Pike222 rob111 abc 44 Ken33 Thompson22 ken111 def NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA","title":"concat"},{"location":"usage/#sample","text":"Usage sampling by proportion Usage: csvtk sample [flags] Flags: -h, --help help for sample -n, --line-number print line number as the first column (\"n\") -p, --proportion float sample by proportion -s, --rand-seed int rand seed (default 11) Examples $ seq 100 | csvtk sample -H -p 0.5 | wc -l 46 $ seq 100 | csvtk sample -H -p 0.5 | wc -l 46 $ seq 100 | csvtk sample -H -p 0.1 | wc -l 10 $ seq 100 | csvtk sample -H -p 0.05 -n 50,50 52,52 65,65","title":"sample"},{"location":"usage/#cut","text":"Usage select and arrange fields Examples: 1. Single column csvtk cut -f 1 csvtk cut -f colA 2. Multiple columns (replicates allowed) csvtk cut -f 1,3,2,1 csvtk cut -f colA,colB,colA 3. Column ranges csvtk cut -f 1,3-5 # 1, 3, 4, 5 csvtk cut -f 3,5- # 3rd col, and 5th col to the end csvtk cut -f 1- # for all csvtk cut -f 2-,1 # move 1th col to the end 4. Unselect csvtk cut -f -1,-3 # discard 1st and 3rd column csvtk cut -f -1--3 # discard 1st to 3rd column csvtk cut -f -2- # discard 2nd and all columns on the right. csvtu cut -f -colA,-colB # discard colA and colB Usage: csvtk cut [flags] Flags: -m, --allow-missing-col allow missing column -b, --blank-missing-col blank missing column -f, --fields string select only these fields. type \"csvtk cut -h\" for examples -F, --fuzzy-fields using fuzzy fields, e.g., -F -f \"*name\" or -F -f \"id123*\" -h, --help help for cut -i, --ignore-case ignore case (column name) -u, --uniq-column deduplicate columns matched by multiple fuzzy column names Examples data: $ cat testdata/names.csv id,first_name,last_name,username 11,\"Rob\",\"Pike\",rob 2,Ken,Thompson,ken 4,\"Robert\",\"Griesemer\",\"gri\" 1,\"Robert\",\"Thompson\",\"abc\" NA,\"Robert\",\"Abel\",\"123\" Select columns by column index: csvtk cut -f 1,2 $ cat testdata/names.csv \\ | csvtk cut -f 1,2 id,first_name 11,Rob 2,Ken 4,Robert 1,Robert NA,Robert # select more than once $ cat testdata/names.csv \\ | csvtk cut -f 1,2,2 id,first_name,first_name 11,Rob,Rob 2,Ken,Ken 4,Robert,Robert 1,Robert,Robert NA,Robert,Robert Select columns by column names: csvtk cut -f first_name,username $ cat testdata/names.csv \\ | csvtk cut -f first_name,username first_name,username Rob,rob Ken,ken Robert,gri Robert,abc Robert,123 # select more than once $ cat testdata/names.csv \\ | csvtk cut -f first_name,username,username first_name,username,username Rob,rob,rob Ken,ken,ken Robert,gri,gri Robert,abc,abc Robert,123,123 Unselect : select 3+ columns: csvtk cut -f -1,-2 $ cat testdata/names.csv \\ | csvtk cut -f -1,-2 last_name,username Pike,rob Thompson,ken Griesemer,gri Thompson,abc Abel,123 select columns except first_name : csvtk cut -f -first_name $ cat testdata/names.csv \\ | csvtk cut -f -first_name id,last_name,username 11,Pike,rob 2,Thompson,ken 4,Griesemer,gri 1,Thompson,abc NA,Abel,123 Fuzzy fields using wildcard character, csvtk cut -F -f \"*_name,username\" $ cat testdata/names.csv \\ | csvtk cut -F -f \"*_name,username\" first_name,last_name,username Rob,Pike,rob Ken,Thompson,ken Robert,Griesemer,gri Robert,Thompson,abc Robert,Abel,123 All fields: csvtk cut -F -f \"*\" or csvtk cut -f 1- . $ cat testdata/names.csv \\ | csvtk cut -F -f \"*\" id,first_name,last_name,username 11,Rob,Pike,rob 2,Ken,Thompson,ken 4,Robert,Griesemer,gri 1,Robert,Thompson,abc NA,Robert,Abel,123 Field ranges (read help message (\"csvtk cut -f\") for more examples) csvtk cut -f 2-4 for column 2,3,4 $ cat testdata/names.csv \\ | csvtk cut -f 2-4 first_name,last_name,username Rob,Pike,rob Ken,Thompson,ken Robert,Griesemer,gri Robert,Thompson,abc Robert,Abel,123 csvtk cut -f -3--1 for discarding column 1,2,3 $ cat testdata/names.csv \\ | csvtk cut -f -3--1 username rob ken gri abc 123 csvtk cut -f 2-,1 for moving 1th column to the end. $ cat testdata/names.csv \\ | csvtk cut -f 2-,1 first_name,last_name,username,id Rob,Pike,rob,11 Ken,Thompson,ken,2 Robert,Griesemer,gri,4 Robert,Thompson,abc,1 Robert,Abel,123,NA csvtk cut -f 1,1 for duplicating columns $ cat testdata/names.csv \\ | csvtk cut -f 1,1 id,id 11,11 2,2 4,4 1,1 NA,NA","title":"cut"},{"location":"usage/#uniq","text":"Usage unique data without sorting Usage: csvtk uniq [flags] Flags: -f, --fields string select these fields as keys. e.g -f 1,2 or -f columnA,columnB (default \"1\") -F, --fuzzy-fields using fuzzy fields, e.g., -F -f \"*name\" or -F -f \"id123*\" -h, --help help for uniq -i, --ignore-case ignore case -n, --keep-n int keep at most N records for a key (default 1) Examples: data: $ cat testdata/names.csv id,first_name,last_name,username 11,\"Rob\",\"Pike\",rob 2,Ken,Thompson,ken 4,\"Robert\",\"Griesemer\",\"gri\" 1,\"Robert\",\"Thompson\",\"abc\" NA,\"Robert\",\"Abel\",\"123\" unique first_name (it removes rows with duplicated first_name) $ cat testdata/names.csv \\ | csvtk uniq -f first_name id,first_name,last_name,username 11,Rob,Pike,rob 2,Ken,Thompson,ken 4,Robert,Griesemer,gri unique first_name, a more common way $ cat testdata/names.csv \\ | csvtk cut -f first_name \\ | csvtk uniq -f 1 first_name Rob Ken Robert keep top 2 items for every group. $ cat testdata/players.csv gender,id,name male,1,A male,2,B male,3,C female,11,a female,12,b female,13,c female,14,d $ cat testdata/players.csv \\ | csvtk sort -k gender:N -k id:nr \\ | csvtk uniq -f gender -n 2 gender,id,name female,14,d female,13,c male,3,C male,2,B","title":"uniq"},{"location":"usage/#freq","text":"Usage frequencies of selected fields Usage: csvtk freq [flags] Flags: -f, --fields string select only these fields. e.g -f 1,2 or -f columnA,columnB (default \"1\") -F, --fuzzy-fields using fuzzy fields, e.g., -F -f \"*name\" or -F -f \"id123*\" -i, --ignore-case ignore case -r, --reverse reverse order while sorting -n, --sort-by-freq sort by frequency -k, --sort-by-key sort by key Examples one filed $ cat testdata/names.csv \\ | csvtk freq -f first_name | csvtk pretty first_name frequency Ken 1 Rob 1 Robert 3 sort by frequency. you can also use csvtk sort with more sorting options $ cat testdata/names.csv \\ | csvtk freq -f first_name -n -r \\ | csvtk pretty first_name frequency Robert 3 Ken 1 Rob 1 sorty by key $ cat testdata/names.csv \\ | csvtk freq -f first_name -k \\ | csvtk pretty first_name frequency Ken 1 Rob 1 Robert 3 multiple fields $ cat testdata/names.csv \\ | csvtk freq -f first_name,last_name \\ | csvtk pretty first_name last_name frequency Robert Abel 1 Ken Thompson 1 Rob Pike 1 Robert Thompson 1 Robert Griesemer 1 data without header row $ cat testdata/ testdata/digitals.tsv \\ | csvtk -t -H freq -f 1 8 1 1 1 4 1 7 1","title":"freq"},{"location":"usage/#inter","text":"Usage intersection of multiple files Attention: 1. fields in all files should be the same, if not, extracting to another file using \"csvtk cut\". Usage: csvtk inter [flags] Flags: -f, --fields string select these fields as the key. e.g -f 1,2 or -f columnA,columnB (default \"1\") -F, --fuzzy-fields using fuzzy fields, e.g., -F -f \"*name\" or -F -f \"id123*\" -i, --ignore-case ignore case Examples: $ cat testdata/phones.csv username,phone gri,11111 rob,12345 ken,22222 shenwei,999999 $ cat testdata/region.csv name,region ken,nowhere gri,somewhere shenwei,another Thompson,there $ csvtk inter testdata/phones.csv testdata/region.csv username gri ken shenwei","title":"inter"},{"location":"usage/#grep","text":"Usage grep data by selected fields with patterns/regular expressions Attentions: 1. By default, we directly compare the column value with patterns, use \"-r/--use-regexp\" for partly matching. 2. Multiple patterns can be given by setting '-p/--pattern' more than once, or giving comma separated values (CSV formats). Therefore, please use double quotation marks for patterns containing comma, e.g., -p '\"A{2,}\"' Usage: csvtk grep [flags] Flags: --delete-matched delete a pattern right after being matched, this keeps the firstly matched data and speedups when using regular expressions -f, --fields string comma separated key fields, column name or index. e.g. -f 1-3 or -f id,id2 or -F -f \"group*\" (default \"1\") -F, --fuzzy-fields using fuzzy fields, e.g., -F -f \"*name\" or -F -f \"id123*\" -h, --help help for grep -i, --ignore-case ignore case --immediate-output print output immediately, do not use write buffer -v, --invert invert match -n, --line-number print line number as the first column (\"n\") -N, --no-highlight no highlight -p, --pattern strings query pattern (multiple values supported). Attention: use double quotation marks for patterns containing comma, e.g., -p '\"A{2,}\"' -P, --pattern-file string pattern files (one pattern per line) -r, --use-regexp patterns are regular expression --verbose verbose output Examples Matched parts will be highlight . By exact keys $ cat testdata/names.csv \\ | csvtk grep -f last_name -p Pike -p Abel \\ | csvtk pretty id first_name last_name username 11 Rob Pike rob NA Robert Abel 123 # another form of multiple keys $ csvtk grep -f last_name -p Pike,Abel,Tom By regular expression: csvtk grep -f first_name -r -p Rob $ cat testdata/names.csv \\ | csvtk grep -f first_name -r -p Rob \\ | csvtk pretty id first_name last_name username 11 Rob Pike rob 4 Robert Griesemer gri 1 Robert Thompson abc NA Robert Abel 123 By pattern list $ csvtk grep -f first_name -P name_list.txt Remore rows containing any missing data (NA): $ csvtk grep -F -f \"*\" -r -p \"^$\" -v Show line number $ cat names.csv \\ | csvtk pretty id first_name last_name username 11 Rob Pike rob 2 Ken Thompson ken 4 Robert Griesemer gri 1 Robert Thompson abc NA Robert Abel 123 $ cat names.csv \\ | csvtk grep -f first_name -r -i -p rob -n \\ | csvtk pretty n id first_name last_name username 1 11 Rob Pike rob 3 4 Robert Griesemer gri 4 1 Robert Thompson abc 5 NA Robert Abel 123","title":"grep"},{"location":"usage/#filter","text":"Usage filter rows by values of selected fields with arithmetic expression Usage: csvtk filter [flags] Flags: --any print record if any of the field satisfy the condition -f, --filter string filter condition. e.g. -f \"age>12\" or -f \"1,3<=2\" or -F -f \"c*!=0\" -F, --fuzzy-fields using fuzzy fields, e.g., -F -f \"*name\" or -F -f \"id123*\" -h, --help help for filter -n, --line-number print line number as the first column (\"n\") Examples single field $ cat testdata/names.csv id,first_name,last_name,username 11,\"Rob\",\"Pike\",rob 2,Ken,Thompson,ken 4,\"Robert\",\"Griesemer\",\"gri\" 1,\"Robert\",\"Thompson\",\"abc\" NA,\"Robert\",\"Abel\",\"123\" $ cat testdata/names.csv \\ | csvtk filter -f \"id>0\" \\ | csvtk pretty id first_name last_name username 11 Rob Pike rob 2 Ken Thompson ken 4 Robert Griesemer gri 1 Robert Thompson abc multiple fields $ cat testdata/digitals.tsv 4 5 6 1 2 3 7 8 0 8 1,000 4 $ cat testdata/digitals.tsv \\ | csvtk -t -H filter -f \"1-3>0\" 4 5 6 1 2 3 8 1,000 4 using --any to print record if any of the field satisfy the condition $ cat testdata/digitals.tsv \\ | csvtk -t -H filter -f \"1-3>0\" --any 4 5 6 1 2 3 7 8 0 8 1,000 4 fuzzy fields $ cat testdata/names.csv \\ | csvtk filter -F -f \"i*!=0\" id,first_name,last_name,username 11,Rob,Pike,rob 2,Ken,Thompson,ken 4,Robert,Griesemer,gri 1,Robert,Thompson,abc","title":"filter"},{"location":"usage/#filter2","text":"Usage filter rows by awk-like arithmetic/string expressions The arithmetic/string expression is supported by: https://github.com/Knetic/govaluate Supported operators and types: Modifiers: + - / * & | ^ ** % >> << Comparators: > >= < <= == != =~ !~ Logical ops: || && Numeric constants, as 64-bit floating point (12345.678) String constants (single quotes: 'foobar') Date constants (single quotes) Boolean constants: true false Parenthesis to control order of evaluation ( ) Arrays (anything separated by , within parenthesis: (1, 2, 'foo')) Prefixes: ! - ~ Ternary conditional: ? : Null coalescence: ?? Custom functions: - len(), length of strings, e.g., len($1), len($a), len($1, $2) - ulen(), length of unicode strings/width of unicode strings rendered to a terminal, e.g., len(\"\u6c88\u4f1f\")==6, ulen(\"\u6c88\u4f1f\")==4 Usage: csvtk filter2 [flags] Flags: -f, --filter string awk-like filter condition. e.g. '$age>12' or '$1 > $3' or '$name==\"abc\"' or '$1 % 2 == 0' -h, --help help for filter2 -n, --line-number print line number as the first column (\"n\") -s, --numeric-as-string treat even numeric fields as strings to avoid converting big numbers into scientific notation Examples: filter rows with id greater than 3: $ cat testdata/names.csv id,first_name,last_name,username 11,\"Rob\",\"Pike\",rob 2,Ken,Thompson,ken 4,\"Robert\",\"Griesemer\",\"gri\" 1,\"Robert\",\"Thompson\",\"abc\" NA,\"Robert\",\"Abel\",\"123\" $ cat testdata/names.csv \\ | csvtk filter2 -f '$id > 3' id,first_name,last_name,username 11,Rob,Pike,rob 4,Robert,Griesemer,gri arithmetic and string expressions $ cat testdata/names.csv \\ | csvtk filter2 -f '$id > 3 || $username==\"ken\"' id,first_name,last_name,username 11,Rob,Pike,rob 2,Ken,Thompson,ken 4,Robert,Griesemer,gri More arithmetic expressions $ cat testdata/digitals.tsv 4 5 6 1 2 3 7 8 0 8 1,000 4 $ cat testdata/digitals.tsv \\ | csvtk filter2 -H -t -f '$1 > 2 && $2 % 2 == 0' 7 8 0 8 1,000 4 # comparison between fields and support $ cat testdata/digitals.tsv \\ | csvtk filter2 -H -t -f '$2 <= $3 || ( $1 / $2 > 0.5 )' 4 5 6 1 2 3 7 8 0","title":"filter2"},{"location":"usage/#join","text":"Usage join files by selected fields (inner, left and outer join). Attention: 1. Multiple keys supported 2. Default operation is inner join, use --left-join for left join and --outer-join for outer join. Usage: csvtk join [flags] Aliases: join, merge Flags: -f, --fields string Semicolon separated key fields of all files, if given one, we think all the files have the same key columns. Fields of different files should be separated by \";\", e.g -f \"1;2\" or -f \"A,B;C,D\" or -f id (default \"1\") -F, --fuzzy-fields using fuzzy fields, e.g., -F -f \"*name\" or -F -f \"id123*\" -h, --help help for join -i, --ignore-case ignore case -n, --ignore-null do not match NULL values -k, --keep-unmatched keep unmatched data of the first file (left join) -L, --left-join left join, equals to -k/--keep-unmatched, exclusive with --outer-join --na string content for filling NA data -O, --outer-join outer join, exclusive with --left-join Examples: data $ cat testdata/phones.csv username,phone gri,11111 rob,12345 ken,22222 shenwei,999999 $ cat testdata/region.csv name,region ken,nowhere gri,somewhere shenwei,another Thompson,there All files have same key column: csvtk join -f id file1.csv file2.csv $ csvtk join -f 1 testdata/phones.csv testdata/region.csv \\ | csvtk pretty username phone region gri 11111 somewhere ken 22222 nowhere shenwei 999999 another keep unmatched (left join) $ csvtk join -f 1 testdata/phones.csv testdata/region.csv --left-join \\ | csvtk pretty username phone region gri 11111 somewhere rob 12345 ken 22222 nowhere shenwei 999999 another keep unmatched and fill with something $ csvtk join -f 1 testdata/phones.csv testdata/region.csv --left-join --na NA \\ | csvtk pretty username phone region gri 11111 somewhere rob 12345 NA ken 22222 nowhere shenwei 999999 another Outer join $ csvtk join -f 1 testdata/phones.csv testdata/region.csv --outer-join --na NA \\ | csvtk pretty username phone region gri 11111 somewhere rob 12345 NA ken 22222 nowhere shenwei 999999 another Thompson NA there Files have different key columns: csvtk join -f \"username;username;name\" testdata/names.csv phone.csv adress.csv -k . Note that fields are separated with ; not , . $ csvtk join -f \"username;name\" testdata/phones.csv testdata/region.csv --left-join --na NA \\ | csvtk pretty username phone region gri 11111 somewhere rob 12345 NA ken 22222 nowhere shenwei 999999 another Some special cases $ cat testdata/1.csv name,attr foo,cool bar,handsome bob,beutiful $ cat testdata/2.csv name,major bar,bioinformatics bob,microbiology bob,computer science $ cat testdata/3.csv id,name,hobby 1,bar,baseball 2,bob,basketball 3,foo,football 4,wei,programming # nothing special $ csvtk join testdata/{1,2,3}.csv -f name --outer-join --na NA \\ | csvtk pretty name attr major id hobby foo cool NA 3 football bar handsome bioinformatics 1 baseball bob beutiful microbiology 2 basketball bob beutiful computer science 2 basketball wei NA NA 4 programming # just reorder files $ csvtk join testdata/{3,2,1}.csv -f name --outer-join --na NA \\ | csvtk pretty id name hobby major attr 1 bar baseball bioinformatics handsome 2 bob basketball microbiology beutiful 2 bob basketball computer science beutiful 3 foo football NA cool 4 wei programming NA NA # special case: names in 3.csv contain all names in all files $ csvtk join testdata/{3,2,1}.csv -f name --left-join --na NA \\ | csvtk pretty id name hobby major attr 1 bar baseball bioinformatics handsome 2 bob basketball microbiology beutiful 2 bob basketball computer science beutiful 3 foo football NA cool 4 wei programming NA NA","title":"join"},{"location":"usage/#split","text":"Usage split CSV/TSV into multiple files according to column values Note: 1. flag -o/--out-file can specify out directory for splitted files Usage: csvtk split [flags] Flags: -g, --buf-groups int buffering N groups before writing to file (default 100) -b, --buf-rows int buffering N rows for every group before writing to file (default 100000) -f, --fields string comma separated key fields, column name or index. e.g. -f 1-3 or -f id,id2 or -F -f \"group*\" (default \"1\") -F, --fuzzy-fields using fuzzy fields, e.g., -F -f \"*name\" or -F -f \"id123*\" -h, --help help for split -i, --ignore-case ignore case -G, --out-gzip force output gzipped file Examples Test data $ cat names.csv id,first_name,last_name,username 11,\"Rob\",\"Pike\",rob 2,Ken,Thompson,ken 4,\"Robert\",\"Griesemer\",\"gri\" 1,\"Robert\",\"Thompson\",\"abc\" NA,\"Robert\",\"Abel\",\"123\" split according to first_name $ csvtk split names.csv -f first_name $ ls *.csv names.csv names-Ken.csv names-Rob.csv names-Robert.csv $ cat names-Ken.csv id,first_name,last_name,username 2,Ken,Thompson,ken $ cat names-Rob.csv id,first_name,last_name,username 11,Rob,Pike,rob $ cat names-Robert.csv id,first_name,last_name,username 4,Robert,Griesemer,gri 1,Robert,Thompson,abc NA,Robert,Abel,123 split according to first_name and last_name $ csvtk split names.csv -f first_name,last_name $ ls *.csv names.csv names-Robert-Abel.csv names-Robert-Thompson.csv names-Ken-Thompson.csv names-Robert-Griesemer.csv names-Rob-Pike.csv flag -o/--out-file can specify out directory for splitted files $ seq 10000 | csvtk split -H -o result $ ls result/*.csv | wc -l 10000 extreme example 1: lots (1M) of rows in groups $ yes 2 | head -n 10000000 | gzip -c > t.gz $ memusg -t csvtk -H split t.gz elapsed time: 7.959s peak rss: 35.7 MB # check $ zcat t-2.gz | wc -l 10000000 $ zcat t-2.gz | md5sum f194afd7cecf645c0e3cce50c9bc526e - $ zcat t.gz | md5sum f194afd7cecf645c0e3cce50c9bc526e - extreme example 2: lots (10K) of groups $ seq 10000 | gzip -c > t2.gz $ memusg -t csvtk -H split t2.gz -o t2 elapsed time: 20.856s peak rss: 23.77 MB # check $ ls t2/*.gz | wc -l 10000 $ zcat t2/*.gz | sort -k 1,1n | md5sum 72d4ff27a28afbc066d5804999d5a504 - $ zcat t2.gz | md5sum 72d4ff27a28afbc066d5804999d5a504 -","title":"split"},{"location":"usage/#splitxlsx","text":"Usage split XLSX sheet into multiple sheets according to column values Strengths: Sheet properties are remained unchanged. Weakness : Complicated sheet structures are not well supported, e.g., 1. merged cells 2. more than one header row Usage: csvtk splitxlsx [flags] Flags: -f, --fields string comma separated key fields, column name or index. e.g. -f 1-3 or -f id,id2 or -F -f \"group*\" (default \"1\") -F, --fuzzy-fields using fuzzy fields, e.g., -F -f \"*name\" or -F -f \"id123*\" -h, --help help for splitxlsx -i, --ignore-case ignore case (cell value) -a, --list-sheets list all sheets -N, --sheet-index int Nth sheet to retrieve (default 1) -n, --sheet-name string sheet to retrieve Examples example data # list all sheets $ csvtk xlsx2csv -a accounts.xlsx index sheet 1 names 2 phones 3 region # data of sheet \"names\" $ csvtk xlsx2csv accounts.xlsx | csvtk pretty id first_name last_name username 11 Rob Pike rob 2 Ken Thompson ken 4 Robert Griesemer gri 1 Robert Thompson abc NA Robert Abel 123 split sheet \"names\" according to first_name $ csvtk splitxlsx accounts.xlsx -n names -f first_name $ ls accounts.* accounts.split.xlsx accounts.xlsx $ csvtk splitxlsx -a accounts.split.xlsx index sheet 1 names 2 phones 3 region 4 Rob 5 Ken 6 Robert $ csvtk xlsx2csv accounts.split.xlsx -n Rob \\ | csvtk pretty id first_name last_name username 11 Rob Pike rob $ csvtk xlsx2csv accounts.split.xlsx -n Robert \\ | csvtk pretty id first_name last_name username 4 Robert Griesemer gri 1 Robert Thompson abc NA Robert Abel 123","title":"splitxlsx"},{"location":"usage/#comb","text":"Usage compute combinations of items at every row Usage: csvtk comb [flags] Aliases: comb, combination Flags: -h, --help help for comb -i, --ignore-case ignore-case -S, --nat-sort sort items in natural order -n, --number int number of items in a combination, 0 for no limit, i.e., return all combinations (default 2) -s, --sort sort items in a combination Examples: $ cat players.csv gender,id,name male,1,A male,2,B male,3,C female,11,a female,12,b female,13,c female,14,d # put names of one group in one row $ cat players.csv \\ | csvtk collapse -f 1 -v 3 -s ';' \\ | csvtk cut -f 2 name A;B;C a;b;c;d # n = 2 $ cat players.csv \\ | csvtk collapse -f 1 -v 3 -s ';' \\ | csvtk cut -f 2 \\ | csvtk comb -d ';' -n 2 A,B A,C B,C a,b a,c b,c a,d b,d c,d # n = 3 $ cat players.csv \\ | csvtk collapse -f 1 -v 3 -s ';' \\ | csvtk cut -f 2 \\ | csvtk comb -d ';' -n 3 A,B,C a,b,c a,b,d a,c,d b,c,d # n = 0 $ cat players.csv \\ | csvtk collapse -f 1 -v 3 -s ';' \\ | csvtk cut -f 2 \\ | csvtk comb -d ';' -n 0 A B A,B C A,C B,C A,B,C a b a,b c a,c b,c a,b,c d a,d b,d a,b,d c,d a,c,d b,c,d a,b,c,d","title":"comb"},{"location":"usage/#add-header","text":"Usage add column names Usage: csvtk add-header [flags] Flags: -h, --help help for add-header -n, --names strings column names to add, in CSV format Examples: No new colnames given: $ seq 3 | csvtk mutate -H \\ | csvtk add-header [WARN] colnames not given, c1, c2, c3... will be used c1,c2 1,1 2,2 3,3 Adding new colnames: $ seq 3 | csvtk mutate -H \\ | csvtk add-header -n a,b a,b 1,1 2,2 3,3 $ seq 3 | csvtk mutate -H \\ | csvtk add-header -n a -n b a,b 1,1 2,2 3,3 $ seq 3 | csvtk mutate -H -t \\ | csvtk add-header -t -n a,b a b 1 1 2 2 3 3","title":"add-header"},{"location":"usage/#del-header","text":"Usage delete column names Usage: csvtk del-header [flags] Flags: -h, --help help for del-header Examples: $ seq 3 | csvtk add-header c1 1 2 3 $ seq 3 | csvtk add-header | csvtk del-header 1 2 3 $ seq 3 | csvtk del-header -H 1 2 3","title":"del-header"},{"location":"usage/#rename","text":"Usage rename column names with new names Usage: csvtk rename [flags] Flags: -f, --fields string select only these fields. e.g -f 1,2 or -f columnA,columnB -F, --fuzzy-fields using fuzzy fields, e.g., -F -f \"*name\" or -F -f \"id123*\" -n, --names string comma separated new names Examples: Setting new names: csvtk rename -f A,B -n a,b or csvtk rename -f 1-3 -n a,b,c $ cat testdata/phones.csv username,phone gri,11111 rob,12345 ken,22222 shenwei,999999 $ cat testdata/phones.csv \\ | csvtk rename -f 1-2 -n \u59d3\u540d,\u7535\u8bdd \\ | csvtk pretty \u59d3\u540d \u7535\u8bdd gri 11111 rob 12345 ken 22222 shenwei 999999","title":"rename"},{"location":"usage/#rename2","text":"Usage rename column names by regular expression Special replacement symbols: {nr} ascending number, starting from 1 {kv} Corresponding value of the key (captured variable $n) by key-value file, n can be specified by flag --key-capt-idx (default: 1) Usage: csvtk rename2 [flags] Flags: -f, --fields string select only these fields. e.g -f 1,2 or -f columnA,columnB -F, --fuzzy-fields using fuzzy fields, e.g., -F -f \"*name\" or -F -f \"id123*\" -h, --help help for rename2 -i, --ignore-case ignore case -K, --keep-key keep the key as value when no value found for the key --key-capt-idx int capture variable index of key (1-based) (default 1) --key-miss-repl string replacement for key with no corresponding value -k, --kv-file string tab-delimited key-value file for replacing key with value when using \"{kv}\" in -r (--replacement) -p, --pattern string search regular expression -r, --replacement string renamement. supporting capture variables. e.g. $1 represents the text of the first submatch. ATTENTION: use SINGLE quote NOT double quotes in *nix OS or use the \\ escape character. Ascending number is also supported by \"{nr}\".use ${1} instead of $1 when {kv} given! Examples: Add suffix to all column names. $ cat testdata/phones.csv username,phone gri,11111 rob,12345 ken,22222 shenwei,999999 $ cat testdata/phones.csv \\ | csvtk rename2 -F -f \"*\" -p \"(.*)\" -r 'prefix_${1}_suffix' prefix_username_suffix,prefix_phone_suffix gri,11111 rob,12345 ken,22222 shenwei,999999 supporting {kv} and {nr} in csvtk replace . e.g., replace barcode with sample name. $ cat barcodes.tsv Sample Barcode sc1 CCTAGATTAAT sc2 GAAGACTTGGT sc3 GAAGCAGTATG sc4 GGTAACCTGAC sc5 ATAGTTCTCGT $ cat table.tsv gene ATAGTTCTCGT GAAGCAGTATG GAAGACTTGGT AAAAAAAAAA gene1 0 0 3 0 gen1e2 0 0 0 0 # note that, we must arrange the order of barcodes.tsv to KEY-VALUE $ csvtk cut -t -f 2,1 barcodes.tsv Barcode Sample CCTAGATTAAT sc1 GAAGACTTGGT sc2 GAAGCAGTATG sc3 GGTAACCTGAC sc4 ATAGTTCTCGT sc5 # here we go!!!! $ csvtk rename2 -t -k <(csvtk cut -t -f 2,1 barcodes.tsv) \\ -f -1 -p '(.+)' -r '{kv}' --key-miss-repl unknown table.tsv gene sc5 sc3 sc2 unknown gene1 0 0 3 0 gen1e2 0 0 0 0 {nr} , incase you need this $ echo \"a,b,c,d\" \\ | csvtk rename2 -p '(.+)' -r 'col_{nr}' -f -1 --start-num 2 a,col_2,col_3,col_4","title":"rename2"},{"location":"usage/#replace","text":"Usage replace data of selected fields by regular expression Note that the replacement supports capture variables. e.g. $1 represents the text of the first submatch. ATTENTION: use SINGLE quote NOT double quotes in *nix OS. Examples: Adding space to cell values. csvtk replace -p \"(.)\" -r '$1 ' Or use the \\ escape character. csvtk replace -p \"(.)\" -r \"\\$1 \" more on: http://shenwei356.github.io/csvtk/usage/#replace Special replacement symbols: {nr} Record number, starting from 1 {kv} Corresponding value of the key (captured variable $n) by key-value file, n can be specified by flag --key-capt-idx (default: 1) Usage: csvtk replace [flags] Flags: -f, --fields string select only these fields. e.g -f 1,2 or -f columnA,columnB (default \"1\") -F, --fuzzy-fields using fuzzy fields, e.g., -F -f \"*name\" or -F -f \"id123*\" -i, --ignore-case ignore case -K, --keep-key keep the key as value when no value found for the key --key-capt-idx int capture variable index of key (1-based) (default 1) --key-miss-repl string replacement for key with no corresponding value -k, --kv-file string tab-delimited key-value file for replacing key with value when using \"{kv}\" in -r (--replacement) -p, --pattern string search regular expression -r, --replacement string replacement. supporting capture variables. e.g. $1 represents the text of the first submatch. ATTENTION: for *nix OS, use SINGLE quote NOT double quotes or use the \\ escape character. Record number is also supported by \"{nr}\".use ${1} instead of $1 when {kv} given! Examples remove Chinese charactors $ csvtk replace -F -f \"*_name\" -p \"\\p{Han}+\" -r \"\" replace by key-value files $ cat data.tsv name id A ID001 B ID002 C ID004 $ cat alias.tsv 001 Tom 002 Bob 003 Jim $ csvtk replace -t -f 2 -p \"ID(.+)\" -r \"N: {nr}, alias: {kv}\" -k alias.tsv data.tsv [INFO] read key-value file: alias.tsv [INFO] 3 pairs of key-value loaded name id A N: 1, alias: Tom B N: 2, alias: Bob C N: 3, alias: 004","title":"replace"},{"location":"usage/#round","text":"Usage round float to n decimal places Usage: csvtk round [flags] Flags: -a, --all-fields all fields, overides -f/--fields -n, --decimal-width int limit floats to N decimal points (default 2) -f, --fields string select only these fields. e.g -f 1,2 or -f columnA,columnB (default \"1\") -F, --fuzzy-fields using fuzzy fields, e.g., -F -f \"*name\" or -F -f \"id123*\" -h, --help help for round Examples: $ cat testdata/floats.csv | csvtk pretty a b 0.12345 abc NA 0.9999198549640733 12.3 e3 1.4814505299984235e-05 -3.1415926E05 # one or more fields $ cat testdata/floats.csv | csvtk round -n 2 -f b | csvtk pretty a b 0.12345 abc NA 1.00 12.3 e3 1.4814505299984235e-05 -3.14E05 # all fields $ cat testdata/floats.csv | csvtk round -n 2 -a | csvtk pretty a b 0.12 abc NA 1.00 12.30 e3 1.48e-05 -3.14E05","title":"round"},{"location":"usage/#mutate","text":"Usage create new column from selected fields by regular expression Usage: csvtk mutate [flags] Flags: -f, --fields string select only these fields. e.g -f 1,2 or -f columnA,columnB (default \"1\") -i, --ignore-case ignore case --na for unmatched data, use blank instead of original data -n, --name string new column name -p, --pattern string search regular expression with capture bracket. e.g. (default \"^(.+)$\") Examples By default, copy a column: csvtk mutate -f id -n newname Extract prefix of data as group name using regular expression (get \"A\" from \"A.1\" as group name): csvtk mutate -f sample -n group -p \"^(.+?)\\.\" get the first letter as new column $ cat testdata/phones.csv username,phone gri,11111 rob,12345 ken,22222 shenwei,999999 $ cat testdata/phones.csv \\ | csvtk mutate -f username -p \"^(\\w)\" -n first_letter username,phone,first_letter gri,11111,g rob,12345,r ken,22222,k shenwei,999999,s","title":"mutate"},{"location":"usage/#mutate2","text":"Usage create new column from selected fields by awk-like arithmetic/string expressions The arithmetic/string expression is supported by: https://github.com/Knetic/govaluate Supported operators and types: Modifiers: + - / * & | ^ ** % >> << Comparators: > >= < <= == != =~ !~ Logical ops: || && Numeric constants, as 64-bit floating point (12345.678) String constants (single quotes: 'foobar') Date constants (single quotes) Boolean constants: true false Parenthesis to control order of evaluation ( ) Arrays (anything separated by , within parenthesis: (1, 2, 'foo')) Prefixes: ! - ~ Ternary conditional: ? : Null coalescence: ?? Custom functions: - len(), length of strings, e.g., len($1), len($a), len($1, $2) - ulen(), length of unicode strings/width of unicode strings rendered to a terminal, e.g., len(\"\u6c88\u4f1f\")==6, ulen(\"\u6c88\u4f1f\")==4 Usage: csvtk mutate2 [flags] Flags: -w, --decimal-width int limit floats to N decimal points (default 2) -e, --expression string arithmetic/string expressions. e.g. \"'string'\", '\"abc\"', ' $a + \"-\" + $b ', '$1 + $2', '$a / $b', ' $1 > 100 ? \"big\" : \"small\" ' -h, --help help for mutate2 -n, --name string new column name -s, --numeric-as-string treat even numeric fields as strings to avoid converting big numbers into scientific notation Example Constants $ cat testdata/digitals.tsv \\ | csvtk mutate2 -t -H -e \" 'abc' \" 4 5 6 abc 1 2 3 abc 7 8 0 abc 8 1,000 4 abc $ val=123 \\ && cat testdata/digitals.tsv \\ | csvtk mutate2 -t -H -e \" $val \" 4 5 6 123 1 2 3 123 7 8 0 123 8 1,000 4 123 String concatenation $ cat testdata/names.csv \\ | csvtk mutate2 -n full_name -e ' $first_name + \" \" + $last_name ' \\ | csvtk pretty id first_name last_name username full_name 11 Rob Pike rob Rob Pike 2 Ken Thompson ken Ken Thompson 4 Robert Griesemer gri Robert Griesemer 1 Robert Thompson abc Robert Thompson NA Robert Abel 123 Robert Abel Math $ cat testdata/digitals.tsv | csvtk mutate2 -t -H -e '$1 + $3' -L 0 4 5 6 10 1 2 3 4 7 8 0 7 8 1,000 4 12 Bool $ cat testdata/digitals.tsv | csvtk mutate2 -t -H -e '$1 > 5' 4 5 6 false 1 2 3 false 7 8 0 true 8 1,000 4 true Ternary condition ( ? : ) $ cat testdata/digitals.tsv | csvtk mutate2 -t -H -e '$1 > 5 ? \"big\" : \"small\" ' 4 5 6 small 1 2 3 small 7 8 0 big 8 1,000 4 big Null coalescence ( ?? ) $ echo -e \"one,two\\na1,a2\\n,b2\\na2,\" | csvtk pretty one two --- --- a1 a2 b2 a2 $ echo -e \"one,two\\na1,a2\\n,b2\\na2,\" \\ | csvtk mutate2 -n three -e '$one ?? $two' \\ | csvtk pretty one two three --- --- ----- a1 a2 a1 b2 b2 a2 a2","title":"mutate2"},{"location":"usage/#sep","text":"Usage separate column into multiple columns Usage: csvtk sep [flags] Flags: --drop drop extra data, exclusive with --merge -f, --fields string select only these fields. e.g -f 1,2 or -f columnA,columnB (default \"1\") -h, --help help for sep -i, --ignore-case ignore case --merge only splits at most N times, exclusive with --drop --na string content for filling NA data -n, --names strings new column names -N, --num-cols int preset number of new created columns -R, --remove remove input column -s, --sep string separator -r, --use-regexp separator is a regular expression Examples: $ cat players.csv | csvtk collapse -f 1 -v 3 -s ';' gender,name male,A;B;C female,a;b;c;d # set number of new columns as 3. $ cat players.csv | csvtk collapse -f 1 -v 3 -s ';' \\ | csvtk sep -f 2 -s ';' -n p1,p2,p3,p4 -N 4 --na NA \\ | csvtk pretty gender name p1 p2 p3 p4 male A;B;C A B C NA female a;b;c;d a b c d # set number of new columns as 3, drop extra values $ cat players.csv | csvtk collapse -f 1 -v 3 -s ';' \\ | csvtk sep -f 2 -s ';' -n p1,p2,p3 --drop \\ | csvtk pretty gender name p1 p2 p3 male A;B;C A B C female a;b;c;d a b c # set number of new columns as 3, split as most 3 parts $ cat players.csv | csvtk collapse -f 1 -v 3 -s ';' \\ | csvtk sep -f 2 -s ';' -n p1,p2,p3 --merge \\ | csvtk pretty gender name p1 p2 p3 male A;B;C A B C female a;b;c;d a b c;d # $ echo -ne \"taxid\\tlineage\\n9606\\tEukaryota;Chordata;Mammalia;Primates;Hominidae;Homo;Homo sapiens\\n\" taxid lineage 9606 Eukaryota;Chordata;Mammalia;Primates;Hominidae;Homo;Homo sapiens $ echo -ne \"taxid\\tlineage\\n9606\\tEukaryota;Chordata;Mammalia;Primates;Hominidae;Homo;Homo sapiens\\n\" \\ | csvtk sep -t -f 2 -s ';' -n kindom,phylum,class,order,family,genus,species --remove \\ | csvtk pretty -t taxid kindom phylum class order family genus species 9606 Eukaryota Chordata Mammalia Primates Hominidae Homo Homo sapiens","title":"sep"},{"location":"usage/#gather","text":"Usage gather columns into key-value pairs Usage: csvtk gather [flags] Flags: -f, --fields string fields for gathering. e.g -f 1,2 or -f columnA,columnB, or -f -columnA for unselect columnA -F, --fuzzy-fields using fuzzy fields, e.g., -F -f \"*name\" or -F -f \"id123*\" -k, --key string name of key column to create in output -v, --value string name of value column to create in output Examples: $ cat testdata/names.csv id,first_name,last_name,username 11,\"Rob\",\"Pike\",rob 2,Ken,Thompson,ken 4,\"Robert\",\"Griesemer\",\"gri\" 1,\"Robert\",\"Thompson\",\"abc\" NA,\"Robert\",\"Abel\",\"123 $ cat testdata/names.csv \\ | csvtk gather -k item -v value -f -1 id,item,value 11,first_name,Rob 11,last_name,Pike 11,username,rob 2,first_name,Ken 2,last_name,Thompson 2,username,ken 4,first_name,Robert 4,last_name,Griesemer 4,username,gri 1,first_name,Robert 1,last_name,Thompson 1,username,abc NA,first_name,Robert NA,last_name,Abel NA,username,123","title":"gather"},{"location":"usage/#unfold","text":"Usage unfold multiple values in cells of a field Example: $ echo -ne \"id,values,meta\\n1,a;b,12\\n2,c,23\\n3,d;e;f,34\\n\" \\ | csvtk pretty id values meta 1 a;b 12 2 c 23 3 d;e;f 34 $ echo -ne \"id,values,meta\\n1,a;b,12\\n2,c,23\\n3,d;e;f,34\\n\" \\ | csvtk unfold -f values -s \";\" \\ | csvtk pretty id values meta 1 a 12 1 b 12 2 c 23 3 d 34 3 e 34 3 f 34 Usage: csvtk unfold [flags] Flags: -f, --fields string field to expand, only one field is allowed. type \"csvtk unfold -h\" for examples -h, --help help for unfold -s, --separater string separater for folded values (default \"; \")","title":"unfold"},{"location":"usage/#fold","text":"Usage fold multiple values of a field into cells of groups Attention: Only grouping fields and value filed are outputted. Example: $ echo -ne \"id,value,meta\\n1,a,12\\n1,b,34\\n2,c,56\\n2,d,78\\n\" \\ | csvtk pretty id value meta 1 a 12 1 b 34 2 c 56 2 d 78 $ echo -ne \"id,value,meta\\n1,a,12\\n1,b,34\\n2,c,56\\n2,d,78\\n\" \\ | csvtk fold -f id -v value -s \";\" \\ | csvtk pretty id value 1 a;b 2 c;d $ echo -ne \"id,value,meta\\n1,a,12\\n1,b,34\\n2,c,56\\n2,d,78\\n\" \\ | csvtk fold -f id -v value -s \";\" \\ | csvtk unfold -f value -s \";\" \\ | csvtk pretty id value 1 a 1 b 2 c 2 d Usage: csvtk fold [flags] Aliases: fold, collapse Flags: -f, --fields string key fields for grouping. e.g -f 1,2 or -f columnA,columnB (default \"1\") -F, --fuzzy-fields using fuzzy fields (only for key fields), e.g., -F -f \"*name\" or -F -f \"id123*\" -h, --help help for fold -i, --ignore-case ignore case -s, --separater string separater for folded values (default \"; \") -v, --vfield string value field for folding examples data $ csvtk pretty teachers.csv lab teacher class computational biology Tom Bioinformatics computational biology Tom Statistics computational biology Rob Bioinformatics sequencing center Jerry Bioinformatics sequencing center Nick Molecular Biology sequencing center Nick Microbiology List teachers for every lab/class. uniq is used to deduplicate items. $ cat teachers.csv \\ | csvtk uniq -f lab,teacher \\ | csvtk fold -f lab -v teacher \\ | csvtk pretty lab teacher computational biology Tom; Rob sequencing center Jerry; Nick $ cat teachers.csv \\ | csvtk uniq -f class,teacher \\ | csvtk fold -f class -v teacher -s \", \" \\ | csvtk pretty class teacher Statistics Tom Bioinformatics Tom, Rob, Jerry Molecular Biology Nick Microbiology Nick Multiple key fields supported $ cat teachers.csv \\ | csvtk fold -f teacher,lab -v class \\ | csvtk pretty teacher lab class Tom computational biology Bioinformatics; Statistics Rob computational biology Bioinformatics Jerry sequencing center Bioinformatics Nick sequencing center Molecular Biology; Microbiology","title":"fold"},{"location":"usage/#fmtdate","text":"Usage format date of selected fields Date parsing is supported by: https://github.com/araddon/dateparse Date formating is supported by: https://github.com/metakeule/fmtdate Time zones: format: Asia/Shanghai whole list: https://en.wikipedia.org/wiki/List_of_tz_database_time_zones Output format is in MS Excel (TM) syntax. Placeholders: M - month (1) MM - month (01) MMM - month (Jan) MMMM - month (January) D - day (2) DD - day (02) DDD - day (Mon) DDDD - day (Monday) YY - year (06) YYYY - year (2006) hh - hours (15) mm - minutes (04) ss - seconds (05) AM/PM hours: 'h' followed by optional 'mm' and 'ss' followed by 'pm', e.g. hpm - hours (03PM) h:mmpm - hours:minutes (03:04PM) h:mm:sspm - hours:minutes:seconds (03:04:05PM) Time zones: a time format followed by 'ZZZZ', 'ZZZ' or 'ZZ', e.g. hh:mm:ss ZZZZ (16:05:06 +0100) hh:mm:ss ZZZ (16:05:06 CET) hh:mm:ss ZZ (16:05:06 +01:00) Usage: csvtk fmtdate [flags] Flags: -f, --fields string select only these fields. e.g -f 1,2 or -f columnA,columnB (default \"1\") --format string output date format in MS Excel (TM) syntax, type \"csvtk fmtdate -h\" for details (default \"YYYY-MM-DD hh:mm:ss\") -F, --fuzzy-fields using fuzzy fields, e.g., -F -f \"*name\" or -F -f \"id123*\" -h, --help help for fmtdate -k, --keep-unparsed keep the key as value when no value found for the key -z, --time-zone string timezone aka \"Asia/Shanghai\" or \"America/Los_Angeles\" formatted time-zone, type \"csvtk fmtdate -h\" for details Examples $ csvtk xlsx2csv date.xlsx | csvtk pretty data value ------------------- ----- 2021-08-25 11:24:21 1 08/25/21 11:24 p8 2 NA 3 4 $ csvtk xlsx2csv date.xlsx \\ | csvtk fmtdate --format \"YYYY-MM-DD hh:mm:ss\" \\ | csvtk pretty data value ------------------- ----- 2021-08-25 11:24:21 1 2021-08-25 11:24:00 2 3 4 $ csvtk xlsx2csv date.xlsx \\ | csvtk fmtdate --format \"YYYY-MM-DD hh:mm:ss\" -k \\ | csvtk pretty data value ------------------- ----- 2021-08-25 11:24:21 1 2021-08-25 11:24:00 2 NA 3 4","title":"fmtdate"},{"location":"usage/#sort","text":"Usage sort by selected fields Usage: csvtk sort [flags] Flags: -h, --help help for sort -i, --ignore-case ignore-case -k, --keys strings keys (multiple values supported). sort type supported, \"N\" for natural order, \"n\" for number, \"u\" for user-defined order and \"r\" for reverse. e.g., \"-k 1\" or \"-k A:r\" or \"\"-k 1:nr -k 2\" (default [1]) -L, --levels strings user-defined level file (one level per line, multiple values supported). format: <field>:<level-file>. e.g., \"-k name:u -L name:level.txt\" Examples data $ cat testdata/names.csv id,first_name,last_name,username 11,\"Rob\",\"Pike\",rob 2,Ken,Thompson,ken 4,\"Robert\",\"Griesemer\",\"gri\" 1,\"Robert\",\"Thompson\",\"abc\" NA,\"Robert\",\"Abel\",\"123\" By single column : csvtk sort -k 1 or csvtk sort -k last_name in alphabetical order $ cat testdata/names.csv \\ | csvtk sort -k first_name id,first_name,last_name,username 2,Ken,Thompson,ken 11,Rob,Pike,rob NA,Robert,Abel,123 1,Robert,Thompson,abc 4,Robert,Griesemer,gri in reversed alphabetical order ( key:r ) $ cat testdata/names.csv \\ | csvtk sort -k first_name:r id,first_name,last_name,username NA,Robert,Abel,123 1,Robert,Thompson,abc 4,Robert,Griesemer,gri 11,Rob,Pike,rob 2,Ken,Thompson,ken in numerical order ( key:n ) $ cat testdata/names.csv \\ | csvtk sort -k id:n id,first_name,last_name,username NA,Robert,Abel,123 1,Robert,Thompson,abc 2,Ken,Thompson,ken 4,Robert,Griesemer,gri 11,Rob,Pike,rob in natural order ( key:N ) $ cat testdata/names.csv | csvtk sort -k id:N id,first_name,last_name,username 1,Robert,Thompson,abc 2,Ken,Thompson,ken 4,Robert,Griesemer,gri 11,Rob,Pike,rob NA,Robert,Abel,123 in natural order ( key:N ), a bioinformatics example $ echo \"X,Y,1,10,2,M,11,1_c,Un_g,1_g\" | csvtk transpose X Y 1 10 2 M 11 1_c Un_g 1_g $ echo \"X,Y,1,10,2,M,11,1_c,Un_g,1_g\" \\ | csvtk transpose \\ | csvtk sort -H -k 1:N 1 1_c 1_g 2 10 11 M Un_g X Y By multiple columns: csvtk sort -k 1,2 or csvtk sort -k 1 -k 2 or csvtk sort -k last_name,age # by first_name and then last_name $ cat testdata/names.csv | csvtk sort -k first_name -k last_name id,first_name,last_name,username 2,Ken,Thompson,ken 11,Rob,Pike,rob NA,Robert,Abel,123 4,Robert,Griesemer,gri 1,Robert,Thompson,abc # by first_name and then ID $ cat testdata/names.csv | csvtk sort -k first_name -k id:n id,first_name,last_name,username 2,Ken,Thompson,ken 11,Rob,Pike,rob NA,Robert,Abel,123 1,Robert,Thompson,abc 4,Robert,Griesemer,gri By user-defined order # user-defined order/level $ cat testdata/size_level.txt tiny mini small medium big # original data $ cat testdata/size.csv id,size 1,Huge 2,Tiny 3,Big 4,Small 5,Medium $ csvtk sort -k 2:u -i -L 2:testdata/size_level.txt testdata/size.csv id,size 2,Tiny 4,Small 5,Medium 3,Big 1,Huge","title":"sort"},{"location":"usage/#plot","text":"Usage plot common figures Notes: 1. Output file can be set by flag -o/--out-file. 2. File format is determined by the out file suffix. Supported formats: eps, jpg|jpeg, pdf, png, svg, and tif|tiff 3. If flag -o/--out-file not set (default), image is written to stdout, you can display the image by pipping to \"display\" command of Imagemagic or just redirect to file. Usage: csvtk plot [command] Available Commands: box plot boxplot hist plot histogram line line plot and scatter plot Flags: --axis-width float axis width (default 1.5) -f, --data-field string column index or column name of data (default \"1\") --format string image format for stdout when flag -o/--out-file not given. available values: eps, jpg|jpeg, pdf, png, svg, and tif|tiff. (default \"png\") -g, --group-field string column index or column name of group --height float Figure height (default 4.5) --label-size int label font size (default 14) --tick-width float axis tick width (default 1.5) --title string Figure title --title-size int title font size (default 16) --width float Figure width (default 6) --x-max string maximum value of X axis --x-min string minimum value of X axis --xlab string x label text --y-max string maximum value of Y axis --y-min string minimum value of Y axis --ylab string y label text Note that most of the flags of plot are global flags of the subcommands hist , box and line Notes of image output Output file can be set by flag -o/--out-file. File format is determined by the out file suffix. Supported formats: eps, jpg|jpeg, pdf, png, svg, and tif|tiff If flag -o/--out-file not set (default), image is written to stdout, you can display the image by pipping to display command of Imagemagic or just redirect to file.","title":"plot"},{"location":"usage/#plot-hist","text":"Usage plot histogram Notes: 1. Output file can be set by flag -o/--out-file. 2. File format is determined by the out file suffix. Supported formats: eps, jpg|jpeg, pdf, png, svg, and tif|tiff 3. If flag -o/--out-file not set (default), image is written to stdout, you can display the image by pipping to \"display\" command of Imagemagic or just redirect to file. Usage: csvtk plot hist [flags] Flags: --bins int number of bins (default 50) --color-index int color index, 1-7 (default 1) Examples example data $ zcat testdata/grouped_data.tsv.gz | head -n 5 | csvtk -t pretty Group Length GC Content Group A 97 57.73 Group A 95 49.47 Group A 97 49.48 Group A 100 51.00 plot histogram with data of the second column: $ csvtk -t plot hist testdata/grouped_data.tsv.gz -f 2 \\ --title Histogram -o histogram.png You can also write image to stdout and pipe to \"display\" command of Imagemagic: $ csvtk -t plot hist testdata/grouped_data.tsv.gz -f 2 | display","title":"plot hist"},{"location":"usage/#plot-box","text":"Usage plot boxplot Notes: 1. Output file can be set by flag -o/--out-file. 2. File format is determined by the out file suffix. Supported formats: eps, jpg|jpeg, pdf, png, svg, and tif|tiff 3. If flag -o/--out-file not set (default), image is written to stdout, you can display the image by pipping to \"display\" command of Imagemagic or just redirect to file. Usage: csvtk plot box [flags] Flags: --box-width float box width --horiz horize box plot Examples plot boxplot with data of the \"GC Content\" (third) column, group information is the \"Group\" column. csvtk -t plot box testdata/grouped_data.tsv.gz -g \"Group\" -f \"GC Content\" \\ --width 3 --title \"Box plot\" \\ > boxplot.png plot horiz boxplot with data of the \"Length\" (second) column, group information is the \"Group\" column. $ csvtk -t plot box testdata/grouped_data.tsv.gz -g \"Group\" -f \"Length\" \\ --height 3 --width 5 --horiz --title \"Horiz box plot\" \\ > boxplot2.png`","title":"plot box"},{"location":"usage/#plot-line","text":"Usage line plot and scatter plot Notes: 1. Output file can be set by flag -o/--out-file. 2. File format is determined by the out file suffix. Supported formats: eps, jpg|jpeg, pdf, png, svg, and tif|tiff 3. If flag -o/--out-file not set (default), image is written to stdout, you can display the image by pipping to \"display\" command of Imagemagic or just redirect to file. Usage: csvtk plot line [flags] Flags: -x, --data-field-x string column index or column name of X for command line -y, --data-field-y string column index or column name of Y for command line --legend-left locate legend along the left edge of the plot --legend-top locate legend along the top edge of the plot --line-width float line width (default 1.5) --point-size float point size (default 3) --scatter only plot points Examples example data $ head -n 5 testdata/xy.tsv Group X Y A 0 1 A 1 1.3 A 1.5 1.5 A 2.0 2 plot line plot with X-Y data $ csvtk -t plot line testdata/xy.tsv -x X -y Y -g Group \\ --title \"Line plot\" \\ > lineplot.png plot scatter $ csvtk -t plot line testdata/xy.tsv -x X -y Y -g Group \\ --title \"Scatter\" --scatter \\ > lineplot.png","title":"plot line"},{"location":"usage/#cat","text":"Usage stream file to stdout and report progress on stderr Usage: csvtk cat [flags] Flags: -b, --buffsize int buffer size (default 8192) -h, --help help for cat -L, --lines count lines instead of bytes -p, --print-freq int print frequency (-1 for print after parsing) (default 1) -s, --total int expected total bytes/lines (default -1) Examples Stream file, report progress in bytes csvtk cat file.tsv Stream file from stdin, report progress in lines tac input.tsv | csvtk cat -L -s `wc -l < input.tsv` -","title":"cat"},{"location":"usage/#genautocomplete","text":"Usage generate shell autocompletion script Supported shell: bash|zsh|fish|powershell Bash: # generate completion shell csvtk genautocomplete --shell bash # configure if never did. # install bash-completion if the \"complete\" command is not found. echo \"for bcfile in ~/.bash_completion.d/* ; do source \\$bcfile; done\" >> ~/.bash_completion echo \"source ~/.bash_completion\" >> ~/.bashrc Zsh: # generate completion shell csvtk genautocomplete --shell zsh --file ~/.zfunc/_csvtk # configure if never did echo 'fpath=( ~/.zfunc \"${fpath[@]}\" )' >> ~/.zshrc echo \"autoload -U compinit; compinit\" >> ~/.zshrc fish: csvtk genautocomplete --shell fish --file ~/.config/fish/completions/csvtk.fish Usage: csvtk genautocomplete [flags] Flags: --file string autocompletion file (default \"/home/shenwei/.bash_completion.d/csvtk.sh\") -h, --help help for genautocomplete --shell string autocompletion type (bash|zsh|fish|powershell) (default \"bash\") /** * RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS. * LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables */ /* var disqus_config = function () { this.page.url = PAGE_URL; // Replace PAGE_URL with your page's canonical URL variable this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable }; */ (function() { // DON'T EDIT BELOW THIS LINE var d = document, s = d.createElement('script'); s.src = '//csvtk.disqus.com/embed.js'; s.setAttribute('data-timestamp', +new Date()); (d.head || d.body).appendChild(s); })(); Please enable JavaScript to view the comments powered by Disqus.","title":"genautocomplete"}]}